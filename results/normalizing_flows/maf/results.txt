{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 100,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
Evaluate (epoch 0) -- logp(x) = -1.924 +/- 0.004
Evaluate (epoch 1) -- logp(x) = -1.545 +/- 0.008
Evaluate (epoch 2) -- logp(x) = -1.213 +/- 0.006
Evaluate (epoch 3) -- logp(x) = -0.960 +/- 0.008
Evaluate (epoch 4) -- logp(x) = -0.912 +/- 0.010
Evaluate (epoch 5) -- logp(x) = -0.958 +/- 0.010
Evaluate (epoch 6) -- logp(x) = -0.922 +/- 0.012
Evaluate (epoch 7) -- logp(x) = -0.919 +/- 0.010
Evaluate (epoch 8) -- logp(x) = -0.822 +/- 0.009
Evaluate (epoch 9) -- logp(x) = -0.744 +/- 0.011
Evaluate (epoch 10) -- logp(x) = -0.684 +/- 0.009
Evaluate (epoch 11) -- logp(x) = -0.879 +/- 0.009
Evaluate (epoch 12) -- logp(x) = -0.871 +/- 0.009
Evaluate (epoch 13) -- logp(x) = -0.656 +/- 0.009
Evaluate (epoch 14) -- logp(x) = -0.681 +/- 0.009
Evaluate (epoch 15) -- logp(x) = -1.063 +/- 0.009
Evaluate (epoch 16) -- logp(x) = -0.714 +/- 0.009
Evaluate (epoch 17) -- logp(x) = -0.746 +/- 0.009
Evaluate (epoch 18) -- logp(x) = -0.597 +/- 0.009
Evaluate (epoch 19) -- logp(x) = -0.620 +/- 0.009
Evaluate (epoch 20) -- logp(x) = -0.794 +/- 0.009
Evaluate (epoch 21) -- logp(x) = -0.647 +/- 0.009
Evaluate (epoch 22) -- logp(x) = -0.575 +/- 0.008
Evaluate (epoch 23) -- logp(x) = -0.632 +/- 0.009
Evaluate (epoch 24) -- logp(x) = -0.649 +/- 0.009
Evaluate (epoch 25) -- logp(x) = -0.693 +/- 0.009
Evaluate (epoch 26) -- logp(x) = -0.626 +/- 0.009
Evaluate (epoch 27) -- logp(x) = -0.675 +/- 0.009
Evaluate (epoch 28) -- logp(x) = -0.716 +/- 0.009
Evaluate (epoch 29) -- logp(x) = -0.689 +/- 0.009
Evaluate (epoch 30) -- logp(x) = -0.538 +/- 0.009
Evaluate (epoch 31) -- logp(x) = -0.660 +/- 0.009
Evaluate (epoch 32) -- logp(x) = -0.620 +/- 0.008
Evaluate (epoch 33) -- logp(x) = -0.606 +/- 0.009
Evaluate (epoch 34) -- logp(x) = -0.435 +/- 0.009
Evaluate (epoch 35) -- logp(x) = -0.595 +/- 0.009
Evaluate (epoch 36) -- logp(x) = -0.629 +/- 0.008
Evaluate (epoch 37) -- logp(x) = -0.348 +/- 0.010
Evaluate (epoch 38) -- logp(x) = -0.808 +/- 0.011
Evaluate (epoch 39) -- logp(x) = -0.566 +/- 0.009
Evaluate (epoch 40) -- logp(x) = -0.662 +/- 0.010
Evaluate (epoch 41) -- logp(x) = -0.508 +/- 0.009
Evaluate (epoch 42) -- logp(x) = -0.635 +/- 0.010
Evaluate (epoch 43) -- logp(x) = -0.533 +/- 0.009
Evaluate (epoch 44) -- logp(x) = -0.673 +/- 0.009
Evaluate (epoch 45) -- logp(x) = -0.414 +/- 0.010
Evaluate (epoch 46) -- logp(x) = -0.560 +/- 0.012
Evaluate (epoch 47) -- logp(x) = -0.654 +/- 0.011
Evaluate (epoch 48) -- logp(x) = -0.351 +/- 0.010
Evaluate (epoch 49) -- logp(x) = -0.685 +/- 0.013
Evaluate (epoch 50) -- logp(x) = -0.939 +/- 0.015
Evaluate (epoch 51) -- logp(x) = -0.519 +/- 0.013
Evaluate (epoch 52) -- logp(x) = -0.512 +/- 0.012
Evaluate (epoch 53) -- logp(x) = -0.327 +/- 0.015
Evaluate (epoch 54) -- logp(x) = -0.444 +/- 0.017
Evaluate (epoch 55) -- logp(x) = -0.420 +/- 0.014
Evaluate (epoch 56) -- logp(x) = -0.309 +/- 0.016
Evaluate (epoch 57) -- logp(x) = -0.383 +/- 0.016
Evaluate (epoch 58) -- logp(x) = -0.343 +/- 0.015
Evaluate (epoch 59) -- logp(x) = -0.247 +/- 0.016
Evaluate (epoch 60) -- logp(x) = -0.202 +/- 0.016
Evaluate (epoch 61) -- logp(x) = -0.423 +/- 0.017
Evaluate (epoch 62) -- logp(x) = -0.108 +/- 0.017
Evaluate (epoch 63) -- logp(x) = -0.197 +/- 0.016
Evaluate (epoch 64) -- logp(x) = -0.138 +/- 0.017
Evaluate (epoch 65) -- logp(x) = -0.174 +/- 0.017
Evaluate (epoch 66) -- logp(x) = -0.091 +/- 0.018
Evaluate (epoch 67) -- logp(x) = -0.207 +/- 0.018
Evaluate (epoch 68) -- logp(x) = -0.295 +/- 0.017
Evaluate (epoch 69) -- logp(x) = -0.061 +/- 0.018
Evaluate (epoch 70) -- logp(x) = -0.145 +/- 0.017
Evaluate (epoch 71) -- logp(x) = -0.125 +/- 0.017
Evaluate (epoch 72) -- logp(x) = -0.083 +/- 0.018
Evaluate (epoch 73) -- logp(x) = -0.123 +/- 0.018
Evaluate (epoch 74) -- logp(x) = -0.095 +/- 0.017
Evaluate (epoch 75) -- logp(x) = 0.020 +/- 0.017
Evaluate (epoch 76) -- logp(x) = -0.093 +/- 0.017
Evaluate (epoch 77) -- logp(x) = -0.100 +/- 0.018
Evaluate (epoch 78) -- logp(x) = -0.320 +/- 0.018
Evaluate (epoch 79) -- logp(x) = 0.035 +/- 0.017
Evaluate (epoch 80) -- logp(x) = -0.407 +/- 0.018
Evaluate (epoch 81) -- logp(x) = -0.214 +/- 0.018
Evaluate (epoch 82) -- logp(x) = 0.013 +/- 0.020
Evaluate (epoch 83) -- logp(x) = -0.080 +/- 0.019
Evaluate (epoch 84) -- logp(x) = -0.283 +/- 0.018
Evaluate (epoch 85) -- logp(x) = -0.059 +/- 0.016
Evaluate (epoch 86) -- logp(x) = 0.117 +/- 0.018
Evaluate (epoch 87) -- logp(x) = 0.066 +/- 0.018
Evaluate (epoch 88) -- logp(x) = 0.096 +/- 0.018
Evaluate (epoch 89) -- logp(x) = -0.074 +/- 0.019
Evaluate (epoch 90) -- logp(x) = 0.080 +/- 0.018
Evaluate (epoch 91) -- logp(x) = -0.090 +/- 0.019
Evaluate (epoch 92) -- logp(x) = -0.046 +/- 0.025
Evaluate (epoch 93) -- logp(x) = 0.118 +/- 0.020
Evaluate (epoch 94) -- logp(x) = 0.053 +/- 0.019
Evaluate (epoch 95) -- logp(x) = 0.047 +/- 0.020
Evaluate (epoch 96) -- logp(x) = -0.199 +/- 0.018
Evaluate (epoch 97) -- logp(x) = 0.016 +/- 0.019
Evaluate (epoch 98) -- logp(x) = -0.052 +/- 0.019
Evaluate (epoch 99) -- logp(x) = 0.180 +/- 0.018
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 100,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
Evaluate (epoch 0) -- logp(x) = -2.614 +/- 0.013
Evaluate (epoch 1) -- logp(x) = -2.593 +/- 0.012
Evaluate (epoch 2) -- logp(x) = -2.559 +/- 0.012
Evaluate (epoch 3) -- logp(x) = -2.397 +/- 0.012
Evaluate (epoch 4) -- logp(x) = -2.291 +/- 0.012
Evaluate (epoch 5) -- logp(x) = -2.238 +/- 0.012
Evaluate (epoch 6) -- logp(x) = -2.160 +/- 0.011
Evaluate (epoch 7) -- logp(x) = -2.134 +/- 0.012
Evaluate (epoch 8) -- logp(x) = -2.102 +/- 0.012
Evaluate (epoch 9) -- logp(x) = -2.083 +/- 0.012
Evaluate (epoch 10) -- logp(x) = -2.025 +/- 0.012
Evaluate (epoch 11) -- logp(x) = -1.984 +/- 0.011
Evaluate (epoch 12) -- logp(x) = -1.989 +/- 0.012
Evaluate (epoch 13) -- logp(x) = -1.956 +/- 0.012
Evaluate (epoch 14) -- logp(x) = -2.038 +/- 0.011
Evaluate (epoch 15) -- logp(x) = -1.926 +/- 0.011
Evaluate (epoch 16) -- logp(x) = -1.903 +/- 0.012
Evaluate (epoch 17) -- logp(x) = -1.851 +/- 0.012
Evaluate (epoch 18) -- logp(x) = -1.831 +/- 0.012
Evaluate (epoch 19) -- logp(x) = -1.819 +/- 0.013
Evaluate (epoch 20) -- logp(x) = -1.810 +/- 0.012
Evaluate (epoch 21) -- logp(x) = -1.771 +/- 0.012
Evaluate (epoch 22) -- logp(x) = -1.781 +/- 0.013
Evaluate (epoch 23) -- logp(x) = -1.945 +/- 0.012
Evaluate (epoch 24) -- logp(x) = -1.799 +/- 0.012
Evaluate (epoch 25) -- logp(x) = -1.871 +/- 0.011
Evaluate (epoch 26) -- logp(x) = -1.794 +/- 0.012
Evaluate (epoch 27) -- logp(x) = -1.736 +/- 0.012
Evaluate (epoch 28) -- logp(x) = -1.716 +/- 0.012
Evaluate (epoch 29) -- logp(x) = -1.745 +/- 0.012
Evaluate (epoch 30) -- logp(x) = -1.781 +/- 0.011
Evaluate (epoch 31) -- logp(x) = -1.692 +/- 0.013
Evaluate (epoch 32) -- logp(x) = -1.682 +/- 0.013
Evaluate (epoch 33) -- logp(x) = -1.751 +/- 0.013
Evaluate (epoch 34) -- logp(x) = -1.687 +/- 0.013
Evaluate (epoch 35) -- logp(x) = -1.683 +/- 0.014
Evaluate (epoch 36) -- logp(x) = -1.663 +/- 0.013
Evaluate (epoch 37) -- logp(x) = -1.652 +/- 0.013
Evaluate (epoch 38) -- logp(x) = -1.662 +/- 0.013
Evaluate (epoch 39) -- logp(x) = -1.654 +/- 0.013
Evaluate (epoch 40) -- logp(x) = -1.646 +/- 0.013
Evaluate (epoch 41) -- logp(x) = -1.654 +/- 0.012
Evaluate (epoch 42) -- logp(x) = -1.627 +/- 0.012
Evaluate (epoch 43) -- logp(x) = -1.607 +/- 0.013
Evaluate (epoch 44) -- logp(x) = -1.624 +/- 0.012
Evaluate (epoch 45) -- logp(x) = -1.648 +/- 0.012
Evaluate (epoch 46) -- logp(x) = -1.565 +/- 0.014
Evaluate (epoch 47) -- logp(x) = -1.550 +/- 0.014
Evaluate (epoch 48) -- logp(x) = -1.531 +/- 0.013
Evaluate (epoch 49) -- logp(x) = -1.578 +/- 0.013
Evaluate (epoch 50) -- logp(x) = -1.669 +/- 0.012
Evaluate (epoch 51) -- logp(x) = -1.571 +/- 0.013
Evaluate (epoch 52) -- logp(x) = -1.552 +/- 0.013
Evaluate (epoch 53) -- logp(x) = -1.749 +/- 0.014
Evaluate (epoch 54) -- logp(x) = -1.555 +/- 0.012
Evaluate (epoch 55) -- logp(x) = -1.548 +/- 0.013
Evaluate (epoch 56) -- logp(x) = -1.622 +/- 0.012
Evaluate (epoch 57) -- logp(x) = -1.539 +/- 0.013
Evaluate (epoch 58) -- logp(x) = -1.457 +/- 0.013
Evaluate (epoch 59) -- logp(x) = -1.486 +/- 0.013
Evaluate (epoch 60) -- logp(x) = -1.530 +/- 0.012
Evaluate (epoch 61) -- logp(x) = -1.507 +/- 0.013
Evaluate (epoch 62) -- logp(x) = -1.548 +/- 0.014
Evaluate (epoch 63) -- logp(x) = -1.524 +/- 0.013
Evaluate (epoch 64) -- logp(x) = -1.578 +/- 0.014
Evaluate (epoch 65) -- logp(x) = -1.462 +/- 0.013
Evaluate (epoch 66) -- logp(x) = -1.476 +/- 0.013
Evaluate (epoch 67) -- logp(x) = -1.428 +/- 0.014
Evaluate (epoch 68) -- logp(x) = -1.426 +/- 0.014
Evaluate (epoch 69) -- logp(x) = -1.398 +/- 0.015
Evaluate (epoch 70) -- logp(x) = -1.476 +/- 0.013
Evaluate (epoch 71) -- logp(x) = -1.530 +/- 0.013
Evaluate (epoch 72) -- logp(x) = -1.520 +/- 0.014
Evaluate (epoch 73) -- logp(x) = -1.427 +/- 0.014
Evaluate (epoch 74) -- logp(x) = -1.417 +/- 0.014
Evaluate (epoch 75) -- logp(x) = -1.443 +/- 0.013
Evaluate (epoch 76) -- logp(x) = -1.389 +/- 0.014
Evaluate (epoch 77) -- logp(x) = -1.428 +/- 0.014
Evaluate (epoch 78) -- logp(x) = -1.408 +/- 0.014
Evaluate (epoch 79) -- logp(x) = -1.461 +/- 0.014
Evaluate (epoch 80) -- logp(x) = -1.438 +/- 0.014
Evaluate (epoch 81) -- logp(x) = -1.368 +/- 0.014
Evaluate (epoch 82) -- logp(x) = -1.438 +/- 0.015
Evaluate (epoch 83) -- logp(x) = -1.381 +/- 0.014
Evaluate (epoch 84) -- logp(x) = -1.621 +/- 0.015
Evaluate (epoch 85) -- logp(x) = -1.343 +/- 0.014
Evaluate (epoch 86) -- logp(x) = -1.325 +/- 0.015
Evaluate (epoch 87) -- logp(x) = -1.336 +/- 0.014
Evaluate (epoch 88) -- logp(x) = -1.383 +/- 0.014
Evaluate (epoch 89) -- logp(x) = -1.325 +/- 0.015
Evaluate (epoch 90) -- logp(x) = -1.346 +/- 0.014
Evaluate (epoch 91) -- logp(x) = -1.362 +/- 0.014
Evaluate (epoch 92) -- logp(x) = -1.372 +/- 0.014
Evaluate (epoch 93) -- logp(x) = -1.393 +/- 0.014
Evaluate (epoch 94) -- logp(x) = -1.263 +/- 0.015
Evaluate (epoch 95) -- logp(x) = -1.364 +/- 0.015
Evaluate (epoch 96) -- logp(x) = -1.331 +/- 0.013
Evaluate (epoch 97) -- logp(x) = -1.386 +/- 0.014
Evaluate (epoch 98) -- logp(x) = -1.360 +/- 0.014
Evaluate (epoch 99) -- logp(x) = -1.327 +/- 0.014
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 100,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
Evaluate (epoch 0) -- logp(x) = -1.005 +/- 0.018
Evaluate (epoch 1) -- logp(x) = -0.982 +/- 0.017
Evaluate (epoch 2) -- logp(x) = -0.962 +/- 0.017
Evaluate (epoch 3) -- logp(x) = -0.943 +/- 0.017
Evaluate (epoch 4) -- logp(x) = -0.914 +/- 0.017
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': False,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): BatchNorm()
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): BatchNorm()
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (5): BatchNorm()
    (6): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (7): BatchNorm()
    (8): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (9): BatchNorm()
  )
)
Evaluate (epoch 5) -- logp(x) = -0.894 +/- 0.017
Evaluate (epoch 6) -- logp(x) = -0.885 +/- 0.017
Evaluate (epoch 7) -- logp(x) = -0.869 +/- 0.016
Evaluate (epoch 8) -- logp(x) = -0.853 +/- 0.016
Evaluate (epoch 9) -- logp(x) = -0.837 +/- 0.016
Evaluate (epoch 10) -- logp(x) = -0.849 +/- 0.016
Evaluate (epoch 11) -- logp(x) = -0.823 +/- 0.015
Evaluate (epoch 12) -- logp(x) = -0.818 +/- 0.016
Evaluate (epoch 13) -- logp(x) = -0.850 +/- 0.016
Evaluate (epoch 14) -- logp(x) = -0.805 +/- 0.016
Evaluate (epoch 15) -- logp(x) = -0.812 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -0.790 +/- 0.016
Evaluate (epoch 17) -- logp(x) = -0.806 +/- 0.016
Evaluate (epoch 18) -- logp(x) = -0.779 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -0.777 +/- 0.015
Evaluate (epoch 20) -- logp(x) = -0.778 +/- 0.016
Evaluate (epoch 21) -- logp(x) = -0.774 +/- 0.015
Evaluate (epoch 22) -- logp(x) = -0.767 +/- 0.016
Evaluate (epoch 23) -- logp(x) = -0.781 +/- 0.016
Evaluate (epoch 24) -- logp(x) = -0.759 +/- 0.016
Evaluate (epoch 25) -- logp(x) = -0.838 +/- 0.017
Evaluate (epoch 26) -- logp(x) = -0.756 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -0.761 +/- 0.015
Evaluate (epoch 28) -- logp(x) = -0.748 +/- 0.015
Evaluate (epoch 29) -- logp(x) = -0.752 +/- 0.015
Evaluate (epoch 30) -- logp(x) = -0.748 +/- 0.016
Evaluate (epoch 31) -- logp(x) = -0.742 +/- 0.015
Evaluate (epoch 32) -- logp(x) = -0.746 +/- 0.016
Evaluate (epoch 33) -- logp(x) = -0.746 +/- 0.015
Evaluate (epoch 34) -- logp(x) = -0.767 +/- 0.016
Evaluate (epoch 35) -- logp(x) = -0.743 +/- 0.015
Evaluate (epoch 36) -- logp(x) = -0.737 +/- 0.016
Evaluate (epoch 37) -- logp(x) = -0.735 +/- 0.016
Evaluate (epoch 38) -- logp(x) = -0.728 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -0.738 +/- 0.016
Evaluate (epoch 40) -- logp(x) = -0.738 +/- 0.015
Evaluate (epoch 41) -- logp(x) = -0.713 +/- 0.016
Evaluate (epoch 42) -- logp(x) = -0.718 +/- 0.015
Evaluate (epoch 43) -- logp(x) = -0.722 +/- 0.015
Evaluate (epoch 44) -- logp(x) = -0.714 +/- 0.015
Evaluate (epoch 45) -- logp(x) = -0.714 +/- 0.016
Evaluate (epoch 46) -- logp(x) = -0.717 +/- 0.015
Evaluate (epoch 47) -- logp(x) = -0.721 +/- 0.015
Evaluate (epoch 48) -- logp(x) = -0.700 +/- 0.015
Evaluate (epoch 49) -- logp(x) = -0.689 +/- 0.015
Evaluate (epoch 50) -- logp(x) = -0.699 +/- 0.016
Evaluate (epoch 51) -- logp(x) = -0.687 +/- 0.015
Evaluate (epoch 52) -- logp(x) = -0.691 +/- 0.015
Evaluate (epoch 53) -- logp(x) = -0.705 +/- 0.014
Evaluate (epoch 54) -- logp(x) = -0.687 +/- 0.015
Evaluate (epoch 55) -- logp(x) = -0.702 +/- 0.016
Evaluate (epoch 56) -- logp(x) = -0.678 +/- 0.015
Evaluate (epoch 57) -- logp(x) = -0.678 +/- 0.015
Evaluate (epoch 58) -- logp(x) = -0.678 +/- 0.015
Evaluate (epoch 59) -- logp(x) = -0.670 +/- 0.014
Evaluate (epoch 60) -- logp(x) = -0.672 +/- 0.015
Evaluate (epoch 61) -- logp(x) = -0.675 +/- 0.015
Evaluate (epoch 62) -- logp(x) = -0.671 +/- 0.015
Evaluate (epoch 63) -- logp(x) = -0.679 +/- 0.016
Evaluate (epoch 64) -- logp(x) = -0.660 +/- 0.015
Evaluate (epoch 65) -- logp(x) = -0.673 +/- 0.015
Evaluate (epoch 66) -- logp(x) = -0.679 +/- 0.015
Evaluate (epoch 67) -- logp(x) = -0.674 +/- 0.016
Evaluate (epoch 68) -- logp(x) = -0.666 +/- 0.016
Evaluate (epoch 69) -- logp(x) = -0.656 +/- 0.015
Evaluate (epoch 70) -- logp(x) = -0.664 +/- 0.016
Evaluate (epoch 71) -- logp(x) = -0.653 +/- 0.015
Evaluate (epoch 72) -- logp(x) = -0.640 +/- 0.015
Evaluate (epoch 73) -- logp(x) = -0.643 +/- 0.015
Evaluate (epoch 74) -- logp(x) = -0.657 +/- 0.015
Evaluate (epoch 75) -- logp(x) = -0.651 +/- 0.015
Evaluate (epoch 76) -- logp(x) = -0.631 +/- 0.015
Evaluate (epoch 77) -- logp(x) = -0.636 +/- 0.015
Evaluate (epoch 78) -- logp(x) = -0.633 +/- 0.015
Evaluate (epoch 79) -- logp(x) = -0.627 +/- 0.016
Evaluate (epoch 80) -- logp(x) = -0.630 +/- 0.015
Evaluate (epoch 81) -- logp(x) = -0.640 +/- 0.015
Evaluate (epoch 82) -- logp(x) = -0.762 +/- 0.017
Evaluate (epoch 83) -- logp(x) = -0.652 +/- 0.016
Evaluate (epoch 84) -- logp(x) = -0.630 +/- 0.015
Evaluate (epoch 85) -- logp(x) = -0.640 +/- 0.015
Evaluate (epoch 86) -- logp(x) = -0.616 +/- 0.015
Evaluate (epoch 87) -- logp(x) = -0.631 +/- 0.016
Evaluate (epoch 88) -- logp(x) = -0.621 +/- 0.015
Evaluate (epoch 89) -- logp(x) = -0.637 +/- 0.016
Evaluate (epoch 90) -- logp(x) = -0.619 +/- 0.015
Evaluate (epoch 91) -- logp(x) = -0.634 +/- 0.015
Evaluate (epoch 92) -- logp(x) = -0.626 +/- 0.015
Evaluate (epoch 93) -- logp(x) = -0.607 +/- 0.016
Evaluate (epoch 94) -- logp(x) = -0.612 +/- 0.015
Evaluate (epoch 95) -- logp(x) = -0.626 +/- 0.016
Evaluate (epoch 96) -- logp(x) = -0.615 +/- 0.015
Evaluate (epoch 97) -- logp(x) = -0.620 +/- 0.015
Evaluate (epoch 98) -- logp(x) = -0.617 +/- 0.016
Evaluate (epoch 99) -- logp(x) = -0.607 +/- 0.015
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.957 +/- 0.004
Evaluate (epoch 1) -- logp(x) = -1.691 +/- 0.006
Evaluate (epoch 2) -- logp(x) = -0.969 +/- 0.011
Evaluate (epoch 3) -- logp(x) = -0.764 +/- 0.015
Evaluate (epoch 4) -- logp(x) = -0.778 +/- 0.016
Evaluate (epoch 5) -- logp(x) = -0.852 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -0.949 +/- 0.017
Evaluate (epoch 7) -- logp(x) = -0.652 +/- 0.017
Evaluate (epoch 8) -- logp(x) = -0.474 +/- 0.019
Evaluate (epoch 9) -- logp(x) = -0.533 +/- 0.018
Evaluate (epoch 10) -- logp(x) = -0.401 +/- 0.018
Evaluate (epoch 11) -- logp(x) = -0.411 +/- 0.020
Evaluate (epoch 12) -- logp(x) = -1.061 +/- 0.020
Evaluate (epoch 13) -- logp(x) = -0.692 +/- 0.017
Evaluate (epoch 14) -- logp(x) = -0.601 +/- 0.019
Evaluate (epoch 15) -- logp(x) = -0.529 +/- 0.019
Evaluate (epoch 16) -- logp(x) = -0.497 +/- 0.037
Evaluate (epoch 17) -- logp(x) = -0.420 +/- 0.021
Evaluate (epoch 18) -- logp(x) = -0.407 +/- 0.018
Evaluate (epoch 19) -- logp(x) = -0.356 +/- 0.018
Evaluate (epoch 20) -- logp(x) = -0.331 +/- 0.018
Evaluate (epoch 21) -- logp(x) = -0.263 +/- 0.019
Evaluate (epoch 22) -- logp(x) = -0.225 +/- 0.019
Evaluate (epoch 23) -- logp(x) = -0.282 +/- 0.019
Evaluate (epoch 24) -- logp(x) = -0.149 +/- 0.026
Evaluate (epoch 25) -- logp(x) = -0.338 +/- 0.021
Evaluate (epoch 26) -- logp(x) = -0.302 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -2.308 +/- 0.018
Evaluate (epoch 28) -- logp(x) = -1.576 +/- 0.019
Evaluate (epoch 29) -- logp(x) = -0.980 +/- 0.019
Evaluate (epoch 30) -- logp(x) = -0.394 +/- 0.021
Evaluate (epoch 31) -- logp(x) = -0.156 +/- 0.018
Evaluate (epoch 32) -- logp(x) = -0.060 +/- 0.018
Evaluate (epoch 33) -- logp(x) = -0.016 +/- 0.022
Evaluate (epoch 34) -- logp(x) = -0.872 +/- 0.018
Evaluate (epoch 35) -- logp(x) = -0.208 +/- 0.017
Evaluate (epoch 36) -- logp(x) = -0.054 +/- 0.016
Evaluate (epoch 37) -- logp(x) = 0.006 +/- 0.017
Evaluate (epoch 38) -- logp(x) = 0.047 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -0.041 +/- 0.027
Evaluate (epoch 40) -- logp(x) = 0.093 +/- 0.016
Evaluate (epoch 41) -- logp(x) = 0.074 +/- 0.017
Evaluate (epoch 42) -- logp(x) = 0.139 +/- 0.017
Evaluate (epoch 43) -- logp(x) = 0.134 +/- 0.018
Evaluate (epoch 44) -- logp(x) = 0.174 +/- 0.017
Evaluate (epoch 45) -- logp(x) = 0.195 +/- 0.017
Evaluate (epoch 46) -- logp(x) = 0.204 +/- 0.019
Evaluate (epoch 47) -- logp(x) = 0.219 +/- 0.019
Evaluate (epoch 48) -- logp(x) = 0.233 +/- 0.018
Evaluate (epoch 49) -- logp(x) = 0.243 +/- 0.018
Evaluate (epoch 50) -- logp(x) = 0.238 +/- 0.018
Evaluate (epoch 51) -- logp(x) = 0.272 +/- 0.020
Evaluate (epoch 52) -- logp(x) = 0.274 +/- 0.023
Evaluate (epoch 53) -- logp(x) = 0.271 +/- 0.019
Evaluate (epoch 54) -- logp(x) = 0.297 +/- 0.018
Evaluate (epoch 55) -- logp(x) = 0.308 +/- 0.019
Evaluate (epoch 56) -- logp(x) = 0.301 +/- 0.019
Evaluate (epoch 57) -- logp(x) = 0.323 +/- 0.022
Evaluate (epoch 58) -- logp(x) = 0.342 +/- 0.019
Evaluate (epoch 59) -- logp(x) = 0.348 +/- 0.020
Evaluate (epoch 60) -- logp(x) = 0.336 +/- 0.020
Evaluate (epoch 61) -- logp(x) = 0.368 +/- 0.019
Evaluate (epoch 62) -- logp(x) = 0.357 +/- 0.019
Evaluate (epoch 63) -- logp(x) = 0.328 +/- 0.029
Evaluate (epoch 64) -- logp(x) = 0.365 +/- 0.019
Evaluate (epoch 65) -- logp(x) = 0.384 +/- 0.019
Evaluate (epoch 66) -- logp(x) = 0.393 +/- 0.019
Evaluate (epoch 67) -- logp(x) = 0.392 +/- 0.020
Evaluate (epoch 68) -- logp(x) = 0.409 +/- 0.021
Evaluate (epoch 69) -- logp(x) = 0.331 +/- 0.019
Evaluate (epoch 70) -- logp(x) = 0.389 +/- 0.020
Evaluate (epoch 71) -- logp(x) = 0.426 +/- 0.021
Evaluate (epoch 72) -- logp(x) = 0.425 +/- 0.021
Evaluate (epoch 73) -- logp(x) = 0.442 +/- 0.019
Evaluate (epoch 74) -- logp(x) = 0.408 +/- 0.018
Evaluate (epoch 75) -- logp(x) = 0.441 +/- 0.019
Evaluate (epoch 76) -- logp(x) = 0.427 +/- 0.023
Evaluate (epoch 77) -- logp(x) = 0.457 +/- 0.019
Evaluate (epoch 78) -- logp(x) = 0.440 +/- 0.020
Evaluate (epoch 79) -- logp(x) = 0.374 +/- 0.024
Evaluate (epoch 80) -- logp(x) = 0.481 +/- 0.022
Evaluate (epoch 81) -- logp(x) = 0.478 +/- 0.020
Evaluate (epoch 82) -- logp(x) = 0.484 +/- 0.020
Evaluate (epoch 83) -- logp(x) = 0.471 +/- 0.025
Evaluate (epoch 84) -- logp(x) = 0.466 +/- 0.026
Evaluate (epoch 85) -- logp(x) = 0.468 +/- 0.034
Evaluate (epoch 86) -- logp(x) = 0.497 +/- 0.024
Evaluate (epoch 87) -- logp(x) = 0.507 +/- 0.022
Evaluate (epoch 88) -- logp(x) = 0.504 +/- 0.020
Evaluate (epoch 89) -- logp(x) = 0.498 +/- 0.020
Evaluate (epoch 90) -- logp(x) = 0.475 +/- 0.019
Evaluate (epoch 91) -- logp(x) = 0.493 +/- 0.020
Evaluate (epoch 92) -- logp(x) = 0.518 +/- 0.021
Evaluate (epoch 93) -- logp(x) = 0.521 +/- 0.020
Evaluate (epoch 94) -- logp(x) = 0.521 +/- 0.022
Evaluate (epoch 95) -- logp(x) = 0.528 +/- 0.021
Evaluate (epoch 96) -- logp(x) = 0.525 +/- 0.020
Evaluate (epoch 97) -- logp(x) = 0.536 +/- 0.021
Evaluate (epoch 98) -- logp(x) = 0.540 +/- 0.026
Evaluate (epoch 99) -- logp(x) = 0.551 +/- 0.021
Evaluate (epoch 100) -- logp(x) = 0.555 +/- 0.020
Evaluate (epoch 101) -- logp(x) = 0.528 +/- 0.023
Evaluate (epoch 102) -- logp(x) = 0.558 +/- 0.028
Evaluate (epoch 103) -- logp(x) = 0.568 +/- 0.020
Evaluate (epoch 104) -- logp(x) = 0.498 +/- 0.020
Evaluate (epoch 105) -- logp(x) = 0.575 +/- 0.020
Evaluate (epoch 106) -- logp(x) = 0.424 +/- 0.021
Evaluate (epoch 107) -- logp(x) = 0.544 +/- 0.020
Evaluate (epoch 108) -- logp(x) = 0.535 +/- 0.021
Evaluate (epoch 109) -- logp(x) = 0.496 +/- 0.020
Evaluate (epoch 110) -- logp(x) = 0.575 +/- 0.022
Evaluate (epoch 111) -- logp(x) = 0.559 +/- 0.021
Evaluate (epoch 112) -- logp(x) = 0.598 +/- 0.022
Evaluate (epoch 113) -- logp(x) = 0.600 +/- 0.021
Evaluate (epoch 114) -- logp(x) = 0.586 +/- 0.034
Evaluate (epoch 115) -- logp(x) = 0.602 +/- 0.024
Evaluate (epoch 116) -- logp(x) = 0.569 +/- 0.021
Evaluate (epoch 117) -- logp(x) = 0.591 +/- 0.025
Evaluate (epoch 118) -- logp(x) = 0.594 +/- 0.022
Evaluate (epoch 119) -- logp(x) = 0.590 +/- 0.021
Evaluate (epoch 120) -- logp(x) = 0.580 +/- 0.022
Evaluate (epoch 121) -- logp(x) = 0.607 +/- 0.025
Evaluate (epoch 122) -- logp(x) = 0.598 +/- 0.022
Evaluate (epoch 123) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 124) -- logp(x) = 0.608 +/- 0.024
Evaluate (epoch 125) -- logp(x) = 0.601 +/- 0.021
Evaluate (epoch 126) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 127) -- logp(x) = 0.628 +/- 0.021
Evaluate (epoch 128) -- logp(x) = 0.496 +/- 0.031
Evaluate (epoch 129) -- logp(x) = 0.606 +/- 0.026
Evaluate (epoch 130) -- logp(x) = 0.642 +/- 0.021
Evaluate (epoch 131) -- logp(x) = 0.649 +/- 0.024
Evaluate (epoch 132) -- logp(x) = 0.635 +/- 0.021
Evaluate (epoch 133) -- logp(x) = 0.615 +/- 0.023
Evaluate (epoch 134) -- logp(x) = -0.005 +/- 0.034
Evaluate (epoch 135) -- logp(x) = 0.135 +/- 0.022
Evaluate (epoch 136) -- logp(x) = 0.432 +/- 0.019
Evaluate (epoch 137) -- logp(x) = 0.597 +/- 0.023
Evaluate (epoch 138) -- logp(x) = 0.584 +/- 0.023
Evaluate (epoch 139) -- logp(x) = 0.543 +/- 0.023
Evaluate (epoch 140) -- logp(x) = 0.627 +/- 0.022
Evaluate (epoch 141) -- logp(x) = 0.641 +/- 0.024
Evaluate (epoch 142) -- logp(x) = 0.583 +/- 0.023
Evaluate (epoch 143) -- logp(x) = 0.631 +/- 0.022
Evaluate (epoch 144) -- logp(x) = 0.643 +/- 0.025
Evaluate (epoch 145) -- logp(x) = 0.666 +/- 0.023
Evaluate (epoch 146) -- logp(x) = 0.557 +/- 0.081
Evaluate (epoch 147) -- logp(x) = 0.657 +/- 0.022
Evaluate (epoch 148) -- logp(x) = 0.645 +/- 0.023
Evaluate (epoch 149) -- logp(x) = 0.686 +/- 0.022
Evaluate (epoch 150) -- logp(x) = 0.675 +/- 0.023
Evaluate (epoch 151) -- logp(x) = 0.521 +/- 0.023
Evaluate (epoch 152) -- logp(x) = 0.508 +/- 0.030
Evaluate (epoch 153) -- logp(x) = 0.673 +/- 0.022
Evaluate (epoch 154) -- logp(x) = 0.686 +/- 0.023
Evaluate (epoch 155) -- logp(x) = 0.681 +/- 0.026
Evaluate (epoch 156) -- logp(x) = 0.687 +/- 0.025
Evaluate (epoch 157) -- logp(x) = 0.673 +/- 0.033
Evaluate (epoch 158) -- logp(x) = 0.656 +/- 0.025
Evaluate (epoch 159) -- logp(x) = 0.638 +/- 0.023
Evaluate (epoch 160) -- logp(x) = 0.657 +/- 0.027
Evaluate (epoch 161) -- logp(x) = 0.679 +/- 0.021
Evaluate (epoch 162) -- logp(x) = 0.652 +/- 0.021
Evaluate (epoch 163) -- logp(x) = 0.698 +/- 0.022
Evaluate (epoch 164) -- logp(x) = 0.730 +/- 0.022
Evaluate (epoch 165) -- logp(x) = 0.668 +/- 0.026
Evaluate (epoch 166) -- logp(x) = 0.501 +/- 0.022
Evaluate (epoch 167) -- logp(x) = 0.642 +/- 0.025
Evaluate (epoch 168) -- logp(x) = 0.677 +/- 0.024
Evaluate (epoch 169) -- logp(x) = 0.631 +/- 0.023
Evaluate (epoch 170) -- logp(x) = 0.686 +/- 0.024
Evaluate (epoch 171) -- logp(x) = 0.703 +/- 0.027
Evaluate (epoch 172) -- logp(x) = 0.697 +/- 0.023
Evaluate (epoch 173) -- logp(x) = 0.718 +/- 0.024
Evaluate (epoch 174) -- logp(x) = 0.735 +/- 0.022
Evaluate (epoch 175) -- logp(x) = 0.754 +/- 0.022
Evaluate (epoch 176) -- logp(x) = 0.736 +/- 0.026
Evaluate (epoch 177) -- logp(x) = 0.714 +/- 0.026
Evaluate (epoch 178) -- logp(x) = 0.716 +/- 0.024
Evaluate (epoch 179) -- logp(x) = 0.674 +/- 0.024
Evaluate (epoch 180) -- logp(x) = 0.707 +/- 0.026
Evaluate (epoch 181) -- logp(x) = 0.698 +/- 0.028
Evaluate (epoch 182) -- logp(x) = 0.748 +/- 0.027
Evaluate (epoch 183) -- logp(x) = 0.298 +/- 0.029
Evaluate (epoch 184) -- logp(x) = 0.556 +/- 0.024
Evaluate (epoch 185) -- logp(x) = 0.697 +/- 0.028
Evaluate (epoch 186) -- logp(x) = 0.693 +/- 0.026
Evaluate (epoch 187) -- logp(x) = 0.654 +/- 0.023
Evaluate (epoch 188) -- logp(x) = 0.703 +/- 0.024
Evaluate (epoch 189) -- logp(x) = 0.745 +/- 0.029
Evaluate (epoch 190) -- logp(x) = 0.707 +/- 0.026
Evaluate (epoch 191) -- logp(x) = 0.765 +/- 0.025
Evaluate (epoch 192) -- logp(x) = 0.722 +/- 0.023
Evaluate (epoch 193) -- logp(x) = 0.646 +/- 0.024
Evaluate (epoch 194) -- logp(x) = 0.765 +/- 0.024
Evaluate (epoch 195) -- logp(x) = 0.752 +/- 0.026
Evaluate (epoch 196) -- logp(x) = 0.764 +/- 0.026
Evaluate (epoch 197) -- logp(x) = 0.703 +/- 0.030
Evaluate (epoch 198) -- logp(x) = 0.792 +/- 0.024
Evaluate (epoch 199) -- logp(x) = 0.781 +/- 0.024
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.626 +/- 0.013
Evaluate (epoch 1) -- logp(x) = -2.603 +/- 0.012
Evaluate (epoch 2) -- logp(x) = -2.569 +/- 0.012
Evaluate (epoch 3) -- logp(x) = -2.503 +/- 0.012
Evaluate (epoch 4) -- logp(x) = -2.435 +/- 0.011
Evaluate (epoch 5) -- logp(x) = -2.355 +/- 0.011
Evaluate (epoch 6) -- logp(x) = -2.245 +/- 0.011
Evaluate (epoch 7) -- logp(x) = -2.121 +/- 0.012
Evaluate (epoch 8) -- logp(x) = -2.038 +/- 0.013
Evaluate (epoch 9) -- logp(x) = -1.993 +/- 0.013
Evaluate (epoch 10) -- logp(x) = -1.950 +/- 0.013
Evaluate (epoch 11) -- logp(x) = -1.904 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -1.889 +/- 0.015
Evaluate (epoch 13) -- logp(x) = -2.012 +/- 0.014
Evaluate (epoch 14) -- logp(x) = -1.835 +/- 0.015
Evaluate (epoch 15) -- logp(x) = -1.850 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -1.872 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -1.792 +/- 0.017
Evaluate (epoch 18) -- logp(x) = -1.814 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -1.786 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -1.760 +/- 0.015
Evaluate (epoch 21) -- logp(x) = -1.766 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -1.994 +/- 0.014
Evaluate (epoch 23) -- logp(x) = -1.733 +/- 0.016
Evaluate (epoch 24) -- logp(x) = -1.741 +/- 0.017
Evaluate (epoch 25) -- logp(x) = -1.706 +/- 0.016
Evaluate (epoch 26) -- logp(x) = -1.731 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -1.685 +/- 0.016
Evaluate (epoch 28) -- logp(x) = -1.704 +/- 0.016
Evaluate (epoch 29) -- logp(x) = -1.672 +/- 0.017
Evaluate (epoch 30) -- logp(x) = -1.651 +/- 0.017
Evaluate (epoch 31) -- logp(x) = -1.657 +/- 0.016
Evaluate (epoch 32) -- logp(x) = -1.645 +/- 0.017
Evaluate (epoch 33) -- logp(x) = -1.632 +/- 0.017
Evaluate (epoch 34) -- logp(x) = -1.643 +/- 0.016
Evaluate (epoch 35) -- logp(x) = -1.651 +/- 0.017
Evaluate (epoch 36) -- logp(x) = -1.609 +/- 0.016
Evaluate (epoch 37) -- logp(x) = -1.605 +/- 0.017
Evaluate (epoch 38) -- logp(x) = -1.580 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -1.614 +/- 0.016
Evaluate (epoch 40) -- logp(x) = -1.653 +/- 0.016
Evaluate (epoch 41) -- logp(x) = -1.596 +/- 0.020
Evaluate (epoch 42) -- logp(x) = -1.560 +/- 0.024
Evaluate (epoch 43) -- logp(x) = -1.577 +/- 0.017
Evaluate (epoch 44) -- logp(x) = -1.800 +/- 0.014
Evaluate (epoch 45) -- logp(x) = -1.564 +/- 0.017
Evaluate (epoch 46) -- logp(x) = -1.573 +/- 0.017
Evaluate (epoch 47) -- logp(x) = -1.527 +/- 0.016
Evaluate (epoch 48) -- logp(x) = -1.499 +/- 0.017
Evaluate (epoch 49) -- logp(x) = -1.549 +/- 0.021
Evaluate (epoch 50) -- logp(x) = -1.649 +/- 0.016
Evaluate (epoch 51) -- logp(x) = -1.562 +/- 0.016
Evaluate (epoch 52) -- logp(x) = -1.512 +/- 0.022
Evaluate (epoch 53) -- logp(x) = -1.530 +/- 0.016
Evaluate (epoch 54) -- logp(x) = -1.531 +/- 0.016
Evaluate (epoch 55) -- logp(x) = -1.463 +/- 0.017
Evaluate (epoch 56) -- logp(x) = -1.494 +/- 0.017
Evaluate (epoch 57) -- logp(x) = -1.471 +/- 0.017
Evaluate (epoch 58) -- logp(x) = -1.464 +/- 0.017
Evaluate (epoch 59) -- logp(x) = -1.455 +/- 0.017
Evaluate (epoch 60) -- logp(x) = -1.635 +/- 0.015
Evaluate (epoch 61) -- logp(x) = -1.466 +/- 0.021
Evaluate (epoch 62) -- logp(x) = -1.618 +/- 0.023
Evaluate (epoch 63) -- logp(x) = -1.428 +/- 0.017
Evaluate (epoch 64) -- logp(x) = -1.422 +/- 0.017
Evaluate (epoch 65) -- logp(x) = -1.427 +/- 0.022
Evaluate (epoch 66) -- logp(x) = -1.407 +/- 0.017
Evaluate (epoch 67) -- logp(x) = -1.412 +/- 0.017
Evaluate (epoch 68) -- logp(x) = -1.432 +/- 0.017
Evaluate (epoch 69) -- logp(x) = -1.391 +/- 0.018
Evaluate (epoch 70) -- logp(x) = -1.387 +/- 0.019
Evaluate (epoch 71) -- logp(x) = -1.773 +/- 0.048
Evaluate (epoch 72) -- logp(x) = -2.579 +/- 0.014
Evaluate (epoch 73) -- logp(x) = -2.360 +/- 0.013
Evaluate (epoch 74) -- logp(x) = -2.127 +/- 0.013
Evaluate (epoch 75) -- logp(x) = -2.018 +/- 0.014
Evaluate (epoch 76) -- logp(x) = -1.938 +/- 0.014
Evaluate (epoch 77) -- logp(x) = -1.875 +/- 0.015
Evaluate (epoch 78) -- logp(x) = -1.831 +/- 0.013
Evaluate (epoch 79) -- logp(x) = -1.751 +/- 0.014
Evaluate (epoch 80) -- logp(x) = -1.674 +/- 0.014
Evaluate (epoch 81) -- logp(x) = -1.679 +/- 0.014
Evaluate (epoch 82) -- logp(x) = -1.586 +/- 0.014
Evaluate (epoch 83) -- logp(x) = -1.614 +/- 0.014
Evaluate (epoch 84) -- logp(x) = -1.557 +/- 0.015
Evaluate (epoch 85) -- logp(x) = -1.532 +/- 0.015
Evaluate (epoch 86) -- logp(x) = -1.520 +/- 0.015
Evaluate (epoch 87) -- logp(x) = -1.523 +/- 0.016
Evaluate (epoch 88) -- logp(x) = -1.497 +/- 0.016
Evaluate (epoch 89) -- logp(x) = -1.471 +/- 0.016
Evaluate (epoch 90) -- logp(x) = -1.468 +/- 0.016
Evaluate (epoch 91) -- logp(x) = -1.450 +/- 0.016
Evaluate (epoch 92) -- logp(x) = -1.530 +/- 0.015
Evaluate (epoch 93) -- logp(x) = -1.445 +/- 0.016
Evaluate (epoch 94) -- logp(x) = -1.501 +/- 0.017
Evaluate (epoch 95) -- logp(x) = -1.448 +/- 0.017
Evaluate (epoch 96) -- logp(x) = -1.505 +/- 0.016
Evaluate (epoch 97) -- logp(x) = -1.449 +/- 0.017
Evaluate (epoch 98) -- logp(x) = -1.435 +/- 0.017
Evaluate (epoch 99) -- logp(x) = -1.447 +/- 0.017
Evaluate (epoch 100) -- logp(x) = -1.394 +/- 0.017
Evaluate (epoch 101) -- logp(x) = -1.380 +/- 0.018
Evaluate (epoch 102) -- logp(x) = -1.388 +/- 0.018
Evaluate (epoch 103) -- logp(x) = -1.378 +/- 0.017
Evaluate (epoch 104) -- logp(x) = -1.377 +/- 0.018
Evaluate (epoch 105) -- logp(x) = -1.360 +/- 0.018
Evaluate (epoch 106) -- logp(x) = -1.355 +/- 0.018
Evaluate (epoch 107) -- logp(x) = -1.488 +/- 0.017
Evaluate (epoch 108) -- logp(x) = -1.423 +/- 0.017
Evaluate (epoch 109) -- logp(x) = -1.360 +/- 0.018
Evaluate (epoch 110) -- logp(x) = -1.361 +/- 0.018
Evaluate (epoch 111) -- logp(x) = -1.352 +/- 0.018
Evaluate (epoch 112) -- logp(x) = -1.387 +/- 0.029
Evaluate (epoch 113) -- logp(x) = -1.722 +/- 0.019
Evaluate (epoch 114) -- logp(x) = -1.538 +/- 0.017
Evaluate (epoch 115) -- logp(x) = -1.458 +/- 0.018
Evaluate (epoch 116) -- logp(x) = -1.417 +/- 0.018
Evaluate (epoch 117) -- logp(x) = -1.394 +/- 0.017
Evaluate (epoch 118) -- logp(x) = -1.446 +/- 0.018
Evaluate (epoch 119) -- logp(x) = -1.366 +/- 0.018
Evaluate (epoch 120) -- logp(x) = -1.414 +/- 0.034
Evaluate (epoch 121) -- logp(x) = -1.351 +/- 0.018
Evaluate (epoch 122) -- logp(x) = -1.344 +/- 0.019
Evaluate (epoch 123) -- logp(x) = -1.375 +/- 0.018
Evaluate (epoch 124) -- logp(x) = -1.383 +/- 0.018
Evaluate (epoch 125) -- logp(x) = -1.324 +/- 0.018
Evaluate (epoch 126) -- logp(x) = -1.330 +/- 0.019
Evaluate (epoch 127) -- logp(x) = -1.388 +/- 0.019
Evaluate (epoch 128) -- logp(x) = -1.384 +/- 0.018
Evaluate (epoch 129) -- logp(x) = -1.359 +/- 0.018
Evaluate (epoch 130) -- logp(x) = -1.346 +/- 0.020
Evaluate (epoch 131) -- logp(x) = -1.335 +/- 0.020
Evaluate (epoch 132) -- logp(x) = -1.302 +/- 0.018
Evaluate (epoch 133) -- logp(x) = -1.301 +/- 0.020
Evaluate (epoch 134) -- logp(x) = -1.289 +/- 0.020
Evaluate (epoch 135) -- logp(x) = -1.351 +/- 0.019
Evaluate (epoch 136) -- logp(x) = -1.308 +/- 0.020
Evaluate (epoch 137) -- logp(x) = -1.367 +/- 0.019
Evaluate (epoch 138) -- logp(x) = -1.295 +/- 0.018
Evaluate (epoch 139) -- logp(x) = -1.307 +/- 0.020
Evaluate (epoch 140) -- logp(x) = -1.285 +/- 0.019
Evaluate (epoch 141) -- logp(x) = -1.313 +/- 0.019
Evaluate (epoch 142) -- logp(x) = -1.328 +/- 0.019
Evaluate (epoch 143) -- logp(x) = -1.369 +/- 0.018
Evaluate (epoch 144) -- logp(x) = -1.279 +/- 0.018
Evaluate (epoch 145) -- logp(x) = -1.297 +/- 0.019
Evaluate (epoch 146) -- logp(x) = -1.405 +/- 0.018
Evaluate (epoch 147) -- logp(x) = -1.392 +/- 0.018
Evaluate (epoch 148) -- logp(x) = -1.284 +/- 0.020
Evaluate (epoch 149) -- logp(x) = -1.332 +/- 0.020
Evaluate (epoch 150) -- logp(x) = -1.291 +/- 0.019
Evaluate (epoch 151) -- logp(x) = -1.259 +/- 0.018
Evaluate (epoch 152) -- logp(x) = -1.339 +/- 0.019
Evaluate (epoch 153) -- logp(x) = -1.295 +/- 0.018
Evaluate (epoch 154) -- logp(x) = -1.277 +/- 0.018
Evaluate (epoch 155) -- logp(x) = -1.254 +/- 0.020
Evaluate (epoch 156) -- logp(x) = -1.822 +/- 0.015
Evaluate (epoch 157) -- logp(x) = -1.533 +/- 0.019
Evaluate (epoch 158) -- logp(x) = -1.550 +/- 0.017
Evaluate (epoch 159) -- logp(x) = -1.464 +/- 0.018
Evaluate (epoch 160) -- logp(x) = -1.416 +/- 0.020
Evaluate (epoch 161) -- logp(x) = -1.369 +/- 0.019
Evaluate (epoch 162) -- logp(x) = -1.481 +/- 0.072
Evaluate (epoch 163) -- logp(x) = -1.793 +/- 0.017
Evaluate (epoch 164) -- logp(x) = -1.606 +/- 0.019
Evaluate (epoch 165) -- logp(x) = -1.476 +/- 0.016
Evaluate (epoch 166) -- logp(x) = -1.368 +/- 0.016
Evaluate (epoch 167) -- logp(x) = -1.344 +/- 0.016
Evaluate (epoch 168) -- logp(x) = -1.300 +/- 0.017
Evaluate (epoch 169) -- logp(x) = -1.303 +/- 0.017
Evaluate (epoch 170) -- logp(x) = -1.316 +/- 0.018
Evaluate (epoch 171) -- logp(x) = -1.249 +/- 0.018
Evaluate (epoch 172) -- logp(x) = -1.419 +/- 0.018
Evaluate (epoch 173) -- logp(x) = -1.339 +/- 0.019
Evaluate (epoch 174) -- logp(x) = -1.427 +/- 0.018
Evaluate (epoch 175) -- logp(x) = -1.290 +/- 0.018
Evaluate (epoch 176) -- logp(x) = -1.317 +/- 0.019
Evaluate (epoch 177) -- logp(x) = -1.563 +/- 0.015
Evaluate (epoch 178) -- logp(x) = -1.250 +/- 0.022
Evaluate (epoch 179) -- logp(x) = -1.362 +/- 0.018
Evaluate (epoch 180) -- logp(x) = -1.299 +/- 0.018
Evaluate (epoch 181) -- logp(x) = -1.648 +/- 0.015
Evaluate (epoch 182) -- logp(x) = -1.248 +/- 0.018
Evaluate (epoch 183) -- logp(x) = -1.264 +/- 0.019
Evaluate (epoch 184) -- logp(x) = -1.246 +/- 0.019
Evaluate (epoch 185) -- logp(x) = -1.420 +/- 0.017
Evaluate (epoch 186) -- logp(x) = -1.289 +/- 0.016
Evaluate (epoch 187) -- logp(x) = -1.359 +/- 0.017
Evaluate (epoch 188) -- logp(x) = -1.286 +/- 0.018
Evaluate (epoch 189) -- logp(x) = -1.236 +/- 0.071
Evaluate (epoch 190) -- logp(x) = -1.456 +/- 0.016
Evaluate (epoch 191) -- logp(x) = -1.260 +/- 0.019
Evaluate (epoch 192) -- logp(x) = -1.343 +/- 0.016
Evaluate (epoch 193) -- logp(x) = -1.257 +/- 0.018
Evaluate (epoch 194) -- logp(x) = -1.349 +/- 0.018
Evaluate (epoch 195) -- logp(x) = -1.223 +/- 0.018
Evaluate (epoch 196) -- logp(x) = -1.592 +/- 0.017
Evaluate (epoch 197) -- logp(x) = -1.445 +/- 0.017
Evaluate (epoch 198) -- logp(x) = -1.260 +/- 0.016
Evaluate (epoch 199) -- logp(x) = -1.211 +/- 0.018
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.020 +/- 0.016
Evaluate (epoch 1) -- logp(x) = -1.000 +/- 0.016
Evaluate (epoch 2) -- logp(x) = -0.986 +/- 0.016
Evaluate (epoch 3) -- logp(x) = -0.970 +/- 0.017
Evaluate (epoch 4) -- logp(x) = -0.955 +/- 0.016
Evaluate (epoch 5) -- logp(x) = -0.938 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -0.918 +/- 0.015
Evaluate (epoch 7) -- logp(x) = -0.888 +/- 0.015
Evaluate (epoch 8) -- logp(x) = -0.850 +/- 0.014
Evaluate (epoch 9) -- logp(x) = -0.821 +/- 0.014
Evaluate (epoch 10) -- logp(x) = -0.811 +/- 0.014
Evaluate (epoch 11) -- logp(x) = -0.798 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -0.777 +/- 0.014
Evaluate (epoch 13) -- logp(x) = -0.774 +/- 0.015
Evaluate (epoch 14) -- logp(x) = -0.786 +/- 0.014
Evaluate (epoch 15) -- logp(x) = -0.769 +/- 0.014
Evaluate (epoch 16) -- logp(x) = -0.749 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -0.758 +/- 0.015
Evaluate (epoch 18) -- logp(x) = -0.796 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -0.740 +/- 0.015
Evaluate (epoch 20) -- logp(x) = -0.799 +/- 0.016
Evaluate (epoch 21) -- logp(x) = -0.755 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -0.729 +/- 0.015
Evaluate (epoch 23) -- logp(x) = -0.745 +/- 0.014
Evaluate (epoch 24) -- logp(x) = -0.720 +/- 0.015
Evaluate (epoch 25) -- logp(x) = -0.769 +/- 0.015
Evaluate (epoch 26) -- logp(x) = -0.802 +/- 0.025
Evaluate (epoch 27) -- logp(x) = -0.726 +/- 0.016
Evaluate (epoch 28) -- logp(x) = -0.780 +/- 0.129
Evaluate (epoch 29) -- logp(x) = -0.706 +/- 0.015
Evaluate (epoch 30) -- logp(x) = -0.704 +/- 0.015
Evaluate (epoch 31) -- logp(x) = -0.735 +/- 0.016
Evaluate (epoch 32) -- logp(x) = -0.711 +/- 0.016
Evaluate (epoch 33) -- logp(x) = -0.777 +/- 0.017
Evaluate (epoch 34) -- logp(x) = -0.747 +/- 0.016
Evaluate (epoch 35) -- logp(x) = -0.740 +/- 0.016
Evaluate (epoch 36) -- logp(x) = -0.716 +/- 0.016
Evaluate (epoch 37) -- logp(x) = -0.718 +/- 0.016
Evaluate (epoch 38) -- logp(x) = -0.708 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -0.694 +/- 0.016
Evaluate (epoch 40) -- logp(x) = -0.697 +/- 0.016
Evaluate (epoch 41) -- logp(x) = -0.688 +/- 0.017
Evaluate (epoch 42) -- logp(x) = -0.687 +/- 0.017
Evaluate (epoch 43) -- logp(x) = -0.683 +/- 0.017
Evaluate (epoch 44) -- logp(x) = -0.684 +/- 0.017
Evaluate (epoch 45) -- logp(x) = -0.682 +/- 0.019
Evaluate (epoch 46) -- logp(x) = -0.681 +/- 0.017
Evaluate (epoch 47) -- logp(x) = -0.678 +/- 0.017
Evaluate (epoch 48) -- logp(x) = -0.719 +/- 0.016
Evaluate (epoch 49) -- logp(x) = -0.690 +/- 0.018
Evaluate (epoch 50) -- logp(x) = -0.670 +/- 0.017
Evaluate (epoch 51) -- logp(x) = -0.672 +/- 0.019
Evaluate (epoch 52) -- logp(x) = -0.653 +/- 0.018
Evaluate (epoch 53) -- logp(x) = -0.667 +/- 0.017
Evaluate (epoch 54) -- logp(x) = -0.696 +/- 0.017
Evaluate (epoch 55) -- logp(x) = -0.660 +/- 0.018
Evaluate (epoch 56) -- logp(x) = -0.704 +/- 0.018
Evaluate (epoch 57) -- logp(x) = -0.669 +/- 0.021
Evaluate (epoch 58) -- logp(x) = -0.659 +/- 0.019
Evaluate (epoch 59) -- logp(x) = -1.302 +/- 0.061
Evaluate (epoch 60) -- logp(x) = -0.944 +/- 0.019
Evaluate (epoch 61) -- logp(x) = -0.850 +/- 0.019
Evaluate (epoch 62) -- logp(x) = -0.732 +/- 0.019
Evaluate (epoch 63) -- logp(x) = -0.702 +/- 0.019
Evaluate (epoch 64) -- logp(x) = -0.671 +/- 0.019
Evaluate (epoch 65) -- logp(x) = -0.670 +/- 0.018
Evaluate (epoch 66) -- logp(x) = -0.688 +/- 0.018
Evaluate (epoch 67) -- logp(x) = -0.715 +/- 0.019
Evaluate (epoch 68) -- logp(x) = -0.666 +/- 0.019
Evaluate (epoch 69) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 70) -- logp(x) = -0.659 +/- 0.018
Evaluate (epoch 71) -- logp(x) = -0.738 +/- 0.018
Evaluate (epoch 72) -- logp(x) = -0.657 +/- 0.018
Evaluate (epoch 73) -- logp(x) = -0.642 +/- 0.018
Evaluate (epoch 74) -- logp(x) = -0.641 +/- 0.019
Evaluate (epoch 75) -- logp(x) = -0.654 +/- 0.019
Evaluate (epoch 76) -- logp(x) = -0.628 +/- 0.019
Evaluate (epoch 77) -- logp(x) = -0.630 +/- 0.019
Evaluate (epoch 78) -- logp(x) = -0.694 +/- 0.020
Evaluate (epoch 79) -- logp(x) = -0.638 +/- 0.019
Evaluate (epoch 80) -- logp(x) = -0.638 +/- 0.019
Evaluate (epoch 81) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 82) -- logp(x) = -0.634 +/- 0.019
Evaluate (epoch 83) -- logp(x) = -0.631 +/- 0.019
Evaluate (epoch 84) -- logp(x) = -0.625 +/- 0.019
Evaluate (epoch 85) -- logp(x) = -0.603 +/- 0.019
Evaluate (epoch 86) -- logp(x) = -0.695 +/- 0.023
Evaluate (epoch 87) -- logp(x) = -0.855 +/- 0.018
Evaluate (epoch 88) -- logp(x) = -0.766 +/- 0.020
Evaluate (epoch 89) -- logp(x) = -0.703 +/- 0.019
Evaluate (epoch 90) -- logp(x) = -33180.270 +/- 50675.902
Evaluate (epoch 91) -- logp(x) = -0.944 +/- 0.018
Evaluate (epoch 92) -- logp(x) = -0.869 +/- 0.018
Evaluate (epoch 93) -- logp(x) = -0.824 +/- 0.018
Evaluate (epoch 94) -- logp(x) = -0.800 +/- 0.019
Evaluate (epoch 95) -- logp(x) = -0.780 +/- 0.019
Evaluate (epoch 96) -- logp(x) = -0.767 +/- 0.019
Evaluate (epoch 97) -- logp(x) = -0.760 +/- 0.020
Evaluate (epoch 98) -- logp(x) = -0.742 +/- 0.019
Evaluate (epoch 99) -- logp(x) = -0.737 +/- 0.020
Evaluate (epoch 100) -- logp(x) = -0.726 +/- 0.020
Evaluate (epoch 101) -- logp(x) = -0.721 +/- 0.020
Evaluate (epoch 102) -- logp(x) = -0.705 +/- 0.020
Evaluate (epoch 103) -- logp(x) = -0.694 +/- 0.020
Evaluate (epoch 104) -- logp(x) = -0.686 +/- 0.020
Evaluate (epoch 105) -- logp(x) = -0.680 +/- 0.020
Evaluate (epoch 106) -- logp(x) = -0.696 +/- 0.019
Evaluate (epoch 107) -- logp(x) = -0.672 +/- 0.020
Evaluate (epoch 108) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 109) -- logp(x) = -0.675 +/- 0.021
Evaluate (epoch 110) -- logp(x) = -0.671 +/- 0.020
Evaluate (epoch 111) -- logp(x) = -0.668 +/- 0.020
Evaluate (epoch 112) -- logp(x) = -0.688 +/- 0.020
Evaluate (epoch 113) -- logp(x) = -0.661 +/- 0.020
Evaluate (epoch 114) -- logp(x) = -0.660 +/- 0.020
Evaluate (epoch 115) -- logp(x) = -0.661 +/- 0.021
Evaluate (epoch 116) -- logp(x) = -0.652 +/- 0.020
Evaluate (epoch 117) -- logp(x) = -0.651 +/- 0.020
Evaluate (epoch 118) -- logp(x) = -0.644 +/- 0.020
Evaluate (epoch 119) -- logp(x) = -0.680 +/- 0.023
Evaluate (epoch 120) -- logp(x) = -0.647 +/- 0.020
Evaluate (epoch 121) -- logp(x) = -0.640 +/- 0.021
Evaluate (epoch 122) -- logp(x) = -0.646 +/- 0.020
Evaluate (epoch 123) -- logp(x) = -0.650 +/- 0.020
Evaluate (epoch 124) -- logp(x) = -0.644 +/- 0.021
Evaluate (epoch 125) -- logp(x) = -0.636 +/- 0.020
Evaluate (epoch 126) -- logp(x) = -0.672 +/- 0.020
Evaluate (epoch 127) -- logp(x) = -0.646 +/- 0.020
Evaluate (epoch 128) -- logp(x) = -0.661 +/- 0.020
Evaluate (epoch 129) -- logp(x) = -0.639 +/- 0.020
Evaluate (epoch 130) -- logp(x) = -0.642 +/- 0.020
Evaluate (epoch 131) -- logp(x) = -0.636 +/- 0.020
Evaluate (epoch 132) -- logp(x) = -0.666 +/- 0.021
Evaluate (epoch 133) -- logp(x) = -0.626 +/- 0.020
Evaluate (epoch 134) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 135) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 136) -- logp(x) = -0.627 +/- 0.019
Evaluate (epoch 137) -- logp(x) = -0.658 +/- 0.021
Evaluate (epoch 138) -- logp(x) = -0.637 +/- 0.021
Evaluate (epoch 139) -- logp(x) = -0.616 +/- 0.021
Evaluate (epoch 140) -- logp(x) = -0.615 +/- 0.020
Evaluate (epoch 141) -- logp(x) = -0.873 +/- 0.022
Evaluate (epoch 142) -- logp(x) = -0.747 +/- 0.022
Evaluate (epoch 143) -- logp(x) = -0.701 +/- 0.021
Evaluate (epoch 144) -- logp(x) = -0.684 +/- 0.021
Evaluate (epoch 145) -- logp(x) = -0.671 +/- 0.021
Evaluate (epoch 146) -- logp(x) = -0.663 +/- 0.021
Evaluate (epoch 147) -- logp(x) = -0.664 +/- 0.021
Evaluate (epoch 148) -- logp(x) = -0.654 +/- 0.021
Evaluate (epoch 149) -- logp(x) = -0.665 +/- 0.021
Evaluate (epoch 150) -- logp(x) = -0.654 +/- 0.021
Evaluate (epoch 151) -- logp(x) = -0.647 +/- 0.020
Evaluate (epoch 152) -- logp(x) = -0.642 +/- 0.021
Evaluate (epoch 153) -- logp(x) = -0.637 +/- 0.021
Evaluate (epoch 154) -- logp(x) = -0.658 +/- 0.021
Evaluate (epoch 155) -- logp(x) = -0.633 +/- 0.020
Evaluate (epoch 156) -- logp(x) = -0.629 +/- 0.020
Evaluate (epoch 157) -- logp(x) = -0.638 +/- 0.020
Evaluate (epoch 158) -- logp(x) = -0.622 +/- 0.021
Evaluate (epoch 159) -- logp(x) = -0.617 +/- 0.020
Evaluate (epoch 160) -- logp(x) = -0.613 +/- 0.021
Evaluate (epoch 161) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 162) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 163) -- logp(x) = -0.607 +/- 0.020
Evaluate (epoch 164) -- logp(x) = -0.696 +/- 0.020
Evaluate (epoch 165) -- logp(x) = -0.684 +/- 0.021
Evaluate (epoch 166) -- logp(x) = -0.656 +/- 0.020
Evaluate (epoch 167) -- logp(x) = -0.641 +/- 0.020
Evaluate (epoch 168) -- logp(x) = -0.630 +/- 0.020
Evaluate (epoch 169) -- logp(x) = -0.619 +/- 0.020
Evaluate (epoch 170) -- logp(x) = -0.610 +/- 0.020
Evaluate (epoch 171) -- logp(x) = -0.603 +/- 0.020
Evaluate (epoch 172) -- logp(x) = -0.596 +/- 0.020
Evaluate (epoch 173) -- logp(x) = -0.591 +/- 0.020
Evaluate (epoch 174) -- logp(x) = -0.585 +/- 0.020
Evaluate (epoch 175) -- logp(x) = -0.584 +/- 0.020
Evaluate (epoch 176) -- logp(x) = -0.583 +/- 0.020
Evaluate (epoch 177) -- logp(x) = -0.574 +/- 0.020
Evaluate (epoch 178) -- logp(x) = -0.568 +/- 0.020
Evaluate (epoch 179) -- logp(x) = -0.572 +/- 0.020
Evaluate (epoch 180) -- logp(x) = -0.562 +/- 0.020
Evaluate (epoch 181) -- logp(x) = -0.557 +/- 0.020
Evaluate (epoch 182) -- logp(x) = -0.561 +/- 0.020
Evaluate (epoch 183) -- logp(x) = -0.555 +/- 0.021
Evaluate (epoch 184) -- logp(x) = -0.548 +/- 0.020
Evaluate (epoch 185) -- logp(x) = -0.547 +/- 0.020
Evaluate (epoch 186) -- logp(x) = -0.545 +/- 0.020
Evaluate (epoch 187) -- logp(x) = -0.539 +/- 0.021
Evaluate (epoch 188) -- logp(x) = -0.556 +/- 0.024
Evaluate (epoch 189) -- logp(x) = -0.558 +/- 0.020
Evaluate (epoch 190) -- logp(x) = -0.534 +/- 0.020
Evaluate (epoch 191) -- logp(x) = -0.535 +/- 0.020
Evaluate (epoch 192) -- logp(x) = -0.525 +/- 0.020
Evaluate (epoch 193) -- logp(x) = -0.529 +/- 0.021
Evaluate (epoch 194) -- logp(x) = -0.555 +/- 0.020
Evaluate (epoch 195) -- logp(x) = -0.521 +/- 0.021
Evaluate (epoch 196) -- logp(x) = -0.515 +/- 0.021
Evaluate (epoch 197) -- logp(x) = -0.523 +/- 0.021
Evaluate (epoch 198) -- logp(x) = -0.525 +/- 0.021
Evaluate (epoch 199) -- logp(x) = -0.848 +/- 0.038
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.957 +/- 0.004
Evaluate (epoch 1) -- logp(x) = -1.691 +/- 0.006
Evaluate (epoch 2) -- logp(x) = -0.969 +/- 0.011
Evaluate (epoch 3) -- logp(x) = -0.764 +/- 0.015
Evaluate (epoch 4) -- logp(x) = -0.778 +/- 0.016
Evaluate (epoch 5) -- logp(x) = -0.852 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -0.949 +/- 0.017
Evaluate (epoch 7) -- logp(x) = -0.652 +/- 0.017
Evaluate (epoch 8) -- logp(x) = -0.474 +/- 0.019
Evaluate (epoch 9) -- logp(x) = -0.533 +/- 0.018
Evaluate (epoch 10) -- logp(x) = -0.401 +/- 0.018
Evaluate (epoch 11) -- logp(x) = -0.411 +/- 0.020
Evaluate (epoch 12) -- logp(x) = -1.061 +/- 0.020
Evaluate (epoch 13) -- logp(x) = -0.692 +/- 0.017
Evaluate (epoch 14) -- logp(x) = -0.601 +/- 0.019
Evaluate (epoch 15) -- logp(x) = -0.529 +/- 0.019
Evaluate (epoch 16) -- logp(x) = -0.497 +/- 0.037
Evaluate (epoch 17) -- logp(x) = -0.420 +/- 0.021
Evaluate (epoch 18) -- logp(x) = -0.407 +/- 0.018
Evaluate (epoch 19) -- logp(x) = -0.356 +/- 0.018
Evaluate (epoch 20) -- logp(x) = -0.331 +/- 0.018
Evaluate (epoch 21) -- logp(x) = -0.263 +/- 0.019
Evaluate (epoch 22) -- logp(x) = -0.225 +/- 0.019
Evaluate (epoch 23) -- logp(x) = -0.282 +/- 0.019
Evaluate (epoch 24) -- logp(x) = -0.149 +/- 0.026
Evaluate (epoch 25) -- logp(x) = -0.338 +/- 0.021
Evaluate (epoch 26) -- logp(x) = -0.302 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -2.308 +/- 0.018
Evaluate (epoch 28) -- logp(x) = -1.576 +/- 0.019
Evaluate (epoch 29) -- logp(x) = -0.980 +/- 0.019
Evaluate (epoch 30) -- logp(x) = -0.394 +/- 0.021
Evaluate (epoch 31) -- logp(x) = -0.156 +/- 0.018
Evaluate (epoch 32) -- logp(x) = -0.060 +/- 0.018
Evaluate (epoch 33) -- logp(x) = -0.016 +/- 0.022
Evaluate (epoch 34) -- logp(x) = -0.872 +/- 0.018
Evaluate (epoch 35) -- logp(x) = -0.208 +/- 0.017
Evaluate (epoch 36) -- logp(x) = -0.054 +/- 0.016
Evaluate (epoch 37) -- logp(x) = 0.006 +/- 0.017
Evaluate (epoch 38) -- logp(x) = 0.047 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -0.041 +/- 0.027
Evaluate (epoch 40) -- logp(x) = 0.093 +/- 0.016
Evaluate (epoch 41) -- logp(x) = 0.074 +/- 0.017
Evaluate (epoch 42) -- logp(x) = 0.139 +/- 0.017
Evaluate (epoch 43) -- logp(x) = 0.134 +/- 0.018
Evaluate (epoch 44) -- logp(x) = 0.174 +/- 0.017
Evaluate (epoch 45) -- logp(x) = 0.195 +/- 0.017
Evaluate (epoch 46) -- logp(x) = 0.204 +/- 0.019
Evaluate (epoch 47) -- logp(x) = 0.219 +/- 0.019
Evaluate (epoch 48) -- logp(x) = 0.233 +/- 0.018
Evaluate (epoch 49) -- logp(x) = 0.243 +/- 0.018
Evaluate (epoch 50) -- logp(x) = 0.238 +/- 0.018
Evaluate (epoch 51) -- logp(x) = 0.272 +/- 0.020
Evaluate (epoch 52) -- logp(x) = 0.274 +/- 0.023
Evaluate (epoch 53) -- logp(x) = 0.271 +/- 0.019
Evaluate (epoch 54) -- logp(x) = 0.297 +/- 0.018
Evaluate (epoch 55) -- logp(x) = 0.308 +/- 0.019
Evaluate (epoch 56) -- logp(x) = 0.301 +/- 0.019
Evaluate (epoch 57) -- logp(x) = 0.323 +/- 0.022
Evaluate (epoch 58) -- logp(x) = 0.342 +/- 0.019
Evaluate (epoch 59) -- logp(x) = 0.348 +/- 0.020
Evaluate (epoch 60) -- logp(x) = 0.336 +/- 0.020
Evaluate (epoch 61) -- logp(x) = 0.368 +/- 0.019
Evaluate (epoch 62) -- logp(x) = 0.357 +/- 0.019
Evaluate (epoch 63) -- logp(x) = 0.328 +/- 0.029
Evaluate (epoch 64) -- logp(x) = 0.365 +/- 0.019
Evaluate (epoch 65) -- logp(x) = 0.384 +/- 0.019
Evaluate (epoch 66) -- logp(x) = 0.393 +/- 0.019
Evaluate (epoch 67) -- logp(x) = 0.392 +/- 0.020
Evaluate (epoch 68) -- logp(x) = 0.409 +/- 0.021
Evaluate (epoch 69) -- logp(x) = 0.331 +/- 0.019
Evaluate (epoch 70) -- logp(x) = 0.389 +/- 0.020
Evaluate (epoch 71) -- logp(x) = 0.426 +/- 0.021
Evaluate (epoch 72) -- logp(x) = 0.425 +/- 0.021
Evaluate (epoch 73) -- logp(x) = 0.442 +/- 0.019
Evaluate (epoch 74) -- logp(x) = 0.408 +/- 0.018
Evaluate (epoch 75) -- logp(x) = 0.441 +/- 0.019
Evaluate (epoch 76) -- logp(x) = 0.427 +/- 0.023
Evaluate (epoch 77) -- logp(x) = 0.457 +/- 0.019
Evaluate (epoch 78) -- logp(x) = 0.440 +/- 0.020
Evaluate (epoch 79) -- logp(x) = 0.374 +/- 0.024
Evaluate (epoch 80) -- logp(x) = 0.481 +/- 0.022
Evaluate (epoch 81) -- logp(x) = 0.478 +/- 0.020
Evaluate (epoch 82) -- logp(x) = 0.484 +/- 0.020
Evaluate (epoch 83) -- logp(x) = 0.471 +/- 0.025
Evaluate (epoch 84) -- logp(x) = 0.466 +/- 0.026
Evaluate (epoch 85) -- logp(x) = 0.468 +/- 0.034
Evaluate (epoch 86) -- logp(x) = 0.497 +/- 0.024
Evaluate (epoch 87) -- logp(x) = 0.507 +/- 0.022
Evaluate (epoch 88) -- logp(x) = 0.504 +/- 0.020
Evaluate (epoch 89) -- logp(x) = 0.498 +/- 0.020
Evaluate (epoch 90) -- logp(x) = 0.475 +/- 0.019
Evaluate (epoch 91) -- logp(x) = 0.493 +/- 0.020
Evaluate (epoch 92) -- logp(x) = 0.518 +/- 0.021
Evaluate (epoch 93) -- logp(x) = 0.521 +/- 0.020
Evaluate (epoch 94) -- logp(x) = 0.521 +/- 0.022
Evaluate (epoch 95) -- logp(x) = 0.528 +/- 0.021
Evaluate (epoch 96) -- logp(x) = 0.525 +/- 0.020
Evaluate (epoch 97) -- logp(x) = 0.536 +/- 0.021
Evaluate (epoch 98) -- logp(x) = 0.540 +/- 0.026
Evaluate (epoch 99) -- logp(x) = 0.551 +/- 0.021
Evaluate (epoch 100) -- logp(x) = 0.555 +/- 0.020
Evaluate (epoch 101) -- logp(x) = 0.528 +/- 0.023
Evaluate (epoch 102) -- logp(x) = 0.558 +/- 0.028
Evaluate (epoch 103) -- logp(x) = 0.568 +/- 0.020
Evaluate (epoch 104) -- logp(x) = 0.498 +/- 0.020
Evaluate (epoch 105) -- logp(x) = 0.575 +/- 0.020
Evaluate (epoch 106) -- logp(x) = 0.424 +/- 0.021
Evaluate (epoch 107) -- logp(x) = 0.544 +/- 0.020
Evaluate (epoch 108) -- logp(x) = 0.535 +/- 0.021
Evaluate (epoch 109) -- logp(x) = 0.496 +/- 0.020
Evaluate (epoch 110) -- logp(x) = 0.575 +/- 0.022
Evaluate (epoch 111) -- logp(x) = 0.559 +/- 0.021
Evaluate (epoch 112) -- logp(x) = 0.598 +/- 0.022
Evaluate (epoch 113) -- logp(x) = 0.600 +/- 0.021
Evaluate (epoch 114) -- logp(x) = 0.586 +/- 0.034
Evaluate (epoch 115) -- logp(x) = 0.602 +/- 0.024
Evaluate (epoch 116) -- logp(x) = 0.569 +/- 0.021
Evaluate (epoch 117) -- logp(x) = 0.591 +/- 0.025
Evaluate (epoch 118) -- logp(x) = 0.594 +/- 0.022
Evaluate (epoch 119) -- logp(x) = 0.590 +/- 0.021
Evaluate (epoch 120) -- logp(x) = 0.580 +/- 0.022
Evaluate (epoch 121) -- logp(x) = 0.607 +/- 0.025
Evaluate (epoch 122) -- logp(x) = 0.598 +/- 0.022
Evaluate (epoch 123) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 124) -- logp(x) = 0.608 +/- 0.024
Evaluate (epoch 125) -- logp(x) = 0.601 +/- 0.021
Evaluate (epoch 126) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 127) -- logp(x) = 0.628 +/- 0.021
Evaluate (epoch 128) -- logp(x) = 0.496 +/- 0.031
Evaluate (epoch 129) -- logp(x) = 0.606 +/- 0.026
Evaluate (epoch 130) -- logp(x) = 0.642 +/- 0.021
Evaluate (epoch 131) -- logp(x) = 0.649 +/- 0.024
Evaluate (epoch 132) -- logp(x) = 0.635 +/- 0.021
Evaluate (epoch 133) -- logp(x) = 0.615 +/- 0.023
Evaluate (epoch 134) -- logp(x) = -0.005 +/- 0.034
Evaluate (epoch 135) -- logp(x) = 0.135 +/- 0.022
Evaluate (epoch 136) -- logp(x) = 0.432 +/- 0.019
Evaluate (epoch 137) -- logp(x) = 0.597 +/- 0.023
Evaluate (epoch 138) -- logp(x) = 0.584 +/- 0.023
Evaluate (epoch 139) -- logp(x) = 0.543 +/- 0.023
Evaluate (epoch 140) -- logp(x) = 0.627 +/- 0.022
Evaluate (epoch 141) -- logp(x) = 0.641 +/- 0.024
Evaluate (epoch 142) -- logp(x) = 0.583 +/- 0.023
Evaluate (epoch 143) -- logp(x) = 0.631 +/- 0.022
Evaluate (epoch 144) -- logp(x) = 0.643 +/- 0.025
Evaluate (epoch 145) -- logp(x) = 0.666 +/- 0.023
Evaluate (epoch 146) -- logp(x) = 0.557 +/- 0.081
Evaluate (epoch 147) -- logp(x) = 0.657 +/- 0.022
Evaluate (epoch 148) -- logp(x) = 0.645 +/- 0.023
Evaluate (epoch 149) -- logp(x) = 0.686 +/- 0.022
Evaluate (epoch 150) -- logp(x) = 0.675 +/- 0.023
Evaluate (epoch 151) -- logp(x) = 0.521 +/- 0.023
Evaluate (epoch 152) -- logp(x) = 0.508 +/- 0.030
Evaluate (epoch 153) -- logp(x) = 0.673 +/- 0.022
Evaluate (epoch 154) -- logp(x) = 0.686 +/- 0.023
Evaluate (epoch 155) -- logp(x) = 0.681 +/- 0.026
Evaluate (epoch 156) -- logp(x) = 0.687 +/- 0.025
Evaluate (epoch 157) -- logp(x) = 0.673 +/- 0.033
Evaluate (epoch 158) -- logp(x) = 0.656 +/- 0.025
Evaluate (epoch 159) -- logp(x) = 0.638 +/- 0.023
Evaluate (epoch 160) -- logp(x) = 0.657 +/- 0.027
Evaluate (epoch 161) -- logp(x) = 0.679 +/- 0.021
Evaluate (epoch 162) -- logp(x) = 0.652 +/- 0.021
Evaluate (epoch 163) -- logp(x) = 0.698 +/- 0.022
Evaluate (epoch 164) -- logp(x) = 0.730 +/- 0.022
Evaluate (epoch 165) -- logp(x) = 0.668 +/- 0.026
Evaluate (epoch 166) -- logp(x) = 0.501 +/- 0.022
Evaluate (epoch 167) -- logp(x) = 0.642 +/- 0.025
Evaluate (epoch 168) -- logp(x) = 0.677 +/- 0.024
Evaluate (epoch 169) -- logp(x) = 0.631 +/- 0.023
Evaluate (epoch 170) -- logp(x) = 0.686 +/- 0.024
Evaluate (epoch 171) -- logp(x) = 0.703 +/- 0.027
Evaluate (epoch 172) -- logp(x) = 0.697 +/- 0.023
Evaluate (epoch 173) -- logp(x) = 0.718 +/- 0.024
Evaluate (epoch 174) -- logp(x) = 0.735 +/- 0.022
Evaluate (epoch 175) -- logp(x) = 0.754 +/- 0.022
Evaluate (epoch 176) -- logp(x) = 0.736 +/- 0.026
Evaluate (epoch 177) -- logp(x) = 0.714 +/- 0.026
Evaluate (epoch 178) -- logp(x) = 0.716 +/- 0.024
Evaluate (epoch 179) -- logp(x) = 0.674 +/- 0.024
Evaluate (epoch 180) -- logp(x) = 0.707 +/- 0.026
Evaluate (epoch 181) -- logp(x) = 0.698 +/- 0.028
Evaluate (epoch 182) -- logp(x) = 0.748 +/- 0.027
Evaluate (epoch 183) -- logp(x) = 0.298 +/- 0.029
Evaluate (epoch 184) -- logp(x) = 0.556 +/- 0.024
Evaluate (epoch 185) -- logp(x) = 0.697 +/- 0.028
Evaluate (epoch 186) -- logp(x) = 0.693 +/- 0.026
Evaluate (epoch 187) -- logp(x) = 0.654 +/- 0.023
Evaluate (epoch 188) -- logp(x) = 0.703 +/- 0.024
Evaluate (epoch 189) -- logp(x) = 0.745 +/- 0.029
Evaluate (epoch 190) -- logp(x) = 0.707 +/- 0.026
Evaluate (epoch 191) -- logp(x) = 0.765 +/- 0.025
Evaluate (epoch 192) -- logp(x) = 0.722 +/- 0.023
Evaluate (epoch 193) -- logp(x) = 0.646 +/- 0.024
Evaluate (epoch 194) -- logp(x) = 0.765 +/- 0.024
Evaluate (epoch 195) -- logp(x) = 0.752 +/- 0.026
Evaluate (epoch 196) -- logp(x) = 0.764 +/- 0.026
Evaluate (epoch 197) -- logp(x) = 0.703 +/- 0.030
Evaluate (epoch 198) -- logp(x) = 0.792 +/- 0.024
Evaluate (epoch 199) -- logp(x) = 0.781 +/- 0.024
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': './results/maf/best_model_checkpoint.pt',
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 199,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.626 +/- 0.013
Evaluate (epoch 1) -- logp(x) = -2.603 +/- 0.012
Evaluate (epoch 2) -- logp(x) = -2.569 +/- 0.012
Evaluate (epoch 3) -- logp(x) = -2.503 +/- 0.012
Evaluate (epoch 4) -- logp(x) = -2.435 +/- 0.011
Evaluate (epoch 5) -- logp(x) = -2.355 +/- 0.011
Evaluate (epoch 6) -- logp(x) = -2.245 +/- 0.011
Evaluate (epoch 7) -- logp(x) = -2.121 +/- 0.012
Evaluate (epoch 8) -- logp(x) = -2.038 +/- 0.013
Evaluate (epoch 9) -- logp(x) = -1.993 +/- 0.013
Evaluate (epoch 10) -- logp(x) = -1.950 +/- 0.013
Evaluate (epoch 11) -- logp(x) = -1.904 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -1.889 +/- 0.015
Evaluate (epoch 13) -- logp(x) = -2.012 +/- 0.014
Evaluate (epoch 14) -- logp(x) = -1.835 +/- 0.015
Evaluate (epoch 15) -- logp(x) = -1.850 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -1.872 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -1.792 +/- 0.017
Evaluate (epoch 18) -- logp(x) = -1.814 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -1.786 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -1.760 +/- 0.015
Evaluate (epoch 21) -- logp(x) = -1.766 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -1.994 +/- 0.014
Evaluate (epoch 23) -- logp(x) = -1.733 +/- 0.016
Evaluate (epoch 24) -- logp(x) = -1.741 +/- 0.017
Evaluate (epoch 25) -- logp(x) = -1.706 +/- 0.016
Evaluate (epoch 26) -- logp(x) = -1.731 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -1.685 +/- 0.016
Evaluate (epoch 28) -- logp(x) = -1.704 +/- 0.016
Evaluate (epoch 29) -- logp(x) = -1.672 +/- 0.017
Evaluate (epoch 30) -- logp(x) = -1.651 +/- 0.017
Evaluate (epoch 31) -- logp(x) = -1.657 +/- 0.016
Evaluate (epoch 32) -- logp(x) = -1.645 +/- 0.017
Evaluate (epoch 33) -- logp(x) = -1.632 +/- 0.017
Evaluate (epoch 34) -- logp(x) = -1.643 +/- 0.016
Evaluate (epoch 35) -- logp(x) = -1.651 +/- 0.017
Evaluate (epoch 36) -- logp(x) = -1.609 +/- 0.016
Evaluate (epoch 37) -- logp(x) = -1.605 +/- 0.017
Evaluate (epoch 38) -- logp(x) = -1.580 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -1.614 +/- 0.016
Evaluate (epoch 40) -- logp(x) = -1.653 +/- 0.016
Evaluate (epoch 41) -- logp(x) = -1.596 +/- 0.020
Evaluate (epoch 42) -- logp(x) = -1.560 +/- 0.024
Evaluate (epoch 43) -- logp(x) = -1.577 +/- 0.017
Evaluate (epoch 44) -- logp(x) = -1.800 +/- 0.014
Evaluate (epoch 45) -- logp(x) = -1.564 +/- 0.017
Evaluate (epoch 46) -- logp(x) = -1.573 +/- 0.017
Evaluate (epoch 47) -- logp(x) = -1.527 +/- 0.016
Evaluate (epoch 48) -- logp(x) = -1.499 +/- 0.017
Evaluate (epoch 49) -- logp(x) = -1.549 +/- 0.021
Evaluate (epoch 50) -- logp(x) = -1.649 +/- 0.016
Evaluate (epoch 51) -- logp(x) = -1.562 +/- 0.016
Evaluate (epoch 52) -- logp(x) = -1.512 +/- 0.022
Evaluate (epoch 53) -- logp(x) = -1.530 +/- 0.016
Evaluate (epoch 54) -- logp(x) = -1.531 +/- 0.016
Evaluate (epoch 55) -- logp(x) = -1.463 +/- 0.017
Evaluate (epoch 56) -- logp(x) = -1.494 +/- 0.017
Evaluate (epoch 57) -- logp(x) = -1.471 +/- 0.017
Evaluate (epoch 58) -- logp(x) = -1.464 +/- 0.017
Evaluate (epoch 59) -- logp(x) = -1.455 +/- 0.017
Evaluate (epoch 60) -- logp(x) = -1.635 +/- 0.015
Evaluate (epoch 61) -- logp(x) = -1.466 +/- 0.021
Evaluate (epoch 62) -- logp(x) = -1.618 +/- 0.023
Evaluate (epoch 63) -- logp(x) = -1.428 +/- 0.017
Evaluate (epoch 64) -- logp(x) = -1.422 +/- 0.017
Evaluate (epoch 65) -- logp(x) = -1.427 +/- 0.022
Evaluate (epoch 66) -- logp(x) = -1.407 +/- 0.017
Evaluate (epoch 67) -- logp(x) = -1.412 +/- 0.017
Evaluate (epoch 68) -- logp(x) = -1.432 +/- 0.017
Evaluate (epoch 69) -- logp(x) = -1.391 +/- 0.018
Evaluate (epoch 70) -- logp(x) = -1.387 +/- 0.019
Evaluate (epoch 71) -- logp(x) = -1.773 +/- 0.048
Evaluate (epoch 72) -- logp(x) = -2.579 +/- 0.014
Evaluate (epoch 73) -- logp(x) = -2.360 +/- 0.013
Evaluate (epoch 74) -- logp(x) = -2.127 +/- 0.013
Evaluate (epoch 75) -- logp(x) = -2.018 +/- 0.014
Evaluate (epoch 76) -- logp(x) = -1.938 +/- 0.014
Evaluate (epoch 77) -- logp(x) = -1.875 +/- 0.015
Evaluate (epoch 78) -- logp(x) = -1.831 +/- 0.013
Evaluate (epoch 79) -- logp(x) = -1.751 +/- 0.014
Evaluate (epoch 80) -- logp(x) = -1.674 +/- 0.014
Evaluate (epoch 81) -- logp(x) = -1.679 +/- 0.014
Evaluate (epoch 82) -- logp(x) = -1.586 +/- 0.014
Evaluate (epoch 83) -- logp(x) = -1.614 +/- 0.014
Evaluate (epoch 84) -- logp(x) = -1.557 +/- 0.015
Evaluate (epoch 85) -- logp(x) = -1.532 +/- 0.015
Evaluate (epoch 86) -- logp(x) = -1.520 +/- 0.015
Evaluate (epoch 87) -- logp(x) = -1.523 +/- 0.016
Evaluate (epoch 88) -- logp(x) = -1.497 +/- 0.016
Evaluate (epoch 89) -- logp(x) = -1.471 +/- 0.016
Evaluate (epoch 90) -- logp(x) = -1.468 +/- 0.016
Evaluate (epoch 91) -- logp(x) = -1.450 +/- 0.016
Evaluate (epoch 92) -- logp(x) = -1.530 +/- 0.015
Evaluate (epoch 93) -- logp(x) = -1.445 +/- 0.016
Evaluate (epoch 94) -- logp(x) = -1.501 +/- 0.017
Evaluate (epoch 95) -- logp(x) = -1.448 +/- 0.017
Evaluate (epoch 96) -- logp(x) = -1.505 +/- 0.016
Evaluate (epoch 97) -- logp(x) = -1.449 +/- 0.017
Evaluate (epoch 98) -- logp(x) = -1.435 +/- 0.017
Evaluate (epoch 99) -- logp(x) = -1.447 +/- 0.017
Evaluate (epoch 100) -- logp(x) = -1.394 +/- 0.017
Evaluate (epoch 101) -- logp(x) = -1.380 +/- 0.018
Evaluate (epoch 102) -- logp(x) = -1.388 +/- 0.018
Evaluate (epoch 103) -- logp(x) = -1.378 +/- 0.017
Evaluate (epoch 104) -- logp(x) = -1.377 +/- 0.018
Evaluate (epoch 105) -- logp(x) = -1.360 +/- 0.018
Evaluate (epoch 106) -- logp(x) = -1.355 +/- 0.018
Evaluate (epoch 107) -- logp(x) = -1.488 +/- 0.017
Evaluate (epoch 108) -- logp(x) = -1.423 +/- 0.017
Evaluate (epoch 109) -- logp(x) = -1.360 +/- 0.018
Evaluate (epoch 110) -- logp(x) = -1.361 +/- 0.018
Evaluate (epoch 111) -- logp(x) = -1.352 +/- 0.018
Evaluate (epoch 112) -- logp(x) = -1.387 +/- 0.029
Evaluate (epoch 113) -- logp(x) = -1.722 +/- 0.019
Evaluate (epoch 114) -- logp(x) = -1.538 +/- 0.017
Evaluate (epoch 115) -- logp(x) = -1.458 +/- 0.018
Evaluate (epoch 116) -- logp(x) = -1.417 +/- 0.018
Evaluate (epoch 117) -- logp(x) = -1.394 +/- 0.017
Evaluate (epoch 118) -- logp(x) = -1.446 +/- 0.018
Evaluate (epoch 119) -- logp(x) = -1.366 +/- 0.018
Evaluate (epoch 120) -- logp(x) = -1.414 +/- 0.034
Evaluate (epoch 121) -- logp(x) = -1.351 +/- 0.018
Evaluate (epoch 122) -- logp(x) = -1.344 +/- 0.019
Evaluate (epoch 123) -- logp(x) = -1.375 +/- 0.018
Evaluate (epoch 124) -- logp(x) = -1.383 +/- 0.018
Evaluate (epoch 125) -- logp(x) = -1.324 +/- 0.018
Evaluate (epoch 126) -- logp(x) = -1.330 +/- 0.019
Evaluate (epoch 127) -- logp(x) = -1.388 +/- 0.019
Evaluate (epoch 128) -- logp(x) = -1.384 +/- 0.018
Evaluate (epoch 129) -- logp(x) = -1.359 +/- 0.018
Evaluate (epoch 130) -- logp(x) = -1.346 +/- 0.020
Evaluate (epoch 131) -- logp(x) = -1.335 +/- 0.020
Evaluate (epoch 132) -- logp(x) = -1.302 +/- 0.018
Evaluate (epoch 133) -- logp(x) = -1.301 +/- 0.020
Evaluate (epoch 134) -- logp(x) = -1.289 +/- 0.020
Evaluate (epoch 135) -- logp(x) = -1.351 +/- 0.019
Evaluate (epoch 136) -- logp(x) = -1.308 +/- 0.020
Evaluate (epoch 137) -- logp(x) = -1.367 +/- 0.019
Evaluate (epoch 138) -- logp(x) = -1.295 +/- 0.018
Evaluate (epoch 139) -- logp(x) = -1.307 +/- 0.020
Evaluate (epoch 140) -- logp(x) = -1.285 +/- 0.019
Evaluate (epoch 141) -- logp(x) = -1.313 +/- 0.019
Evaluate (epoch 142) -- logp(x) = -1.328 +/- 0.019
Evaluate (epoch 143) -- logp(x) = -1.369 +/- 0.018
Evaluate (epoch 144) -- logp(x) = -1.279 +/- 0.018
Evaluate (epoch 145) -- logp(x) = -1.297 +/- 0.019
Evaluate (epoch 146) -- logp(x) = -1.405 +/- 0.018
Evaluate (epoch 147) -- logp(x) = -1.392 +/- 0.018
Evaluate (epoch 148) -- logp(x) = -1.284 +/- 0.020
Evaluate (epoch 149) -- logp(x) = -1.332 +/- 0.020
Evaluate (epoch 150) -- logp(x) = -1.291 +/- 0.019
Evaluate (epoch 151) -- logp(x) = -1.259 +/- 0.018
Evaluate (epoch 152) -- logp(x) = -1.339 +/- 0.019
Evaluate (epoch 153) -- logp(x) = -1.295 +/- 0.018
Evaluate (epoch 154) -- logp(x) = -1.277 +/- 0.018
Evaluate (epoch 155) -- logp(x) = -1.254 +/- 0.020
Evaluate (epoch 156) -- logp(x) = -1.822 +/- 0.015
Evaluate (epoch 157) -- logp(x) = -1.533 +/- 0.019
Evaluate (epoch 158) -- logp(x) = -1.550 +/- 0.017
Evaluate (epoch 159) -- logp(x) = -1.464 +/- 0.018
Evaluate (epoch 160) -- logp(x) = -1.416 +/- 0.020
Evaluate (epoch 161) -- logp(x) = -1.369 +/- 0.019
Evaluate (epoch 162) -- logp(x) = -1.481 +/- 0.072
Evaluate (epoch 163) -- logp(x) = -1.793 +/- 0.017
Evaluate (epoch 164) -- logp(x) = -1.606 +/- 0.019
Evaluate (epoch 165) -- logp(x) = -1.476 +/- 0.016
Evaluate (epoch 166) -- logp(x) = -1.368 +/- 0.016
Evaluate (epoch 167) -- logp(x) = -1.344 +/- 0.016
Evaluate (epoch 168) -- logp(x) = -1.300 +/- 0.017
Evaluate (epoch 169) -- logp(x) = -1.303 +/- 0.017
Evaluate (epoch 170) -- logp(x) = -1.316 +/- 0.018
Evaluate (epoch 171) -- logp(x) = -1.249 +/- 0.018
Evaluate (epoch 172) -- logp(x) = -1.419 +/- 0.018
Evaluate (epoch 173) -- logp(x) = -1.339 +/- 0.019
Evaluate (epoch 174) -- logp(x) = -1.427 +/- 0.018
Evaluate (epoch 175) -- logp(x) = -1.290 +/- 0.018
Evaluate (epoch 176) -- logp(x) = -1.317 +/- 0.019
Evaluate (epoch 177) -- logp(x) = -1.563 +/- 0.015
Evaluate (epoch 178) -- logp(x) = -1.250 +/- 0.022
Evaluate (epoch 179) -- logp(x) = -1.362 +/- 0.018
Evaluate (epoch 180) -- logp(x) = -1.299 +/- 0.018
Evaluate (epoch 181) -- logp(x) = -1.648 +/- 0.015
Evaluate (epoch 182) -- logp(x) = -1.248 +/- 0.018
Evaluate (epoch 183) -- logp(x) = -1.264 +/- 0.019
Evaluate (epoch 184) -- logp(x) = -1.246 +/- 0.019
Evaluate (epoch 185) -- logp(x) = -1.420 +/- 0.017
Evaluate (epoch 186) -- logp(x) = -1.289 +/- 0.016
Evaluate (epoch 187) -- logp(x) = -1.359 +/- 0.017
Evaluate (epoch 188) -- logp(x) = -1.286 +/- 0.018
Evaluate (epoch 189) -- logp(x) = -1.236 +/- 0.071
Evaluate (epoch 190) -- logp(x) = -1.456 +/- 0.016
Evaluate (epoch 191) -- logp(x) = -1.260 +/- 0.019
Evaluate (epoch 192) -- logp(x) = -1.343 +/- 0.016
Evaluate (epoch 193) -- logp(x) = -1.257 +/- 0.018
Evaluate (epoch 194) -- logp(x) = -1.349 +/- 0.018
Evaluate (epoch 195) -- logp(x) = -1.223 +/- 0.018
Evaluate (epoch 196) -- logp(x) = -1.592 +/- 0.017
Evaluate (epoch 197) -- logp(x) = -1.445 +/- 0.017
Evaluate (epoch 198) -- logp(x) = -1.260 +/- 0.016
Evaluate (epoch 199) -- logp(x) = -1.211 +/- 0.018
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': './results/maf/best_model_checkpoint.pt',
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 200,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=3, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=6, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': None,
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.020 +/- 0.016
Evaluate (epoch 1) -- logp(x) = -1.000 +/- 0.016
Evaluate (epoch 2) -- logp(x) = -0.986 +/- 0.016
Evaluate (epoch 3) -- logp(x) = -0.970 +/- 0.017
Evaluate (epoch 4) -- logp(x) = -0.955 +/- 0.016
Evaluate (epoch 5) -- logp(x) = -0.938 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -0.918 +/- 0.015
Evaluate (epoch 7) -- logp(x) = -0.888 +/- 0.015
Evaluate (epoch 8) -- logp(x) = -0.850 +/- 0.014
Evaluate (epoch 9) -- logp(x) = -0.821 +/- 0.014
Evaluate (epoch 10) -- logp(x) = -0.811 +/- 0.014
Evaluate (epoch 11) -- logp(x) = -0.798 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -0.777 +/- 0.014
Evaluate (epoch 13) -- logp(x) = -0.774 +/- 0.015
Evaluate (epoch 14) -- logp(x) = -0.786 +/- 0.014
Evaluate (epoch 15) -- logp(x) = -0.769 +/- 0.014
Evaluate (epoch 16) -- logp(x) = -0.749 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -0.758 +/- 0.015
Evaluate (epoch 18) -- logp(x) = -0.796 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -0.740 +/- 0.015
Evaluate (epoch 20) -- logp(x) = -0.799 +/- 0.016
Evaluate (epoch 21) -- logp(x) = -0.755 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -0.729 +/- 0.015
Evaluate (epoch 23) -- logp(x) = -0.745 +/- 0.014
Evaluate (epoch 24) -- logp(x) = -0.720 +/- 0.015
Evaluate (epoch 25) -- logp(x) = -0.769 +/- 0.015
Evaluate (epoch 26) -- logp(x) = -0.802 +/- 0.025
Evaluate (epoch 27) -- logp(x) = -0.726 +/- 0.016
Evaluate (epoch 28) -- logp(x) = -0.780 +/- 0.129
Evaluate (epoch 29) -- logp(x) = -0.706 +/- 0.015
Evaluate (epoch 30) -- logp(x) = -0.704 +/- 0.015
Evaluate (epoch 31) -- logp(x) = -0.735 +/- 0.016
Evaluate (epoch 32) -- logp(x) = -0.711 +/- 0.016
Evaluate (epoch 33) -- logp(x) = -0.777 +/- 0.017
Evaluate (epoch 34) -- logp(x) = -0.747 +/- 0.016
Evaluate (epoch 35) -- logp(x) = -0.740 +/- 0.016
Evaluate (epoch 36) -- logp(x) = -0.716 +/- 0.016
Evaluate (epoch 37) -- logp(x) = -0.718 +/- 0.016
Evaluate (epoch 38) -- logp(x) = -0.708 +/- 0.016
Evaluate (epoch 39) -- logp(x) = -0.694 +/- 0.016
Evaluate (epoch 40) -- logp(x) = -0.697 +/- 0.016
Evaluate (epoch 41) -- logp(x) = -0.688 +/- 0.017
Evaluate (epoch 42) -- logp(x) = -0.687 +/- 0.017
Evaluate (epoch 43) -- logp(x) = -0.683 +/- 0.017
Evaluate (epoch 44) -- logp(x) = -0.684 +/- 0.017
Evaluate (epoch 45) -- logp(x) = -0.682 +/- 0.019
Evaluate (epoch 46) -- logp(x) = -0.681 +/- 0.017
Evaluate (epoch 47) -- logp(x) = -0.678 +/- 0.017
Evaluate (epoch 48) -- logp(x) = -0.719 +/- 0.016
Evaluate (epoch 49) -- logp(x) = -0.690 +/- 0.018
Evaluate (epoch 50) -- logp(x) = -0.670 +/- 0.017
Evaluate (epoch 51) -- logp(x) = -0.672 +/- 0.019
Evaluate (epoch 52) -- logp(x) = -0.653 +/- 0.018
Evaluate (epoch 53) -- logp(x) = -0.667 +/- 0.017
Evaluate (epoch 54) -- logp(x) = -0.696 +/- 0.017
Evaluate (epoch 55) -- logp(x) = -0.660 +/- 0.018
Evaluate (epoch 56) -- logp(x) = -0.704 +/- 0.018
Evaluate (epoch 57) -- logp(x) = -0.669 +/- 0.021
Evaluate (epoch 58) -- logp(x) = -0.659 +/- 0.019
Evaluate (epoch 59) -- logp(x) = -1.302 +/- 0.061
Evaluate (epoch 60) -- logp(x) = -0.944 +/- 0.019
Evaluate (epoch 61) -- logp(x) = -0.850 +/- 0.019
Evaluate (epoch 62) -- logp(x) = -0.732 +/- 0.019
Evaluate (epoch 63) -- logp(x) = -0.702 +/- 0.019
Evaluate (epoch 64) -- logp(x) = -0.671 +/- 0.019
Evaluate (epoch 65) -- logp(x) = -0.670 +/- 0.018
Evaluate (epoch 66) -- logp(x) = -0.688 +/- 0.018
Evaluate (epoch 67) -- logp(x) = -0.715 +/- 0.019
Evaluate (epoch 68) -- logp(x) = -0.666 +/- 0.019
Evaluate (epoch 69) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 70) -- logp(x) = -0.659 +/- 0.018
Evaluate (epoch 71) -- logp(x) = -0.738 +/- 0.018
Evaluate (epoch 72) -- logp(x) = -0.657 +/- 0.018
Evaluate (epoch 73) -- logp(x) = -0.642 +/- 0.018
Evaluate (epoch 74) -- logp(x) = -0.641 +/- 0.019
Evaluate (epoch 75) -- logp(x) = -0.654 +/- 0.019
Evaluate (epoch 76) -- logp(x) = -0.628 +/- 0.019
Evaluate (epoch 77) -- logp(x) = -0.630 +/- 0.019
Evaluate (epoch 78) -- logp(x) = -0.694 +/- 0.020
Evaluate (epoch 79) -- logp(x) = -0.638 +/- 0.019
Evaluate (epoch 80) -- logp(x) = -0.638 +/- 0.019
Evaluate (epoch 81) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 82) -- logp(x) = -0.634 +/- 0.019
Evaluate (epoch 83) -- logp(x) = -0.631 +/- 0.019
Evaluate (epoch 84) -- logp(x) = -0.625 +/- 0.019
Evaluate (epoch 85) -- logp(x) = -0.603 +/- 0.019
Evaluate (epoch 86) -- logp(x) = -0.695 +/- 0.023
Evaluate (epoch 87) -- logp(x) = -0.855 +/- 0.018
Evaluate (epoch 88) -- logp(x) = -0.766 +/- 0.020
Evaluate (epoch 89) -- logp(x) = -0.703 +/- 0.019
Evaluate (epoch 90) -- logp(x) = -33180.270 +/- 50675.902
Evaluate (epoch 91) -- logp(x) = -0.944 +/- 0.018
Evaluate (epoch 92) -- logp(x) = -0.869 +/- 0.018
Evaluate (epoch 93) -- logp(x) = -0.824 +/- 0.018
Evaluate (epoch 94) -- logp(x) = -0.800 +/- 0.019
Evaluate (epoch 95) -- logp(x) = -0.780 +/- 0.019
Evaluate (epoch 96) -- logp(x) = -0.767 +/- 0.019
Evaluate (epoch 97) -- logp(x) = -0.760 +/- 0.020
Evaluate (epoch 98) -- logp(x) = -0.742 +/- 0.019
Evaluate (epoch 99) -- logp(x) = -0.737 +/- 0.020
Evaluate (epoch 100) -- logp(x) = -0.726 +/- 0.020
Evaluate (epoch 101) -- logp(x) = -0.721 +/- 0.020
Evaluate (epoch 102) -- logp(x) = -0.705 +/- 0.020
Evaluate (epoch 103) -- logp(x) = -0.694 +/- 0.020
Evaluate (epoch 104) -- logp(x) = -0.686 +/- 0.020
Evaluate (epoch 105) -- logp(x) = -0.680 +/- 0.020
Evaluate (epoch 106) -- logp(x) = -0.696 +/- 0.019
Evaluate (epoch 107) -- logp(x) = -0.672 +/- 0.020
Evaluate (epoch 108) -- logp(x) = -0.668 +/- 0.019
Evaluate (epoch 109) -- logp(x) = -0.675 +/- 0.021
Evaluate (epoch 110) -- logp(x) = -0.671 +/- 0.020
Evaluate (epoch 111) -- logp(x) = -0.668 +/- 0.020
Evaluate (epoch 112) -- logp(x) = -0.688 +/- 0.020
Evaluate (epoch 113) -- logp(x) = -0.661 +/- 0.020
Evaluate (epoch 114) -- logp(x) = -0.660 +/- 0.020
Evaluate (epoch 115) -- logp(x) = -0.661 +/- 0.021
Evaluate (epoch 116) -- logp(x) = -0.652 +/- 0.020
Evaluate (epoch 117) -- logp(x) = -0.651 +/- 0.020
Evaluate (epoch 118) -- logp(x) = -0.644 +/- 0.020
Evaluate (epoch 119) -- logp(x) = -0.680 +/- 0.023
Evaluate (epoch 120) -- logp(x) = -0.647 +/- 0.020
Evaluate (epoch 121) -- logp(x) = -0.640 +/- 0.021
Evaluate (epoch 122) -- logp(x) = -0.646 +/- 0.020
Evaluate (epoch 123) -- logp(x) = -0.650 +/- 0.020
Evaluate (epoch 124) -- logp(x) = -0.644 +/- 0.021
Evaluate (epoch 125) -- logp(x) = -0.636 +/- 0.020
Evaluate (epoch 126) -- logp(x) = -0.672 +/- 0.020
Evaluate (epoch 127) -- logp(x) = -0.646 +/- 0.020
Evaluate (epoch 128) -- logp(x) = -0.661 +/- 0.020
Evaluate (epoch 129) -- logp(x) = -0.639 +/- 0.020
Evaluate (epoch 130) -- logp(x) = -0.642 +/- 0.020
Evaluate (epoch 131) -- logp(x) = -0.636 +/- 0.020
Evaluate (epoch 132) -- logp(x) = -0.666 +/- 0.021
Evaluate (epoch 133) -- logp(x) = -0.626 +/- 0.020
Evaluate (epoch 134) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 135) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 136) -- logp(x) = -0.627 +/- 0.019
Evaluate (epoch 137) -- logp(x) = -0.658 +/- 0.021
Evaluate (epoch 138) -- logp(x) = -0.637 +/- 0.021
Evaluate (epoch 139) -- logp(x) = -0.616 +/- 0.021
Evaluate (epoch 140) -- logp(x) = -0.615 +/- 0.020
Evaluate (epoch 141) -- logp(x) = -0.873 +/- 0.022
Evaluate (epoch 142) -- logp(x) = -0.747 +/- 0.022
Evaluate (epoch 143) -- logp(x) = -0.701 +/- 0.021
Evaluate (epoch 144) -- logp(x) = -0.684 +/- 0.021
Evaluate (epoch 145) -- logp(x) = -0.671 +/- 0.021
Evaluate (epoch 146) -- logp(x) = -0.663 +/- 0.021
Evaluate (epoch 147) -- logp(x) = -0.664 +/- 0.021
Evaluate (epoch 148) -- logp(x) = -0.654 +/- 0.021
Evaluate (epoch 149) -- logp(x) = -0.665 +/- 0.021
Evaluate (epoch 150) -- logp(x) = -0.654 +/- 0.021
Evaluate (epoch 151) -- logp(x) = -0.647 +/- 0.020
Evaluate (epoch 152) -- logp(x) = -0.642 +/- 0.021
Evaluate (epoch 153) -- logp(x) = -0.637 +/- 0.021
Evaluate (epoch 154) -- logp(x) = -0.658 +/- 0.021
Evaluate (epoch 155) -- logp(x) = -0.633 +/- 0.020
Evaluate (epoch 156) -- logp(x) = -0.629 +/- 0.020
Evaluate (epoch 157) -- logp(x) = -0.638 +/- 0.020
Evaluate (epoch 158) -- logp(x) = -0.622 +/- 0.021
Evaluate (epoch 159) -- logp(x) = -0.617 +/- 0.020
Evaluate (epoch 160) -- logp(x) = -0.613 +/- 0.021
Evaluate (epoch 161) -- logp(x) = -0.621 +/- 0.020
Evaluate (epoch 162) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 163) -- logp(x) = -0.607 +/- 0.020
Evaluate (epoch 164) -- logp(x) = -0.696 +/- 0.020
Evaluate (epoch 165) -- logp(x) = -0.684 +/- 0.021
Evaluate (epoch 166) -- logp(x) = -0.656 +/- 0.020
Evaluate (epoch 167) -- logp(x) = -0.641 +/- 0.020
Evaluate (epoch 168) -- logp(x) = -0.630 +/- 0.020
Evaluate (epoch 169) -- logp(x) = -0.619 +/- 0.020
Evaluate (epoch 170) -- logp(x) = -0.610 +/- 0.020
Evaluate (epoch 171) -- logp(x) = -0.603 +/- 0.020
Evaluate (epoch 172) -- logp(x) = -0.596 +/- 0.020
Evaluate (epoch 173) -- logp(x) = -0.591 +/- 0.020
Evaluate (epoch 174) -- logp(x) = -0.585 +/- 0.020
Evaluate (epoch 175) -- logp(x) = -0.584 +/- 0.020
Evaluate (epoch 176) -- logp(x) = -0.583 +/- 0.020
Evaluate (epoch 177) -- logp(x) = -0.574 +/- 0.020
Evaluate (epoch 178) -- logp(x) = -0.568 +/- 0.020
Evaluate (epoch 179) -- logp(x) = -0.572 +/- 0.020
Evaluate (epoch 180) -- logp(x) = -0.562 +/- 0.020
Evaluate (epoch 181) -- logp(x) = -0.557 +/- 0.020
Evaluate (epoch 182) -- logp(x) = -0.561 +/- 0.020
Evaluate (epoch 183) -- logp(x) = -0.555 +/- 0.021
Evaluate (epoch 184) -- logp(x) = -0.548 +/- 0.020
Evaluate (epoch 185) -- logp(x) = -0.547 +/- 0.020
Evaluate (epoch 186) -- logp(x) = -0.545 +/- 0.020
Evaluate (epoch 187) -- logp(x) = -0.539 +/- 0.021
Evaluate (epoch 188) -- logp(x) = -0.556 +/- 0.024
Evaluate (epoch 189) -- logp(x) = -0.558 +/- 0.020
Evaluate (epoch 190) -- logp(x) = -0.534 +/- 0.020
Evaluate (epoch 191) -- logp(x) = -0.535 +/- 0.020
Evaluate (epoch 192) -- logp(x) = -0.525 +/- 0.020
Evaluate (epoch 193) -- logp(x) = -0.529 +/- 0.021
Evaluate (epoch 194) -- logp(x) = -0.555 +/- 0.020
Evaluate (epoch 195) -- logp(x) = -0.521 +/- 0.021
Evaluate (epoch 196) -- logp(x) = -0.515 +/- 0.021
Evaluate (epoch 197) -- logp(x) = -0.523 +/- 0.021
Evaluate (epoch 198) -- logp(x) = -0.525 +/- 0.021
Evaluate (epoch 199) -- logp(x) = -0.848 +/- 0.038
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'maf',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/maf',
 'restore_file': './results/maf/best_model_checkpoint.pt',
 'results_file': './results/maf\\results.txt',
 'seed': 1,
 'start_epoch': 197,
 'train': False}
MAF(
  (net): FlowSequential(
    (0): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (1): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (2): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (3): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
    (4): MADE(
      (net_input): MaskedLinear(in_features=2, out_features=100, bias=True)
      (net): Sequential(
        (0): ReLU()
        (1): MaskedLinear(in_features=100, out_features=100, bias=True)
        (2): ReLU()
        (3): MaskedLinear(in_features=100, out_features=4, bias=True)
      )
    )
  )
)
