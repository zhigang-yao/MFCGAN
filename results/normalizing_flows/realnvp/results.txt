{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.008 +/- 0.002
Evaluate (epoch 1) -- logp(x) = -1.003 +/- 0.022
Evaluate (epoch 2) -- logp(x) = -0.686 +/- 0.025
Evaluate (epoch 3) -- logp(x) = -0.669 +/- 0.024
Evaluate (epoch 4) -- logp(x) = -0.446 +/- 0.025
Evaluate (epoch 5) -- logp(x) = -0.113 +/- 0.028
Evaluate (epoch 6) -- logp(x) = -0.055 +/- 0.027
Evaluate (epoch 7) -- logp(x) = 0.091 +/- 0.025
Evaluate (epoch 8) -- logp(x) = 0.138 +/- 0.025
Evaluate (epoch 9) -- logp(x) = 0.245 +/- 0.024
Evaluate (epoch 10) -- logp(x) = 0.214 +/- 0.023
Evaluate (epoch 11) -- logp(x) = 0.259 +/- 0.022
Evaluate (epoch 12) -- logp(x) = 0.378 +/- 0.022
Evaluate (epoch 13) -- logp(x) = 0.395 +/- 0.024
Evaluate (epoch 14) -- logp(x) = 0.402 +/- 0.021
Evaluate (epoch 15) -- logp(x) = 0.455 +/- 0.023
Evaluate (epoch 16) -- logp(x) = 0.506 +/- 0.022
Evaluate (epoch 17) -- logp(x) = 0.552 +/- 0.021
Evaluate (epoch 18) -- logp(x) = 0.546 +/- 0.022
Evaluate (epoch 19) -- logp(x) = 0.554 +/- 0.021
Evaluate (epoch 20) -- logp(x) = 0.549 +/- 0.021
Evaluate (epoch 21) -- logp(x) = 0.200 +/- 0.022
Evaluate (epoch 22) -- logp(x) = 0.454 +/- 0.020
Evaluate (epoch 23) -- logp(x) = 0.613 +/- 0.021
Evaluate (epoch 24) -- logp(x) = 0.618 +/- 0.021
Evaluate (epoch 25) -- logp(x) = 0.328 +/- 0.024
Evaluate (epoch 26) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 27) -- logp(x) = 0.626 +/- 0.023
Evaluate (epoch 28) -- logp(x) = 0.563 +/- 0.025
Evaluate (epoch 29) -- logp(x) = 0.406 +/- 0.021
Evaluate (epoch 30) -- logp(x) = 0.685 +/- 0.021
Evaluate (epoch 31) -- logp(x) = 0.611 +/- 0.023
Evaluate (epoch 32) -- logp(x) = 0.668 +/- 0.021
Evaluate (epoch 33) -- logp(x) = 0.504 +/- 0.021
Evaluate (epoch 34) -- logp(x) = 0.607 +/- 0.022
Evaluate (epoch 35) -- logp(x) = 0.607 +/- 0.024
Evaluate (epoch 36) -- logp(x) = 0.673 +/- 0.021
Evaluate (epoch 37) -- logp(x) = 0.691 +/- 0.020
Evaluate (epoch 38) -- logp(x) = 0.657 +/- 0.022
Evaluate (epoch 39) -- logp(x) = 0.668 +/- 0.024
Evaluate (epoch 40) -- logp(x) = 0.582 +/- 0.023
Evaluate (epoch 41) -- logp(x) = 0.710 +/- 0.021
Evaluate (epoch 42) -- logp(x) = 0.597 +/- 0.021
Evaluate (epoch 43) -- logp(x) = 0.697 +/- 0.021
Evaluate (epoch 44) -- logp(x) = 0.718 +/- 0.019
Evaluate (epoch 45) -- logp(x) = 0.625 +/- 0.021
Evaluate (epoch 46) -- logp(x) = 0.678 +/- 0.020
Evaluate (epoch 47) -- logp(x) = 0.540 +/- 0.025
Evaluate (epoch 48) -- logp(x) = 0.739 +/- 0.020
Evaluate (epoch 49) -- logp(x) = 0.737 +/- 0.021
Evaluate (epoch 50) -- logp(x) = 0.721 +/- 0.021
Evaluate (epoch 51) -- logp(x) = 0.716 +/- 0.021
Evaluate (epoch 52) -- logp(x) = 0.682 +/- 0.020
Evaluate (epoch 53) -- logp(x) = 0.761 +/- 0.020
Evaluate (epoch 54) -- logp(x) = 0.553 +/- 0.026
Evaluate (epoch 55) -- logp(x) = 0.745 +/- 0.021
Evaluate (epoch 56) -- logp(x) = 0.670 +/- 0.025
Evaluate (epoch 57) -- logp(x) = 0.724 +/- 0.020
Evaluate (epoch 58) -- logp(x) = 0.779 +/- 0.021
Evaluate (epoch 59) -- logp(x) = 0.479 +/- 0.022
Evaluate (epoch 60) -- logp(x) = 0.826 +/- 0.021
Evaluate (epoch 61) -- logp(x) = 0.686 +/- 0.024
Evaluate (epoch 62) -- logp(x) = 0.657 +/- 0.027
Evaluate (epoch 63) -- logp(x) = 0.770 +/- 0.026
Evaluate (epoch 64) -- logp(x) = 0.487 +/- 0.029
Evaluate (epoch 65) -- logp(x) = 0.717 +/- 0.020
Evaluate (epoch 66) -- logp(x) = 0.742 +/- 0.022
Evaluate (epoch 67) -- logp(x) = 0.809 +/- 0.021
Evaluate (epoch 68) -- logp(x) = 0.762 +/- 0.019
Evaluate (epoch 69) -- logp(x) = 0.798 +/- 0.020
Evaluate (epoch 70) -- logp(x) = 0.724 +/- 0.023
Evaluate (epoch 71) -- logp(x) = 0.781 +/- 0.022
Evaluate (epoch 72) -- logp(x) = 0.707 +/- 0.024
Evaluate (epoch 73) -- logp(x) = 0.723 +/- 0.020
Evaluate (epoch 74) -- logp(x) = 0.742 +/- 0.021
Evaluate (epoch 75) -- logp(x) = 0.779 +/- 0.023
Evaluate (epoch 76) -- logp(x) = 0.635 +/- 0.025
Evaluate (epoch 77) -- logp(x) = 0.687 +/- 0.020
Evaluate (epoch 78) -- logp(x) = 0.807 +/- 0.020
Evaluate (epoch 79) -- logp(x) = 0.775 +/- 0.021
Evaluate (epoch 80) -- logp(x) = 0.851 +/- 0.018
Evaluate (epoch 81) -- logp(x) = 0.858 +/- 0.020
Evaluate (epoch 82) -- logp(x) = 0.831 +/- 0.019
Evaluate (epoch 83) -- logp(x) = 0.682 +/- 0.025
Evaluate (epoch 84) -- logp(x) = 0.792 +/- 0.023
Evaluate (epoch 85) -- logp(x) = 0.762 +/- 0.020
Evaluate (epoch 86) -- logp(x) = 0.820 +/- 0.019
Evaluate (epoch 87) -- logp(x) = 0.882 +/- 0.020
Evaluate (epoch 88) -- logp(x) = 0.812 +/- 0.019
Evaluate (epoch 89) -- logp(x) = 0.908 +/- 0.020
Evaluate (epoch 90) -- logp(x) = 0.725 +/- 0.022
Evaluate (epoch 91) -- logp(x) = 0.788 +/- 0.018
Evaluate (epoch 92) -- logp(x) = 0.883 +/- 0.020
Evaluate (epoch 93) -- logp(x) = 0.902 +/- 0.020
Evaluate (epoch 94) -- logp(x) = 0.898 +/- 0.020
Evaluate (epoch 95) -- logp(x) = 0.740 +/- 0.022
Evaluate (epoch 96) -- logp(x) = 0.718 +/- 0.022
Evaluate (epoch 97) -- logp(x) = 0.920 +/- 0.020
Evaluate (epoch 98) -- logp(x) = 0.827 +/- 0.019
Evaluate (epoch 99) -- logp(x) = 0.826 +/- 0.022
Evaluate (epoch 100) -- logp(x) = 0.761 +/- 0.024
Evaluate (epoch 101) -- logp(x) = 0.849 +/- 0.021
Evaluate (epoch 102) -- logp(x) = 0.583 +/- 0.021
Evaluate (epoch 103) -- logp(x) = 0.843 +/- 0.022
Evaluate (epoch 104) -- logp(x) = 0.886 +/- 0.020
Evaluate (epoch 105) -- logp(x) = 0.793 +/- 0.019
Evaluate (epoch 106) -- logp(x) = 0.572 +/- 0.025
Evaluate (epoch 107) -- logp(x) = 0.814 +/- 0.020
Evaluate (epoch 108) -- logp(x) = 0.839 +/- 0.019
Evaluate (epoch 109) -- logp(x) = 0.876 +/- 0.020
Evaluate (epoch 110) -- logp(x) = 0.874 +/- 0.021
Evaluate (epoch 111) -- logp(x) = 0.806 +/- 0.022
Evaluate (epoch 112) -- logp(x) = 0.853 +/- 0.021
Evaluate (epoch 113) -- logp(x) = 0.888 +/- 0.021
Evaluate (epoch 114) -- logp(x) = 0.850 +/- 0.019
Evaluate (epoch 115) -- logp(x) = 0.813 +/- 0.020
Evaluate (epoch 116) -- logp(x) = 0.827 +/- 0.021
Evaluate (epoch 117) -- logp(x) = 0.887 +/- 0.021
Evaluate (epoch 118) -- logp(x) = 0.906 +/- 0.020
Evaluate (epoch 119) -- logp(x) = 0.831 +/- 0.020
Evaluate (epoch 120) -- logp(x) = 0.770 +/- 0.024
Evaluate (epoch 121) -- logp(x) = 0.696 +/- 0.019
Evaluate (epoch 122) -- logp(x) = 0.891 +/- 0.021
Evaluate (epoch 123) -- logp(x) = 0.861 +/- 0.022
Evaluate (epoch 124) -- logp(x) = 0.915 +/- 0.020
Evaluate (epoch 125) -- logp(x) = 0.890 +/- 0.020
Evaluate (epoch 126) -- logp(x) = 0.934 +/- 0.019
Evaluate (epoch 127) -- logp(x) = 0.853 +/- 0.018
Evaluate (epoch 128) -- logp(x) = 0.908 +/- 0.021
Evaluate (epoch 129) -- logp(x) = 0.756 +/- 0.020
Evaluate (epoch 130) -- logp(x) = 0.945 +/- 0.020
Evaluate (epoch 131) -- logp(x) = 0.923 +/- 0.020
Evaluate (epoch 132) -- logp(x) = 0.915 +/- 0.019
Evaluate (epoch 133) -- logp(x) = 0.811 +/- 0.024
Evaluate (epoch 134) -- logp(x) = 0.945 +/- 0.019
Evaluate (epoch 135) -- logp(x) = 0.929 +/- 0.019
Evaluate (epoch 136) -- logp(x) = 0.861 +/- 0.023
Evaluate (epoch 137) -- logp(x) = 0.925 +/- 0.020
Evaluate (epoch 138) -- logp(x) = 0.841 +/- 0.023
Evaluate (epoch 139) -- logp(x) = 0.961 +/- 0.019
Evaluate (epoch 140) -- logp(x) = 0.971 +/- 0.019
Evaluate (epoch 141) -- logp(x) = 0.897 +/- 0.020
Evaluate (epoch 142) -- logp(x) = 0.820 +/- 0.025
Evaluate (epoch 143) -- logp(x) = 0.898 +/- 0.022
Evaluate (epoch 144) -- logp(x) = 0.947 +/- 0.020
Evaluate (epoch 145) -- logp(x) = 0.967 +/- 0.018
Evaluate (epoch 146) -- logp(x) = 0.947 +/- 0.019
Evaluate (epoch 147) -- logp(x) = 0.971 +/- 0.020
Evaluate (epoch 148) -- logp(x) = 0.893 +/- 0.022
Evaluate (epoch 149) -- logp(x) = 0.936 +/- 0.019
Evaluate (epoch 150) -- logp(x) = 0.898 +/- 0.020
Evaluate (epoch 151) -- logp(x) = 0.921 +/- 0.019
Evaluate (epoch 152) -- logp(x) = 0.929 +/- 0.020
Evaluate (epoch 153) -- logp(x) = 0.963 +/- 0.021
Evaluate (epoch 154) -- logp(x) = 0.996 +/- 0.018
Evaluate (epoch 155) -- logp(x) = 0.917 +/- 0.020
Evaluate (epoch 156) -- logp(x) = 0.937 +/- 0.019
Evaluate (epoch 157) -- logp(x) = 0.971 +/- 0.019
Evaluate (epoch 158) -- logp(x) = 0.813 +/- 0.022
Evaluate (epoch 159) -- logp(x) = 0.952 +/- 0.020
Evaluate (epoch 160) -- logp(x) = 1.007 +/- 0.018
Evaluate (epoch 161) -- logp(x) = 0.973 +/- 0.019
Evaluate (epoch 162) -- logp(x) = 0.933 +/- 0.019
Evaluate (epoch 163) -- logp(x) = 0.805 +/- 0.021
Evaluate (epoch 164) -- logp(x) = 0.990 +/- 0.020
Evaluate (epoch 165) -- logp(x) = 0.967 +/- 0.019
Evaluate (epoch 166) -- logp(x) = 0.870 +/- 0.023
Evaluate (epoch 167) -- logp(x) = 0.831 +/- 0.024
Evaluate (epoch 168) -- logp(x) = 0.886 +/- 0.018
Evaluate (epoch 169) -- logp(x) = 0.921 +/- 0.019
Evaluate (epoch 170) -- logp(x) = 1.000 +/- 0.019
Evaluate (epoch 171) -- logp(x) = 0.964 +/- 0.020
Evaluate (epoch 172) -- logp(x) = 1.003 +/- 0.020
Evaluate (epoch 173) -- logp(x) = 0.951 +/- 0.022
Evaluate (epoch 174) -- logp(x) = 0.962 +/- 0.020
Evaluate (epoch 175) -- logp(x) = 1.024 +/- 0.018
Evaluate (epoch 176) -- logp(x) = 0.917 +/- 0.019
Evaluate (epoch 177) -- logp(x) = 0.983 +/- 0.019
Evaluate (epoch 178) -- logp(x) = 0.981 +/- 0.020
Evaluate (epoch 179) -- logp(x) = 1.018 +/- 0.017
Evaluate (epoch 180) -- logp(x) = 0.945 +/- 0.018
Evaluate (epoch 181) -- logp(x) = 0.925 +/- 0.020
Evaluate (epoch 182) -- logp(x) = 0.929 +/- 0.020
Evaluate (epoch 183) -- logp(x) = 0.927 +/- 0.022
Evaluate (epoch 184) -- logp(x) = 0.942 +/- 0.021
Evaluate (epoch 185) -- logp(x) = 0.902 +/- 0.032
Evaluate (epoch 186) -- logp(x) = 0.918 +/- 0.022
Evaluate (epoch 187) -- logp(x) = 0.942 +/- 0.020
Evaluate (epoch 188) -- logp(x) = 1.009 +/- 0.019
Evaluate (epoch 189) -- logp(x) = 0.816 +/- 0.025
Evaluate (epoch 190) -- logp(x) = 0.824 +/- 0.023
Evaluate (epoch 191) -- logp(x) = 0.926 +/- 0.023
Evaluate (epoch 192) -- logp(x) = 1.031 +/- 0.018
Evaluate (epoch 193) -- logp(x) = 0.997 +/- 0.019
Evaluate (epoch 194) -- logp(x) = 1.016 +/- 0.018
Evaluate (epoch 195) -- logp(x) = 0.988 +/- 0.021
Evaluate (epoch 196) -- logp(x) = 0.881 +/- 0.026
Evaluate (epoch 197) -- logp(x) = 0.998 +/- 0.018
Evaluate (epoch 198) -- logp(x) = 0.965 +/- 0.020
Evaluate (epoch 199) -- logp(x) = 1.025 +/- 0.022
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.653 +/- 0.014
Evaluate (epoch 1) -- logp(x) = -2.629 +/- 0.014
Evaluate (epoch 2) -- logp(x) = -2.594 +/- 0.013
Evaluate (epoch 3) -- logp(x) = -2.546 +/- 0.013
Evaluate (epoch 4) -- logp(x) = -2.490 +/- 0.012
Evaluate (epoch 5) -- logp(x) = -2.423 +/- 0.014
Evaluate (epoch 6) -- logp(x) = -2.330 +/- 0.013
Evaluate (epoch 7) -- logp(x) = -2.270 +/- 0.012
Evaluate (epoch 8) -- logp(x) = -2.225 +/- 0.012
Evaluate (epoch 9) -- logp(x) = -2.185 +/- 0.013
Evaluate (epoch 10) -- logp(x) = -2.183 +/- 0.013
Evaluate (epoch 11) -- logp(x) = -2.103 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -2.093 +/- 0.014
Evaluate (epoch 13) -- logp(x) = -2.039 +/- 0.013
Evaluate (epoch 14) -- logp(x) = -1.999 +/- 0.015
Evaluate (epoch 15) -- logp(x) = -1.950 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -1.946 +/- 0.015
Evaluate (epoch 17) -- logp(x) = -1.943 +/- 0.017
Evaluate (epoch 18) -- logp(x) = -1.928 +/- 0.016
Evaluate (epoch 19) -- logp(x) = -1.871 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -1.908 +/- 0.016
Evaluate (epoch 21) -- logp(x) = -1.847 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -1.814 +/- 0.019
Evaluate (epoch 23) -- logp(x) = -1.862 +/- 0.025
Evaluate (epoch 24) -- logp(x) = -1.844 +/- 0.015
Evaluate (epoch 25) -- logp(x) = -1.763 +/- 0.018
Evaluate (epoch 26) -- logp(x) = -1.753 +/- 0.017
Evaluate (epoch 27) -- logp(x) = -1.721 +/- 0.018
Evaluate (epoch 28) -- logp(x) = -1.786 +/- 0.018
Evaluate (epoch 29) -- logp(x) = -1.816 +/- 0.018
Evaluate (epoch 30) -- logp(x) = -1.773 +/- 0.017
Evaluate (epoch 31) -- logp(x) = -1.769 +/- 0.022
Evaluate (epoch 32) -- logp(x) = -1.894 +/- 0.052
Evaluate (epoch 33) -- logp(x) = -1.674 +/- 0.018
Evaluate (epoch 34) -- logp(x) = -1.650 +/- 0.019
Evaluate (epoch 35) -- logp(x) = -1.672 +/- 0.018
Evaluate (epoch 36) -- logp(x) = -1.761 +/- 0.015
Evaluate (epoch 37) -- logp(x) = -1.638 +/- 0.019
Evaluate (epoch 38) -- logp(x) = -1.623 +/- 0.018
Evaluate (epoch 39) -- logp(x) = -1.600 +/- 0.019
Evaluate (epoch 40) -- logp(x) = -1.617 +/- 0.020
Evaluate (epoch 41) -- logp(x) = -1.600 +/- 0.019
Evaluate (epoch 42) -- logp(x) = -1.729 +/- 0.020
Evaluate (epoch 43) -- logp(x) = -1.601 +/- 0.021
Evaluate (epoch 44) -- logp(x) = -1.604 +/- 0.020
Evaluate (epoch 45) -- logp(x) = -1.605 +/- 0.019
Evaluate (epoch 46) -- logp(x) = -1.548 +/- 0.023
Evaluate (epoch 47) -- logp(x) = -1.582 +/- 0.020
Evaluate (epoch 48) -- logp(x) = -1.562 +/- 0.021
Evaluate (epoch 49) -- logp(x) = -1.531 +/- 0.027
Evaluate (epoch 50) -- logp(x) = -1.529 +/- 0.020
Evaluate (epoch 51) -- logp(x) = -1.494 +/- 0.021
Evaluate (epoch 52) -- logp(x) = -1.533 +/- 0.020
Evaluate (epoch 53) -- logp(x) = -1.461 +/- 0.021
Evaluate (epoch 54) -- logp(x) = -1.474 +/- 0.020
Evaluate (epoch 55) -- logp(x) = -1.568 +/- 0.021
Evaluate (epoch 56) -- logp(x) = -1.433 +/- 0.022
Evaluate (epoch 57) -- logp(x) = -1.541 +/- 0.020
Evaluate (epoch 58) -- logp(x) = -1.459 +/- 0.020
Evaluate (epoch 59) -- logp(x) = -1.483 +/- 0.022
Evaluate (epoch 60) -- logp(x) = -1.450 +/- 0.021
Evaluate (epoch 61) -- logp(x) = -1.455 +/- 0.021
Evaluate (epoch 62) -- logp(x) = -1.413 +/- 0.021
Evaluate (epoch 63) -- logp(x) = -1.461 +/- 0.023
Evaluate (epoch 64) -- logp(x) = -1.380 +/- 0.023
Evaluate (epoch 65) -- logp(x) = -1.433 +/- 0.021
Evaluate (epoch 66) -- logp(x) = -1.370 +/- 0.021
Evaluate (epoch 67) -- logp(x) = -1.377 +/- 0.023
Evaluate (epoch 68) -- logp(x) = -1.563 +/- 0.020
Evaluate (epoch 69) -- logp(x) = -1.854 +/- 0.021
Evaluate (epoch 70) -- logp(x) = -1.576 +/- 0.020
Evaluate (epoch 71) -- logp(x) = -1.415 +/- 0.021
Evaluate (epoch 72) -- logp(x) = -1.357 +/- 0.022
Evaluate (epoch 73) -- logp(x) = -1.361 +/- 0.021
Evaluate (epoch 74) -- logp(x) = -1.360 +/- 0.022
Evaluate (epoch 75) -- logp(x) = -1.420 +/- 0.022
Evaluate (epoch 76) -- logp(x) = -1.320 +/- 0.022
Evaluate (epoch 77) -- logp(x) = -1.335 +/- 0.021
Evaluate (epoch 78) -- logp(x) = -1.338 +/- 0.024
Evaluate (epoch 79) -- logp(x) = -1.343 +/- 0.022
Evaluate (epoch 80) -- logp(x) = -1.334 +/- 0.023
Evaluate (epoch 81) -- logp(x) = -1.300 +/- 0.023
Evaluate (epoch 82) -- logp(x) = -1.312 +/- 0.023
Evaluate (epoch 83) -- logp(x) = -1.378 +/- 0.024
Evaluate (epoch 84) -- logp(x) = -1.322 +/- 0.025
Evaluate (epoch 85) -- logp(x) = -1.324 +/- 0.023
Evaluate (epoch 86) -- logp(x) = -1.344 +/- 0.024
Evaluate (epoch 87) -- logp(x) = -1.266 +/- 0.022
Evaluate (epoch 88) -- logp(x) = -1.274 +/- 0.023
Evaluate (epoch 89) -- logp(x) = -1.359 +/- 0.022
Evaluate (epoch 90) -- logp(x) = -1.314 +/- 0.025
Evaluate (epoch 91) -- logp(x) = -1.305 +/- 0.021
Evaluate (epoch 92) -- logp(x) = -1.406 +/- 0.022
Evaluate (epoch 93) -- logp(x) = -1.246 +/- 0.022
Evaluate (epoch 94) -- logp(x) = -1.250 +/- 0.022
Evaluate (epoch 95) -- logp(x) = -1.314 +/- 0.024
Evaluate (epoch 96) -- logp(x) = -1.306 +/- 0.023
Evaluate (epoch 97) -- logp(x) = -1.290 +/- 0.023
Evaluate (epoch 98) -- logp(x) = -1.223 +/- 0.023
Evaluate (epoch 99) -- logp(x) = -1.278 +/- 0.022
Evaluate (epoch 100) -- logp(x) = -1.248 +/- 0.023
Evaluate (epoch 101) -- logp(x) = -1.315 +/- 0.024
Evaluate (epoch 102) -- logp(x) = -1.268 +/- 0.023
Evaluate (epoch 103) -- logp(x) = -1.227 +/- 0.023
Evaluate (epoch 104) -- logp(x) = -1.279 +/- 0.023
Evaluate (epoch 105) -- logp(x) = -1.218 +/- 0.023
Evaluate (epoch 106) -- logp(x) = -1.242 +/- 0.023
Evaluate (epoch 107) -- logp(x) = -1.258 +/- 0.022
Evaluate (epoch 108) -- logp(x) = -1.241 +/- 0.024
Evaluate (epoch 109) -- logp(x) = -1.246 +/- 0.023
Evaluate (epoch 110) -- logp(x) = -1.280 +/- 0.027
Evaluate (epoch 111) -- logp(x) = -1.315 +/- 0.022
Evaluate (epoch 112) -- logp(x) = -1.209 +/- 0.022
Evaluate (epoch 113) -- logp(x) = -1.244 +/- 0.023
Evaluate (epoch 114) -- logp(x) = -1.220 +/- 0.023
Evaluate (epoch 115) -- logp(x) = -1.497 +/- 0.023
Evaluate (epoch 116) -- logp(x) = -1.303 +/- 0.022
Evaluate (epoch 117) -- logp(x) = -1.224 +/- 0.023
Evaluate (epoch 118) -- logp(x) = -1.290 +/- 0.023
Evaluate (epoch 119) -- logp(x) = -1.183 +/- 0.022
Evaluate (epoch 120) -- logp(x) = -1.207 +/- 0.023
Evaluate (epoch 121) -- logp(x) = -1.197 +/- 0.023
Evaluate (epoch 122) -- logp(x) = -1.244 +/- 0.022
Evaluate (epoch 123) -- logp(x) = -1.245 +/- 0.022
Evaluate (epoch 124) -- logp(x) = -1.164 +/- 0.023
Evaluate (epoch 125) -- logp(x) = -1.178 +/- 0.023
Evaluate (epoch 126) -- logp(x) = -1.209 +/- 0.023
Evaluate (epoch 127) -- logp(x) = -1.193 +/- 0.023
Evaluate (epoch 128) -- logp(x) = -1.174 +/- 0.024
Evaluate (epoch 129) -- logp(x) = -1.167 +/- 0.024
Evaluate (epoch 130) -- logp(x) = -1.257 +/- 0.030
Evaluate (epoch 131) -- logp(x) = -1.184 +/- 0.024
Evaluate (epoch 132) -- logp(x) = -1.264 +/- 0.026
Evaluate (epoch 133) -- logp(x) = -1.204 +/- 0.023
Evaluate (epoch 134) -- logp(x) = -1.208 +/- 0.023
Evaluate (epoch 135) -- logp(x) = -1.142 +/- 0.023
Evaluate (epoch 136) -- logp(x) = -1.257 +/- 0.022
Evaluate (epoch 137) -- logp(x) = -1.137 +/- 0.023
Evaluate (epoch 138) -- logp(x) = -1.175 +/- 0.024
Evaluate (epoch 139) -- logp(x) = -1.342 +/- 0.023
Evaluate (epoch 140) -- logp(x) = -1.161 +/- 0.023
Evaluate (epoch 141) -- logp(x) = -1.191 +/- 0.027
Evaluate (epoch 142) -- logp(x) = -1.136 +/- 0.023
Evaluate (epoch 143) -- logp(x) = -1.148 +/- 0.023
Evaluate (epoch 144) -- logp(x) = -1.168 +/- 0.023
Evaluate (epoch 145) -- logp(x) = -1.192 +/- 0.023
Evaluate (epoch 146) -- logp(x) = -1.187 +/- 0.024
Evaluate (epoch 147) -- logp(x) = -1.134 +/- 0.023
Evaluate (epoch 148) -- logp(x) = -1.245 +/- 0.027
Evaluate (epoch 149) -- logp(x) = -1.106 +/- 0.024
Evaluate (epoch 150) -- logp(x) = -1.140 +/- 0.025
Evaluate (epoch 151) -- logp(x) = -1.165 +/- 0.024
Evaluate (epoch 152) -- logp(x) = -1.141 +/- 0.023
Evaluate (epoch 153) -- logp(x) = -1.177 +/- 0.023
Evaluate (epoch 154) -- logp(x) = -1.142 +/- 0.023
Evaluate (epoch 155) -- logp(x) = -1.217 +/- 0.024
Evaluate (epoch 156) -- logp(x) = -1.128 +/- 0.024
Evaluate (epoch 157) -- logp(x) = -1.150 +/- 0.023
Evaluate (epoch 158) -- logp(x) = -1.146 +/- 0.023
Evaluate (epoch 159) -- logp(x) = -1.098 +/- 0.023
Evaluate (epoch 160) -- logp(x) = -1.092 +/- 0.024
Evaluate (epoch 161) -- logp(x) = -1.114 +/- 0.024
Evaluate (epoch 162) -- logp(x) = -1.104 +/- 0.023
Evaluate (epoch 163) -- logp(x) = -1.175 +/- 0.024
Evaluate (epoch 164) -- logp(x) = -1.102 +/- 0.023
Evaluate (epoch 165) -- logp(x) = -1.072 +/- 0.024
Evaluate (epoch 166) -- logp(x) = -1.266 +/- 0.021
Evaluate (epoch 167) -- logp(x) = -1.106 +/- 0.024
Evaluate (epoch 168) -- logp(x) = -1.114 +/- 0.023
Evaluate (epoch 169) -- logp(x) = -1.113 +/- 0.025
Evaluate (epoch 170) -- logp(x) = -1.145 +/- 0.023
Evaluate (epoch 171) -- logp(x) = -1.121 +/- 0.023
Evaluate (epoch 172) -- logp(x) = -1.106 +/- 0.023
Evaluate (epoch 173) -- logp(x) = -1.240 +/- 0.022
Evaluate (epoch 174) -- logp(x) = -1.089 +/- 0.023
Evaluate (epoch 175) -- logp(x) = -1.073 +/- 0.023
Evaluate (epoch 176) -- logp(x) = -1.113 +/- 0.023
Evaluate (epoch 177) -- logp(x) = -1.089 +/- 0.023
Evaluate (epoch 178) -- logp(x) = -1.051 +/- 0.024
Evaluate (epoch 179) -- logp(x) = -1.147 +/- 0.025
Evaluate (epoch 180) -- logp(x) = -1.075 +/- 0.025
Evaluate (epoch 181) -- logp(x) = -1.055 +/- 0.024
Evaluate (epoch 182) -- logp(x) = -1.122 +/- 0.023
Evaluate (epoch 183) -- logp(x) = -1.071 +/- 0.024
Evaluate (epoch 184) -- logp(x) = -1.083 +/- 0.025
Evaluate (epoch 185) -- logp(x) = -1.114 +/- 0.022
Evaluate (epoch 186) -- logp(x) = -1.199 +/- 0.022
Evaluate (epoch 187) -- logp(x) = -1.049 +/- 0.024
Evaluate (epoch 188) -- logp(x) = -1.101 +/- 0.023
Evaluate (epoch 189) -- logp(x) = -1.108 +/- 0.023
Evaluate (epoch 190) -- logp(x) = -1.129 +/- 0.025
Evaluate (epoch 191) -- logp(x) = -1.061 +/- 0.024
Evaluate (epoch 192) -- logp(x) = -1.150 +/- 0.028
Evaluate (epoch 193) -- logp(x) = -1.076 +/- 0.024
Evaluate (epoch 194) -- logp(x) = -1.041 +/- 0.023
Evaluate (epoch 195) -- logp(x) = -1.073 +/- 0.024
Evaluate (epoch 196) -- logp(x) = -1.111 +/- 0.024
Evaluate (epoch 197) -- logp(x) = -1.050 +/- 0.024
Evaluate (epoch 198) -- logp(x) = -1.028 +/- 0.024
Evaluate (epoch 199) -- logp(x) = -1.147 +/- 0.024
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.042 +/- 0.019
Evaluate (epoch 1) -- logp(x) = -1.035 +/- 0.018
Evaluate (epoch 2) -- logp(x) = -1.033 +/- 0.019
Evaluate (epoch 3) -- logp(x) = -1.026 +/- 0.017
Evaluate (epoch 4) -- logp(x) = -1.023 +/- 0.018
Evaluate (epoch 5) -- logp(x) = -1.022 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -1.017 +/- 0.016
Evaluate (epoch 7) -- logp(x) = -1.009 +/- 0.017
Evaluate (epoch 8) -- logp(x) = -1.006 +/- 0.016
Evaluate (epoch 9) -- logp(x) = -1.002 +/- 0.016
Evaluate (epoch 10) -- logp(x) = -0.980 +/- 0.015
Evaluate (epoch 11) -- logp(x) = -0.949 +/- 0.015
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
Evaluate (epoch 12) -- logp(x) = -0.943 +/- 0.016
Evaluate (epoch 13) -- logp(x) = -0.902 +/- 0.015
Evaluate (epoch 14) -- logp(x) = -0.897 +/- 0.014
Evaluate (epoch 15) -- logp(x) = -0.879 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -0.846 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -0.827 +/- 0.015
Evaluate (epoch 18) -- logp(x) = -0.812 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -0.791 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -0.792 +/- 0.017
Evaluate (epoch 21) -- logp(x) = -0.827 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -0.992 +/- 0.018
Evaluate (epoch 23) -- logp(x) = -0.867 +/- 0.017
Evaluate (epoch 24) -- logp(x) = -0.832 +/- 0.017
Evaluate (epoch 25) -- logp(x) = -0.792 +/- 0.017
Evaluate (epoch 26) -- logp(x) = -0.755 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -0.749 +/- 0.017
Evaluate (epoch 28) -- logp(x) = -0.698 +/- 0.017
Evaluate (epoch 29) -- logp(x) = -0.708 +/- 0.017
Evaluate (epoch 30) -- logp(x) = -0.667 +/- 0.019
Evaluate (epoch 31) -- logp(x) = -0.663 +/- 0.019
Evaluate (epoch 32) -- logp(x) = -0.652 +/- 0.019
Evaluate (epoch 33) -- logp(x) = -0.649 +/- 0.019
Evaluate (epoch 34) -- logp(x) = -0.611 +/- 0.020
Evaluate (epoch 35) -- logp(x) = -0.619 +/- 0.019
Evaluate (epoch 36) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 37) -- logp(x) = -0.727 +/- 0.019
Evaluate (epoch 38) -- logp(x) = -0.616 +/- 0.019
Evaluate (epoch 39) -- logp(x) = -0.622 +/- 0.022
Evaluate (epoch 40) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 41) -- logp(x) = -0.579 +/- 0.020
Evaluate (epoch 42) -- logp(x) = -0.556 +/- 0.020
Evaluate (epoch 43) -- logp(x) = -0.535 +/- 0.020
Evaluate (epoch 44) -- logp(x) = -0.522 +/- 0.021
Evaluate (epoch 45) -- logp(x) = -0.495 +/- 0.022
Evaluate (epoch 46) -- logp(x) = -0.535 +/- 0.021
Evaluate (epoch 47) -- logp(x) = -0.520 +/- 0.022
Evaluate (epoch 48) -- logp(x) = -0.484 +/- 0.023
Evaluate (epoch 49) -- logp(x) = -0.545 +/- 0.024
Evaluate (epoch 50) -- logp(x) = -0.505 +/- 0.022
Evaluate (epoch 51) -- logp(x) = -0.432 +/- 0.024
Evaluate (epoch 52) -- logp(x) = -0.568 +/- 0.029
Evaluate (epoch 53) -- logp(x) = -0.414 +/- 0.024
Evaluate (epoch 54) -- logp(x) = -0.410 +/- 0.024
Evaluate (epoch 55) -- logp(x) = -0.429 +/- 0.025
Evaluate (epoch 56) -- logp(x) = -0.411 +/- 0.025
Evaluate (epoch 57) -- logp(x) = -0.468 +/- 0.023
Evaluate (epoch 58) -- logp(x) = -0.384 +/- 0.024
Evaluate (epoch 59) -- logp(x) = -0.388 +/- 0.025
Evaluate (epoch 60) -- logp(x) = -0.466 +/- 0.024
Evaluate (epoch 61) -- logp(x) = -0.394 +/- 0.024
Evaluate (epoch 62) -- logp(x) = -0.377 +/- 0.025
Evaluate (epoch 63) -- logp(x) = -0.391 +/- 0.024
Evaluate (epoch 64) -- logp(x) = -0.452 +/- 0.026
Evaluate (epoch 65) -- logp(x) = -0.430 +/- 0.025
Evaluate (epoch 66) -- logp(x) = -0.362 +/- 0.024
Evaluate (epoch 67) -- logp(x) = -0.421 +/- 0.025
Evaluate (epoch 68) -- logp(x) = -0.408 +/- 0.025
Evaluate (epoch 69) -- logp(x) = -0.418 +/- 0.027
Evaluate (epoch 70) -- logp(x) = -0.549 +/- 0.026
Evaluate (epoch 71) -- logp(x) = -0.354 +/- 0.026
Evaluate (epoch 72) -- logp(x) = -0.365 +/- 0.027
Evaluate (epoch 73) -- logp(x) = -0.393 +/- 0.028
Evaluate (epoch 74) -- logp(x) = -0.364 +/- 0.029
Evaluate (epoch 75) -- logp(x) = -0.424 +/- 0.026
Evaluate (epoch 76) -- logp(x) = -0.331 +/- 0.024
Evaluate (epoch 77) -- logp(x) = -0.375 +/- 0.027
Evaluate (epoch 78) -- logp(x) = -0.379 +/- 0.026
Evaluate (epoch 79) -- logp(x) = -0.300 +/- 0.025
Evaluate (epoch 80) -- logp(x) = -0.337 +/- 0.027
Evaluate (epoch 81) -- logp(x) = -0.305 +/- 0.025
Evaluate (epoch 82) -- logp(x) = -0.307 +/- 0.027
Evaluate (epoch 83) -- logp(x) = -0.478 +/- 0.027
Evaluate (epoch 84) -- logp(x) = -0.380 +/- 0.025
Evaluate (epoch 85) -- logp(x) = -0.308 +/- 0.026
Evaluate (epoch 86) -- logp(x) = -0.301 +/- 0.025
Evaluate (epoch 87) -- logp(x) = -0.321 +/- 0.025
Evaluate (epoch 88) -- logp(x) = -0.339 +/- 0.026
Evaluate (epoch 89) -- logp(x) = -0.277 +/- 0.026
Evaluate (epoch 90) -- logp(x) = -0.295 +/- 0.026
Evaluate (epoch 91) -- logp(x) = -0.294 +/- 0.024
Evaluate (epoch 92) -- logp(x) = -0.289 +/- 0.024
Evaluate (epoch 93) -- logp(x) = -0.274 +/- 0.025
Evaluate (epoch 94) -- logp(x) = -0.298 +/- 0.026
Evaluate (epoch 95) -- logp(x) = -0.262 +/- 0.026
Evaluate (epoch 96) -- logp(x) = -0.250 +/- 0.027
Evaluate (epoch 97) -- logp(x) = -0.299 +/- 0.026
Evaluate (epoch 98) -- logp(x) = -0.300 +/- 0.024
Evaluate (epoch 99) -- logp(x) = -0.264 +/- 0.025
Evaluate (epoch 100) -- logp(x) = -0.343 +/- 0.024
Evaluate (epoch 101) -- logp(x) = -0.307 +/- 0.023
Evaluate (epoch 102) -- logp(x) = -0.267 +/- 0.025
Evaluate (epoch 103) -- logp(x) = -0.328 +/- 0.027
Evaluate (epoch 104) -- logp(x) = -0.333 +/- 0.031
Evaluate (epoch 105) -- logp(x) = -0.288 +/- 0.026
Evaluate (epoch 106) -- logp(x) = -0.303 +/- 0.024
Evaluate (epoch 107) -- logp(x) = -0.350 +/- 0.027
Evaluate (epoch 108) -- logp(x) = -0.283 +/- 0.025
Evaluate (epoch 109) -- logp(x) = -0.382 +/- 0.028
Evaluate (epoch 110) -- logp(x) = -0.331 +/- 0.027
Evaluate (epoch 111) -- logp(x) = -0.271 +/- 0.025
Evaluate (epoch 112) -- logp(x) = -0.263 +/- 0.025
Evaluate (epoch 113) -- logp(x) = -0.350 +/- 0.027
Evaluate (epoch 114) -- logp(x) = -0.275 +/- 0.026
Evaluate (epoch 115) -- logp(x) = -0.239 +/- 0.028
Evaluate (epoch 116) -- logp(x) = -0.245 +/- 0.028
Evaluate (epoch 117) -- logp(x) = -0.267 +/- 0.025
Evaluate (epoch 118) -- logp(x) = -0.231 +/- 0.026
Evaluate (epoch 119) -- logp(x) = -0.242 +/- 0.027
Evaluate (epoch 120) -- logp(x) = -0.242 +/- 0.028
Evaluate (epoch 121) -- logp(x) = -0.239 +/- 0.025
Evaluate (epoch 122) -- logp(x) = -0.273 +/- 0.025
Evaluate (epoch 123) -- logp(x) = -0.223 +/- 0.025
Evaluate (epoch 124) -- logp(x) = -0.238 +/- 0.026
Evaluate (epoch 125) -- logp(x) = -0.220 +/- 0.026
Evaluate (epoch 126) -- logp(x) = -0.312 +/- 0.027
Evaluate (epoch 127) -- logp(x) = -0.212 +/- 0.026
Evaluate (epoch 128) -- logp(x) = -0.292 +/- 0.026
Evaluate (epoch 129) -- logp(x) = -0.224 +/- 0.026
Evaluate (epoch 130) -- logp(x) = -0.210 +/- 0.026
Evaluate (epoch 131) -- logp(x) = -0.220 +/- 0.026
Evaluate (epoch 132) -- logp(x) = -0.227 +/- 0.025
Evaluate (epoch 133) -- logp(x) = -0.190 +/- 0.027
Evaluate (epoch 134) -- logp(x) = -0.338 +/- 0.025
Evaluate (epoch 135) -- logp(x) = -0.206 +/- 0.025
Evaluate (epoch 136) -- logp(x) = -0.185 +/- 0.026
Evaluate (epoch 137) -- logp(x) = -0.225 +/- 0.026
Evaluate (epoch 138) -- logp(x) = -0.241 +/- 0.025
Evaluate (epoch 139) -- logp(x) = -0.207 +/- 0.026
Evaluate (epoch 140) -- logp(x) = -0.176 +/- 0.026
Evaluate (epoch 141) -- logp(x) = -0.205 +/- 0.026
Evaluate (epoch 142) -- logp(x) = -0.177 +/- 0.028
Evaluate (epoch 143) -- logp(x) = -0.175 +/- 0.028
Evaluate (epoch 144) -- logp(x) = -0.218 +/- 0.026
Evaluate (epoch 145) -- logp(x) = -0.194 +/- 0.027
Evaluate (epoch 146) -- logp(x) = -0.220 +/- 0.027
Evaluate (epoch 147) -- logp(x) = -0.168 +/- 0.027
Evaluate (epoch 148) -- logp(x) = -0.264 +/- 0.027
Evaluate (epoch 149) -- logp(x) = -0.261 +/- 0.026
Evaluate (epoch 150) -- logp(x) = -0.259 +/- 0.030
Evaluate (epoch 151) -- logp(x) = -0.225 +/- 0.025
Evaluate (epoch 152) -- logp(x) = -0.231 +/- 0.027
Evaluate (epoch 153) -- logp(x) = -0.308 +/- 0.027
Evaluate (epoch 154) -- logp(x) = -0.294 +/- 0.028
Evaluate (epoch 155) -- logp(x) = -0.213 +/- 0.026
Evaluate (epoch 156) -- logp(x) = -0.201 +/- 0.027
Evaluate (epoch 157) -- logp(x) = -0.195 +/- 0.027
Evaluate (epoch 158) -- logp(x) = -0.331 +/- 0.027
Evaluate (epoch 159) -- logp(x) = -0.216 +/- 0.028
Evaluate (epoch 160) -- logp(x) = -0.243 +/- 0.025
Evaluate (epoch 161) -- logp(x) = -0.296 +/- 0.026
Evaluate (epoch 162) -- logp(x) = -0.150 +/- 0.028
Evaluate (epoch 163) -- logp(x) = -0.177 +/- 0.027
Evaluate (epoch 164) -- logp(x) = -0.177 +/- 0.027
Evaluate (epoch 165) -- logp(x) = -0.195 +/- 0.027
Evaluate (epoch 166) -- logp(x) = -0.266 +/- 0.027
Evaluate (epoch 167) -- logp(x) = -0.260 +/- 0.027
Evaluate (epoch 168) -- logp(x) = -0.166 +/- 0.028
Evaluate (epoch 169) -- logp(x) = -0.142 +/- 0.028
Evaluate (epoch 170) -- logp(x) = -0.155 +/- 0.030
Evaluate (epoch 171) -- logp(x) = -0.175 +/- 0.028
Evaluate (epoch 172) -- logp(x) = -0.220 +/- 0.027
Evaluate (epoch 173) -- logp(x) = -0.160 +/- 0.026
Evaluate (epoch 174) -- logp(x) = -0.196 +/- 0.027
Evaluate (epoch 175) -- logp(x) = -0.166 +/- 0.026
Evaluate (epoch 176) -- logp(x) = -0.189 +/- 0.029
Evaluate (epoch 177) -- logp(x) = -0.180 +/- 0.028
Evaluate (epoch 178) -- logp(x) = -0.153 +/- 0.026
Evaluate (epoch 179) -- logp(x) = -0.192 +/- 0.030
Evaluate (epoch 180) -- logp(x) = -0.143 +/- 0.027
Evaluate (epoch 181) -- logp(x) = -0.161 +/- 0.027
Evaluate (epoch 182) -- logp(x) = -0.337 +/- 0.027
Evaluate (epoch 183) -- logp(x) = -0.281 +/- 0.029
Evaluate (epoch 184) -- logp(x) = -0.268 +/- 0.027
Evaluate (epoch 185) -- logp(x) = -0.257 +/- 0.031
Evaluate (epoch 186) -- logp(x) = -0.315 +/- 0.030
Evaluate (epoch 187) -- logp(x) = -0.199 +/- 0.029
Evaluate (epoch 188) -- logp(x) = -0.263 +/- 0.027
Evaluate (epoch 189) -- logp(x) = -0.289 +/- 0.033
Evaluate (epoch 190) -- logp(x) = -0.232 +/- 0.026
Evaluate (epoch 191) -- logp(x) = -0.211 +/- 0.028
Evaluate (epoch 192) -- logp(x) = -0.210 +/- 0.028
Evaluate (epoch 193) -- logp(x) = -0.188 +/- 0.031
Evaluate (epoch 194) -- logp(x) = -0.199 +/- 0.028
Evaluate (epoch 195) -- logp(x) = -0.194 +/- 0.029
Evaluate (epoch 196) -- logp(x) = -0.190 +/- 0.032
Evaluate (epoch 197) -- logp(x) = -0.188 +/- 0.027
Evaluate (epoch 198) -- logp(x) = -0.189 +/- 0.029
Evaluate (epoch 199) -- logp(x) = -0.230 +/- 0.028
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.008 +/- 0.002
Evaluate (epoch 1) -- logp(x) = -1.003 +/- 0.022
Evaluate (epoch 2) -- logp(x) = -0.686 +/- 0.025
Evaluate (epoch 3) -- logp(x) = -0.669 +/- 0.024
Evaluate (epoch 4) -- logp(x) = -0.446 +/- 0.025
Evaluate (epoch 5) -- logp(x) = -0.113 +/- 0.028
Evaluate (epoch 6) -- logp(x) = -0.055 +/- 0.027
Evaluate (epoch 7) -- logp(x) = 0.091 +/- 0.025
Evaluate (epoch 8) -- logp(x) = 0.138 +/- 0.025
Evaluate (epoch 9) -- logp(x) = 0.245 +/- 0.024
Evaluate (epoch 10) -- logp(x) = 0.214 +/- 0.023
Evaluate (epoch 11) -- logp(x) = 0.259 +/- 0.022
Evaluate (epoch 12) -- logp(x) = 0.378 +/- 0.022
Evaluate (epoch 13) -- logp(x) = 0.395 +/- 0.024
Evaluate (epoch 14) -- logp(x) = 0.402 +/- 0.021
Evaluate (epoch 15) -- logp(x) = 0.455 +/- 0.023
Evaluate (epoch 16) -- logp(x) = 0.506 +/- 0.022
Evaluate (epoch 17) -- logp(x) = 0.552 +/- 0.021
Evaluate (epoch 18) -- logp(x) = 0.546 +/- 0.022
Evaluate (epoch 19) -- logp(x) = 0.554 +/- 0.021
Evaluate (epoch 20) -- logp(x) = 0.549 +/- 0.021
Evaluate (epoch 21) -- logp(x) = 0.200 +/- 0.022
Evaluate (epoch 22) -- logp(x) = 0.454 +/- 0.020
Evaluate (epoch 23) -- logp(x) = 0.613 +/- 0.021
Evaluate (epoch 24) -- logp(x) = 0.618 +/- 0.021
Evaluate (epoch 25) -- logp(x) = 0.328 +/- 0.024
Evaluate (epoch 26) -- logp(x) = 0.626 +/- 0.021
Evaluate (epoch 27) -- logp(x) = 0.626 +/- 0.023
Evaluate (epoch 28) -- logp(x) = 0.563 +/- 0.025
Evaluate (epoch 29) -- logp(x) = 0.406 +/- 0.021
Evaluate (epoch 30) -- logp(x) = 0.685 +/- 0.021
Evaluate (epoch 31) -- logp(x) = 0.611 +/- 0.023
Evaluate (epoch 32) -- logp(x) = 0.668 +/- 0.021
Evaluate (epoch 33) -- logp(x) = 0.504 +/- 0.021
Evaluate (epoch 34) -- logp(x) = 0.607 +/- 0.022
Evaluate (epoch 35) -- logp(x) = 0.607 +/- 0.024
Evaluate (epoch 36) -- logp(x) = 0.673 +/- 0.021
Evaluate (epoch 37) -- logp(x) = 0.691 +/- 0.020
Evaluate (epoch 38) -- logp(x) = 0.657 +/- 0.022
Evaluate (epoch 39) -- logp(x) = 0.668 +/- 0.024
Evaluate (epoch 40) -- logp(x) = 0.582 +/- 0.023
Evaluate (epoch 41) -- logp(x) = 0.710 +/- 0.021
Evaluate (epoch 42) -- logp(x) = 0.597 +/- 0.021
Evaluate (epoch 43) -- logp(x) = 0.697 +/- 0.021
Evaluate (epoch 44) -- logp(x) = 0.718 +/- 0.019
Evaluate (epoch 45) -- logp(x) = 0.625 +/- 0.021
Evaluate (epoch 46) -- logp(x) = 0.678 +/- 0.020
Evaluate (epoch 47) -- logp(x) = 0.540 +/- 0.025
Evaluate (epoch 48) -- logp(x) = 0.739 +/- 0.020
Evaluate (epoch 49) -- logp(x) = 0.737 +/- 0.021
Evaluate (epoch 50) -- logp(x) = 0.721 +/- 0.021
Evaluate (epoch 51) -- logp(x) = 0.716 +/- 0.021
Evaluate (epoch 52) -- logp(x) = 0.682 +/- 0.020
Evaluate (epoch 53) -- logp(x) = 0.761 +/- 0.020
Evaluate (epoch 54) -- logp(x) = 0.553 +/- 0.026
Evaluate (epoch 55) -- logp(x) = 0.745 +/- 0.021
Evaluate (epoch 56) -- logp(x) = 0.670 +/- 0.025
Evaluate (epoch 57) -- logp(x) = 0.724 +/- 0.020
Evaluate (epoch 58) -- logp(x) = 0.779 +/- 0.021
Evaluate (epoch 59) -- logp(x) = 0.479 +/- 0.022
Evaluate (epoch 60) -- logp(x) = 0.826 +/- 0.021
Evaluate (epoch 61) -- logp(x) = 0.686 +/- 0.024
Evaluate (epoch 62) -- logp(x) = 0.657 +/- 0.027
Evaluate (epoch 63) -- logp(x) = 0.770 +/- 0.026
Evaluate (epoch 64) -- logp(x) = 0.487 +/- 0.029
Evaluate (epoch 65) -- logp(x) = 0.717 +/- 0.020
Evaluate (epoch 66) -- logp(x) = 0.742 +/- 0.022
Evaluate (epoch 67) -- logp(x) = 0.809 +/- 0.021
Evaluate (epoch 68) -- logp(x) = 0.762 +/- 0.019
Evaluate (epoch 69) -- logp(x) = 0.798 +/- 0.020
Evaluate (epoch 70) -- logp(x) = 0.724 +/- 0.023
Evaluate (epoch 71) -- logp(x) = 0.781 +/- 0.022
Evaluate (epoch 72) -- logp(x) = 0.707 +/- 0.024
Evaluate (epoch 73) -- logp(x) = 0.723 +/- 0.020
Evaluate (epoch 74) -- logp(x) = 0.742 +/- 0.021
Evaluate (epoch 75) -- logp(x) = 0.779 +/- 0.023
Evaluate (epoch 76) -- logp(x) = 0.635 +/- 0.025
Evaluate (epoch 77) -- logp(x) = 0.687 +/- 0.020
Evaluate (epoch 78) -- logp(x) = 0.807 +/- 0.020
Evaluate (epoch 79) -- logp(x) = 0.775 +/- 0.021
Evaluate (epoch 80) -- logp(x) = 0.851 +/- 0.018
Evaluate (epoch 81) -- logp(x) = 0.858 +/- 0.020
Evaluate (epoch 82) -- logp(x) = 0.831 +/- 0.019
Evaluate (epoch 83) -- logp(x) = 0.682 +/- 0.025
Evaluate (epoch 84) -- logp(x) = 0.792 +/- 0.023
Evaluate (epoch 85) -- logp(x) = 0.762 +/- 0.020
Evaluate (epoch 86) -- logp(x) = 0.820 +/- 0.019
Evaluate (epoch 87) -- logp(x) = 0.882 +/- 0.020
Evaluate (epoch 88) -- logp(x) = 0.812 +/- 0.019
Evaluate (epoch 89) -- logp(x) = 0.908 +/- 0.020
Evaluate (epoch 90) -- logp(x) = 0.725 +/- 0.022
Evaluate (epoch 91) -- logp(x) = 0.788 +/- 0.018
Evaluate (epoch 92) -- logp(x) = 0.883 +/- 0.020
Evaluate (epoch 93) -- logp(x) = 0.902 +/- 0.020
Evaluate (epoch 94) -- logp(x) = 0.898 +/- 0.020
Evaluate (epoch 95) -- logp(x) = 0.740 +/- 0.022
Evaluate (epoch 96) -- logp(x) = 0.718 +/- 0.022
Evaluate (epoch 97) -- logp(x) = 0.920 +/- 0.020
Evaluate (epoch 98) -- logp(x) = 0.827 +/- 0.019
Evaluate (epoch 99) -- logp(x) = 0.826 +/- 0.022
Evaluate (epoch 100) -- logp(x) = 0.761 +/- 0.024
Evaluate (epoch 101) -- logp(x) = 0.849 +/- 0.021
Evaluate (epoch 102) -- logp(x) = 0.583 +/- 0.021
Evaluate (epoch 103) -- logp(x) = 0.843 +/- 0.022
Evaluate (epoch 104) -- logp(x) = 0.886 +/- 0.020
Evaluate (epoch 105) -- logp(x) = 0.793 +/- 0.019
Evaluate (epoch 106) -- logp(x) = 0.572 +/- 0.025
Evaluate (epoch 107) -- logp(x) = 0.814 +/- 0.020
Evaluate (epoch 108) -- logp(x) = 0.839 +/- 0.019
Evaluate (epoch 109) -- logp(x) = 0.876 +/- 0.020
Evaluate (epoch 110) -- logp(x) = 0.874 +/- 0.021
Evaluate (epoch 111) -- logp(x) = 0.806 +/- 0.022
Evaluate (epoch 112) -- logp(x) = 0.853 +/- 0.021
Evaluate (epoch 113) -- logp(x) = 0.888 +/- 0.021
Evaluate (epoch 114) -- logp(x) = 0.850 +/- 0.019
Evaluate (epoch 115) -- logp(x) = 0.813 +/- 0.020
Evaluate (epoch 116) -- logp(x) = 0.827 +/- 0.021
Evaluate (epoch 117) -- logp(x) = 0.887 +/- 0.021
Evaluate (epoch 118) -- logp(x) = 0.906 +/- 0.020
Evaluate (epoch 119) -- logp(x) = 0.831 +/- 0.020
Evaluate (epoch 120) -- logp(x) = 0.770 +/- 0.024
Evaluate (epoch 121) -- logp(x) = 0.696 +/- 0.019
Evaluate (epoch 122) -- logp(x) = 0.891 +/- 0.021
Evaluate (epoch 123) -- logp(x) = 0.861 +/- 0.022
Evaluate (epoch 124) -- logp(x) = 0.915 +/- 0.020
Evaluate (epoch 125) -- logp(x) = 0.890 +/- 0.020
Evaluate (epoch 126) -- logp(x) = 0.934 +/- 0.019
Evaluate (epoch 127) -- logp(x) = 0.853 +/- 0.018
Evaluate (epoch 128) -- logp(x) = 0.908 +/- 0.021
Evaluate (epoch 129) -- logp(x) = 0.756 +/- 0.020
Evaluate (epoch 130) -- logp(x) = 0.945 +/- 0.020
Evaluate (epoch 131) -- logp(x) = 0.923 +/- 0.020
Evaluate (epoch 132) -- logp(x) = 0.915 +/- 0.019
Evaluate (epoch 133) -- logp(x) = 0.811 +/- 0.024
Evaluate (epoch 134) -- logp(x) = 0.945 +/- 0.019
Evaluate (epoch 135) -- logp(x) = 0.929 +/- 0.019
Evaluate (epoch 136) -- logp(x) = 0.861 +/- 0.023
Evaluate (epoch 137) -- logp(x) = 0.925 +/- 0.020
Evaluate (epoch 138) -- logp(x) = 0.841 +/- 0.023
Evaluate (epoch 139) -- logp(x) = 0.961 +/- 0.019
Evaluate (epoch 140) -- logp(x) = 0.971 +/- 0.019
Evaluate (epoch 141) -- logp(x) = 0.897 +/- 0.020
Evaluate (epoch 142) -- logp(x) = 0.820 +/- 0.025
Evaluate (epoch 143) -- logp(x) = 0.898 +/- 0.022
Evaluate (epoch 144) -- logp(x) = 0.947 +/- 0.020
Evaluate (epoch 145) -- logp(x) = 0.967 +/- 0.018
Evaluate (epoch 146) -- logp(x) = 0.947 +/- 0.019
Evaluate (epoch 147) -- logp(x) = 0.971 +/- 0.020
Evaluate (epoch 148) -- logp(x) = 0.893 +/- 0.022
Evaluate (epoch 149) -- logp(x) = 0.936 +/- 0.019
Evaluate (epoch 150) -- logp(x) = 0.898 +/- 0.020
Evaluate (epoch 151) -- logp(x) = 0.921 +/- 0.019
Evaluate (epoch 152) -- logp(x) = 0.929 +/- 0.020
Evaluate (epoch 153) -- logp(x) = 0.963 +/- 0.021
Evaluate (epoch 154) -- logp(x) = 0.996 +/- 0.018
Evaluate (epoch 155) -- logp(x) = 0.917 +/- 0.020
Evaluate (epoch 156) -- logp(x) = 0.937 +/- 0.019
Evaluate (epoch 157) -- logp(x) = 0.971 +/- 0.019
Evaluate (epoch 158) -- logp(x) = 0.813 +/- 0.022
Evaluate (epoch 159) -- logp(x) = 0.952 +/- 0.020
Evaluate (epoch 160) -- logp(x) = 1.007 +/- 0.018
Evaluate (epoch 161) -- logp(x) = 0.973 +/- 0.019
Evaluate (epoch 162) -- logp(x) = 0.933 +/- 0.019
Evaluate (epoch 163) -- logp(x) = 0.805 +/- 0.021
Evaluate (epoch 164) -- logp(x) = 0.990 +/- 0.020
Evaluate (epoch 165) -- logp(x) = 0.967 +/- 0.019
Evaluate (epoch 166) -- logp(x) = 0.870 +/- 0.023
Evaluate (epoch 167) -- logp(x) = 0.831 +/- 0.024
Evaluate (epoch 168) -- logp(x) = 0.886 +/- 0.018
Evaluate (epoch 169) -- logp(x) = 0.921 +/- 0.019
Evaluate (epoch 170) -- logp(x) = 1.000 +/- 0.019
Evaluate (epoch 171) -- logp(x) = 0.964 +/- 0.020
Evaluate (epoch 172) -- logp(x) = 1.003 +/- 0.020
Evaluate (epoch 173) -- logp(x) = 0.951 +/- 0.022
Evaluate (epoch 174) -- logp(x) = 0.962 +/- 0.020
Evaluate (epoch 175) -- logp(x) = 1.024 +/- 0.018
Evaluate (epoch 176) -- logp(x) = 0.917 +/- 0.019
Evaluate (epoch 177) -- logp(x) = 0.983 +/- 0.019
Evaluate (epoch 178) -- logp(x) = 0.981 +/- 0.020
Evaluate (epoch 179) -- logp(x) = 1.018 +/- 0.017
Evaluate (epoch 180) -- logp(x) = 0.945 +/- 0.018
Evaluate (epoch 181) -- logp(x) = 0.925 +/- 0.020
Evaluate (epoch 182) -- logp(x) = 0.929 +/- 0.020
Evaluate (epoch 183) -- logp(x) = 0.927 +/- 0.022
Evaluate (epoch 184) -- logp(x) = 0.942 +/- 0.021
Evaluate (epoch 185) -- logp(x) = 0.902 +/- 0.032
Evaluate (epoch 186) -- logp(x) = 0.918 +/- 0.022
Evaluate (epoch 187) -- logp(x) = 0.942 +/- 0.020
Evaluate (epoch 188) -- logp(x) = 1.009 +/- 0.019
Evaluate (epoch 189) -- logp(x) = 0.816 +/- 0.025
Evaluate (epoch 190) -- logp(x) = 0.824 +/- 0.023
Evaluate (epoch 191) -- logp(x) = 0.926 +/- 0.023
Evaluate (epoch 192) -- logp(x) = 1.031 +/- 0.018
Evaluate (epoch 193) -- logp(x) = 0.997 +/- 0.019
Evaluate (epoch 194) -- logp(x) = 1.016 +/- 0.018
Evaluate (epoch 195) -- logp(x) = 0.988 +/- 0.021
Evaluate (epoch 196) -- logp(x) = 0.881 +/- 0.026
Evaluate (epoch 197) -- logp(x) = 0.998 +/- 0.018
Evaluate (epoch 198) -- logp(x) = 0.965 +/- 0.020
Evaluate (epoch 199) -- logp(x) = 1.025 +/- 0.022
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'CIRCLE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': './results/realnvp/best_model_checkpoint.pt',
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 193,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -2.653 +/- 0.014
Evaluate (epoch 1) -- logp(x) = -2.629 +/- 0.014
Evaluate (epoch 2) -- logp(x) = -2.594 +/- 0.013
Evaluate (epoch 3) -- logp(x) = -2.546 +/- 0.013
Evaluate (epoch 4) -- logp(x) = -2.490 +/- 0.012
Evaluate (epoch 5) -- logp(x) = -2.423 +/- 0.014
Evaluate (epoch 6) -- logp(x) = -2.330 +/- 0.013
Evaluate (epoch 7) -- logp(x) = -2.270 +/- 0.012
Evaluate (epoch 8) -- logp(x) = -2.225 +/- 0.012
Evaluate (epoch 9) -- logp(x) = -2.185 +/- 0.013
Evaluate (epoch 10) -- logp(x) = -2.183 +/- 0.013
Evaluate (epoch 11) -- logp(x) = -2.103 +/- 0.014
Evaluate (epoch 12) -- logp(x) = -2.093 +/- 0.014
Evaluate (epoch 13) -- logp(x) = -2.039 +/- 0.013
Evaluate (epoch 14) -- logp(x) = -1.999 +/- 0.015
Evaluate (epoch 15) -- logp(x) = -1.950 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -1.946 +/- 0.015
Evaluate (epoch 17) -- logp(x) = -1.943 +/- 0.017
Evaluate (epoch 18) -- logp(x) = -1.928 +/- 0.016
Evaluate (epoch 19) -- logp(x) = -1.871 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -1.908 +/- 0.016
Evaluate (epoch 21) -- logp(x) = -1.847 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -1.814 +/- 0.019
Evaluate (epoch 23) -- logp(x) = -1.862 +/- 0.025
Evaluate (epoch 24) -- logp(x) = -1.844 +/- 0.015
Evaluate (epoch 25) -- logp(x) = -1.763 +/- 0.018
Evaluate (epoch 26) -- logp(x) = -1.753 +/- 0.017
Evaluate (epoch 27) -- logp(x) = -1.721 +/- 0.018
Evaluate (epoch 28) -- logp(x) = -1.786 +/- 0.018
Evaluate (epoch 29) -- logp(x) = -1.816 +/- 0.018
Evaluate (epoch 30) -- logp(x) = -1.773 +/- 0.017
Evaluate (epoch 31) -- logp(x) = -1.769 +/- 0.022
Evaluate (epoch 32) -- logp(x) = -1.894 +/- 0.052
Evaluate (epoch 33) -- logp(x) = -1.674 +/- 0.018
Evaluate (epoch 34) -- logp(x) = -1.650 +/- 0.019
Evaluate (epoch 35) -- logp(x) = -1.672 +/- 0.018
Evaluate (epoch 36) -- logp(x) = -1.761 +/- 0.015
Evaluate (epoch 37) -- logp(x) = -1.638 +/- 0.019
Evaluate (epoch 38) -- logp(x) = -1.623 +/- 0.018
Evaluate (epoch 39) -- logp(x) = -1.600 +/- 0.019
Evaluate (epoch 40) -- logp(x) = -1.617 +/- 0.020
Evaluate (epoch 41) -- logp(x) = -1.600 +/- 0.019
Evaluate (epoch 42) -- logp(x) = -1.729 +/- 0.020
Evaluate (epoch 43) -- logp(x) = -1.601 +/- 0.021
Evaluate (epoch 44) -- logp(x) = -1.604 +/- 0.020
Evaluate (epoch 45) -- logp(x) = -1.605 +/- 0.019
Evaluate (epoch 46) -- logp(x) = -1.548 +/- 0.023
Evaluate (epoch 47) -- logp(x) = -1.582 +/- 0.020
Evaluate (epoch 48) -- logp(x) = -1.562 +/- 0.021
Evaluate (epoch 49) -- logp(x) = -1.531 +/- 0.027
Evaluate (epoch 50) -- logp(x) = -1.529 +/- 0.020
Evaluate (epoch 51) -- logp(x) = -1.494 +/- 0.021
Evaluate (epoch 52) -- logp(x) = -1.533 +/- 0.020
Evaluate (epoch 53) -- logp(x) = -1.461 +/- 0.021
Evaluate (epoch 54) -- logp(x) = -1.474 +/- 0.020
Evaluate (epoch 55) -- logp(x) = -1.568 +/- 0.021
Evaluate (epoch 56) -- logp(x) = -1.433 +/- 0.022
Evaluate (epoch 57) -- logp(x) = -1.541 +/- 0.020
Evaluate (epoch 58) -- logp(x) = -1.459 +/- 0.020
Evaluate (epoch 59) -- logp(x) = -1.483 +/- 0.022
Evaluate (epoch 60) -- logp(x) = -1.450 +/- 0.021
Evaluate (epoch 61) -- logp(x) = -1.455 +/- 0.021
Evaluate (epoch 62) -- logp(x) = -1.413 +/- 0.021
Evaluate (epoch 63) -- logp(x) = -1.461 +/- 0.023
Evaluate (epoch 64) -- logp(x) = -1.380 +/- 0.023
Evaluate (epoch 65) -- logp(x) = -1.433 +/- 0.021
Evaluate (epoch 66) -- logp(x) = -1.370 +/- 0.021
Evaluate (epoch 67) -- logp(x) = -1.377 +/- 0.023
Evaluate (epoch 68) -- logp(x) = -1.563 +/- 0.020
Evaluate (epoch 69) -- logp(x) = -1.854 +/- 0.021
Evaluate (epoch 70) -- logp(x) = -1.576 +/- 0.020
Evaluate (epoch 71) -- logp(x) = -1.415 +/- 0.021
Evaluate (epoch 72) -- logp(x) = -1.357 +/- 0.022
Evaluate (epoch 73) -- logp(x) = -1.361 +/- 0.021
Evaluate (epoch 74) -- logp(x) = -1.360 +/- 0.022
Evaluate (epoch 75) -- logp(x) = -1.420 +/- 0.022
Evaluate (epoch 76) -- logp(x) = -1.320 +/- 0.022
Evaluate (epoch 77) -- logp(x) = -1.335 +/- 0.021
Evaluate (epoch 78) -- logp(x) = -1.338 +/- 0.024
Evaluate (epoch 79) -- logp(x) = -1.343 +/- 0.022
Evaluate (epoch 80) -- logp(x) = -1.334 +/- 0.023
Evaluate (epoch 81) -- logp(x) = -1.300 +/- 0.023
Evaluate (epoch 82) -- logp(x) = -1.312 +/- 0.023
Evaluate (epoch 83) -- logp(x) = -1.378 +/- 0.024
Evaluate (epoch 84) -- logp(x) = -1.322 +/- 0.025
Evaluate (epoch 85) -- logp(x) = -1.324 +/- 0.023
Evaluate (epoch 86) -- logp(x) = -1.344 +/- 0.024
Evaluate (epoch 87) -- logp(x) = -1.266 +/- 0.022
Evaluate (epoch 88) -- logp(x) = -1.274 +/- 0.023
Evaluate (epoch 89) -- logp(x) = -1.359 +/- 0.022
Evaluate (epoch 90) -- logp(x) = -1.314 +/- 0.025
Evaluate (epoch 91) -- logp(x) = -1.305 +/- 0.021
Evaluate (epoch 92) -- logp(x) = -1.406 +/- 0.022
Evaluate (epoch 93) -- logp(x) = -1.246 +/- 0.022
Evaluate (epoch 94) -- logp(x) = -1.250 +/- 0.022
Evaluate (epoch 95) -- logp(x) = -1.314 +/- 0.024
Evaluate (epoch 96) -- logp(x) = -1.306 +/- 0.023
Evaluate (epoch 97) -- logp(x) = -1.290 +/- 0.023
Evaluate (epoch 98) -- logp(x) = -1.223 +/- 0.023
Evaluate (epoch 99) -- logp(x) = -1.278 +/- 0.022
Evaluate (epoch 100) -- logp(x) = -1.248 +/- 0.023
Evaluate (epoch 101) -- logp(x) = -1.315 +/- 0.024
Evaluate (epoch 102) -- logp(x) = -1.268 +/- 0.023
Evaluate (epoch 103) -- logp(x) = -1.227 +/- 0.023
Evaluate (epoch 104) -- logp(x) = -1.279 +/- 0.023
Evaluate (epoch 105) -- logp(x) = -1.218 +/- 0.023
Evaluate (epoch 106) -- logp(x) = -1.242 +/- 0.023
Evaluate (epoch 107) -- logp(x) = -1.258 +/- 0.022
Evaluate (epoch 108) -- logp(x) = -1.241 +/- 0.024
Evaluate (epoch 109) -- logp(x) = -1.246 +/- 0.023
Evaluate (epoch 110) -- logp(x) = -1.280 +/- 0.027
Evaluate (epoch 111) -- logp(x) = -1.315 +/- 0.022
Evaluate (epoch 112) -- logp(x) = -1.209 +/- 0.022
Evaluate (epoch 113) -- logp(x) = -1.244 +/- 0.023
Evaluate (epoch 114) -- logp(x) = -1.220 +/- 0.023
Evaluate (epoch 115) -- logp(x) = -1.497 +/- 0.023
Evaluate (epoch 116) -- logp(x) = -1.303 +/- 0.022
Evaluate (epoch 117) -- logp(x) = -1.224 +/- 0.023
Evaluate (epoch 118) -- logp(x) = -1.290 +/- 0.023
Evaluate (epoch 119) -- logp(x) = -1.183 +/- 0.022
Evaluate (epoch 120) -- logp(x) = -1.207 +/- 0.023
Evaluate (epoch 121) -- logp(x) = -1.197 +/- 0.023
Evaluate (epoch 122) -- logp(x) = -1.244 +/- 0.022
Evaluate (epoch 123) -- logp(x) = -1.245 +/- 0.022
Evaluate (epoch 124) -- logp(x) = -1.164 +/- 0.023
Evaluate (epoch 125) -- logp(x) = -1.178 +/- 0.023
Evaluate (epoch 126) -- logp(x) = -1.209 +/- 0.023
Evaluate (epoch 127) -- logp(x) = -1.193 +/- 0.023
Evaluate (epoch 128) -- logp(x) = -1.174 +/- 0.024
Evaluate (epoch 129) -- logp(x) = -1.167 +/- 0.024
Evaluate (epoch 130) -- logp(x) = -1.257 +/- 0.030
Evaluate (epoch 131) -- logp(x) = -1.184 +/- 0.024
Evaluate (epoch 132) -- logp(x) = -1.264 +/- 0.026
Evaluate (epoch 133) -- logp(x) = -1.204 +/- 0.023
Evaluate (epoch 134) -- logp(x) = -1.208 +/- 0.023
Evaluate (epoch 135) -- logp(x) = -1.142 +/- 0.023
Evaluate (epoch 136) -- logp(x) = -1.257 +/- 0.022
Evaluate (epoch 137) -- logp(x) = -1.137 +/- 0.023
Evaluate (epoch 138) -- logp(x) = -1.175 +/- 0.024
Evaluate (epoch 139) -- logp(x) = -1.342 +/- 0.023
Evaluate (epoch 140) -- logp(x) = -1.161 +/- 0.023
Evaluate (epoch 141) -- logp(x) = -1.191 +/- 0.027
Evaluate (epoch 142) -- logp(x) = -1.136 +/- 0.023
Evaluate (epoch 143) -- logp(x) = -1.148 +/- 0.023
Evaluate (epoch 144) -- logp(x) = -1.168 +/- 0.023
Evaluate (epoch 145) -- logp(x) = -1.192 +/- 0.023
Evaluate (epoch 146) -- logp(x) = -1.187 +/- 0.024
Evaluate (epoch 147) -- logp(x) = -1.134 +/- 0.023
Evaluate (epoch 148) -- logp(x) = -1.245 +/- 0.027
Evaluate (epoch 149) -- logp(x) = -1.106 +/- 0.024
Evaluate (epoch 150) -- logp(x) = -1.140 +/- 0.025
Evaluate (epoch 151) -- logp(x) = -1.165 +/- 0.024
Evaluate (epoch 152) -- logp(x) = -1.141 +/- 0.023
Evaluate (epoch 153) -- logp(x) = -1.177 +/- 0.023
Evaluate (epoch 154) -- logp(x) = -1.142 +/- 0.023
Evaluate (epoch 155) -- logp(x) = -1.217 +/- 0.024
Evaluate (epoch 156) -- logp(x) = -1.128 +/- 0.024
Evaluate (epoch 157) -- logp(x) = -1.150 +/- 0.023
Evaluate (epoch 158) -- logp(x) = -1.146 +/- 0.023
Evaluate (epoch 159) -- logp(x) = -1.098 +/- 0.023
Evaluate (epoch 160) -- logp(x) = -1.092 +/- 0.024
Evaluate (epoch 161) -- logp(x) = -1.114 +/- 0.024
Evaluate (epoch 162) -- logp(x) = -1.104 +/- 0.023
Evaluate (epoch 163) -- logp(x) = -1.175 +/- 0.024
Evaluate (epoch 164) -- logp(x) = -1.102 +/- 0.023
Evaluate (epoch 165) -- logp(x) = -1.072 +/- 0.024
Evaluate (epoch 166) -- logp(x) = -1.266 +/- 0.021
Evaluate (epoch 167) -- logp(x) = -1.106 +/- 0.024
Evaluate (epoch 168) -- logp(x) = -1.114 +/- 0.023
Evaluate (epoch 169) -- logp(x) = -1.113 +/- 0.025
Evaluate (epoch 170) -- logp(x) = -1.145 +/- 0.023
Evaluate (epoch 171) -- logp(x) = -1.121 +/- 0.023
Evaluate (epoch 172) -- logp(x) = -1.106 +/- 0.023
Evaluate (epoch 173) -- logp(x) = -1.240 +/- 0.022
Evaluate (epoch 174) -- logp(x) = -1.089 +/- 0.023
Evaluate (epoch 175) -- logp(x) = -1.073 +/- 0.023
Evaluate (epoch 176) -- logp(x) = -1.113 +/- 0.023
Evaluate (epoch 177) -- logp(x) = -1.089 +/- 0.023
Evaluate (epoch 178) -- logp(x) = -1.051 +/- 0.024
Evaluate (epoch 179) -- logp(x) = -1.147 +/- 0.025
Evaluate (epoch 180) -- logp(x) = -1.075 +/- 0.025
Evaluate (epoch 181) -- logp(x) = -1.055 +/- 0.024
Evaluate (epoch 182) -- logp(x) = -1.122 +/- 0.023
Evaluate (epoch 183) -- logp(x) = -1.071 +/- 0.024
Evaluate (epoch 184) -- logp(x) = -1.083 +/- 0.025
Evaluate (epoch 185) -- logp(x) = -1.114 +/- 0.022
Evaluate (epoch 186) -- logp(x) = -1.199 +/- 0.022
Evaluate (epoch 187) -- logp(x) = -1.049 +/- 0.024
Evaluate (epoch 188) -- logp(x) = -1.101 +/- 0.023
Evaluate (epoch 189) -- logp(x) = -1.108 +/- 0.023
Evaluate (epoch 190) -- logp(x) = -1.129 +/- 0.025
Evaluate (epoch 191) -- logp(x) = -1.061 +/- 0.024
Evaluate (epoch 192) -- logp(x) = -1.150 +/- 0.028
Evaluate (epoch 193) -- logp(x) = -1.076 +/- 0.024
Evaluate (epoch 194) -- logp(x) = -1.041 +/- 0.023
Evaluate (epoch 195) -- logp(x) = -1.073 +/- 0.024
Evaluate (epoch 196) -- logp(x) = -1.111 +/- 0.024
Evaluate (epoch 197) -- logp(x) = -1.050 +/- 0.024
Evaluate (epoch 198) -- logp(x) = -1.028 +/- 0.024
Evaluate (epoch 199) -- logp(x) = -1.147 +/- 0.024
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'TORUS',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 3,
 'input_order': 'sequential',
 'input_size': 3,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': './results/realnvp/best_model_checkpoint.pt',
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 199,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=3, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=3, bias=True)
      )
    )
  )
)
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': False,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 200,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': None,
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 0,
 'train': True}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
Evaluate (epoch 0) -- logp(x) = -1.042 +/- 0.019
Evaluate (epoch 1) -- logp(x) = -1.035 +/- 0.018
Evaluate (epoch 2) -- logp(x) = -1.033 +/- 0.019
Evaluate (epoch 3) -- logp(x) = -1.026 +/- 0.017
Evaluate (epoch 4) -- logp(x) = -1.023 +/- 0.018
Evaluate (epoch 5) -- logp(x) = -1.022 +/- 0.016
Evaluate (epoch 6) -- logp(x) = -1.017 +/- 0.016
Evaluate (epoch 7) -- logp(x) = -1.009 +/- 0.017
Evaluate (epoch 8) -- logp(x) = -1.006 +/- 0.016
Evaluate (epoch 9) -- logp(x) = -1.002 +/- 0.016
Evaluate (epoch 10) -- logp(x) = -0.980 +/- 0.015
Evaluate (epoch 11) -- logp(x) = -0.949 +/- 0.015
Evaluate (epoch 12) -- logp(x) = -0.943 +/- 0.016
Evaluate (epoch 13) -- logp(x) = -0.902 +/- 0.015
Evaluate (epoch 14) -- logp(x) = -0.897 +/- 0.014
Evaluate (epoch 15) -- logp(x) = -0.879 +/- 0.015
Evaluate (epoch 16) -- logp(x) = -0.846 +/- 0.014
Evaluate (epoch 17) -- logp(x) = -0.827 +/- 0.015
Evaluate (epoch 18) -- logp(x) = -0.812 +/- 0.015
Evaluate (epoch 19) -- logp(x) = -0.791 +/- 0.016
Evaluate (epoch 20) -- logp(x) = -0.792 +/- 0.017
Evaluate (epoch 21) -- logp(x) = -0.827 +/- 0.016
Evaluate (epoch 22) -- logp(x) = -0.992 +/- 0.018
Evaluate (epoch 23) -- logp(x) = -0.867 +/- 0.017
Evaluate (epoch 24) -- logp(x) = -0.832 +/- 0.017
Evaluate (epoch 25) -- logp(x) = -0.792 +/- 0.017
Evaluate (epoch 26) -- logp(x) = -0.755 +/- 0.016
Evaluate (epoch 27) -- logp(x) = -0.749 +/- 0.017
Evaluate (epoch 28) -- logp(x) = -0.698 +/- 0.017
Evaluate (epoch 29) -- logp(x) = -0.708 +/- 0.017
Evaluate (epoch 30) -- logp(x) = -0.667 +/- 0.019
Evaluate (epoch 31) -- logp(x) = -0.663 +/- 0.019
Evaluate (epoch 32) -- logp(x) = -0.652 +/- 0.019
Evaluate (epoch 33) -- logp(x) = -0.649 +/- 0.019
Evaluate (epoch 34) -- logp(x) = -0.611 +/- 0.020
Evaluate (epoch 35) -- logp(x) = -0.619 +/- 0.019
Evaluate (epoch 36) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 37) -- logp(x) = -0.727 +/- 0.019
Evaluate (epoch 38) -- logp(x) = -0.616 +/- 0.019
Evaluate (epoch 39) -- logp(x) = -0.622 +/- 0.022
Evaluate (epoch 40) -- logp(x) = -0.608 +/- 0.020
Evaluate (epoch 41) -- logp(x) = -0.579 +/- 0.020
Evaluate (epoch 42) -- logp(x) = -0.556 +/- 0.020
Evaluate (epoch 43) -- logp(x) = -0.535 +/- 0.020
Evaluate (epoch 44) -- logp(x) = -0.522 +/- 0.021
Evaluate (epoch 45) -- logp(x) = -0.495 +/- 0.022
Evaluate (epoch 46) -- logp(x) = -0.535 +/- 0.021
Evaluate (epoch 47) -- logp(x) = -0.520 +/- 0.022
Evaluate (epoch 48) -- logp(x) = -0.484 +/- 0.023
Evaluate (epoch 49) -- logp(x) = -0.545 +/- 0.024
Evaluate (epoch 50) -- logp(x) = -0.505 +/- 0.022
Evaluate (epoch 51) -- logp(x) = -0.432 +/- 0.024
Evaluate (epoch 52) -- logp(x) = -0.568 +/- 0.029
Evaluate (epoch 53) -- logp(x) = -0.414 +/- 0.024
Evaluate (epoch 54) -- logp(x) = -0.410 +/- 0.024
Evaluate (epoch 55) -- logp(x) = -0.429 +/- 0.025
Evaluate (epoch 56) -- logp(x) = -0.411 +/- 0.025
Evaluate (epoch 57) -- logp(x) = -0.468 +/- 0.023
Evaluate (epoch 58) -- logp(x) = -0.384 +/- 0.024
Evaluate (epoch 59) -- logp(x) = -0.388 +/- 0.025
Evaluate (epoch 60) -- logp(x) = -0.466 +/- 0.024
Evaluate (epoch 61) -- logp(x) = -0.394 +/- 0.024
Evaluate (epoch 62) -- logp(x) = -0.377 +/- 0.025
Evaluate (epoch 63) -- logp(x) = -0.391 +/- 0.024
Evaluate (epoch 64) -- logp(x) = -0.452 +/- 0.026
Evaluate (epoch 65) -- logp(x) = -0.430 +/- 0.025
Evaluate (epoch 66) -- logp(x) = -0.362 +/- 0.024
Evaluate (epoch 67) -- logp(x) = -0.421 +/- 0.025
Evaluate (epoch 68) -- logp(x) = -0.408 +/- 0.025
Evaluate (epoch 69) -- logp(x) = -0.418 +/- 0.027
Evaluate (epoch 70) -- logp(x) = -0.549 +/- 0.026
Evaluate (epoch 71) -- logp(x) = -0.354 +/- 0.026
Evaluate (epoch 72) -- logp(x) = -0.365 +/- 0.027
Evaluate (epoch 73) -- logp(x) = -0.393 +/- 0.028
Evaluate (epoch 74) -- logp(x) = -0.364 +/- 0.029
Evaluate (epoch 75) -- logp(x) = -0.424 +/- 0.026
Evaluate (epoch 76) -- logp(x) = -0.331 +/- 0.024
Evaluate (epoch 77) -- logp(x) = -0.375 +/- 0.027
Evaluate (epoch 78) -- logp(x) = -0.379 +/- 0.026
Evaluate (epoch 79) -- logp(x) = -0.300 +/- 0.025
Evaluate (epoch 80) -- logp(x) = -0.337 +/- 0.027
Evaluate (epoch 81) -- logp(x) = -0.305 +/- 0.025
Evaluate (epoch 82) -- logp(x) = -0.307 +/- 0.027
Evaluate (epoch 83) -- logp(x) = -0.478 +/- 0.027
Evaluate (epoch 84) -- logp(x) = -0.380 +/- 0.025
Evaluate (epoch 85) -- logp(x) = -0.308 +/- 0.026
Evaluate (epoch 86) -- logp(x) = -0.301 +/- 0.025
Evaluate (epoch 87) -- logp(x) = -0.321 +/- 0.025
Evaluate (epoch 88) -- logp(x) = -0.339 +/- 0.026
Evaluate (epoch 89) -- logp(x) = -0.277 +/- 0.026
Evaluate (epoch 90) -- logp(x) = -0.295 +/- 0.026
Evaluate (epoch 91) -- logp(x) = -0.294 +/- 0.024
Evaluate (epoch 92) -- logp(x) = -0.289 +/- 0.024
Evaluate (epoch 93) -- logp(x) = -0.274 +/- 0.025
Evaluate (epoch 94) -- logp(x) = -0.298 +/- 0.026
Evaluate (epoch 95) -- logp(x) = -0.262 +/- 0.026
Evaluate (epoch 96) -- logp(x) = -0.250 +/- 0.027
Evaluate (epoch 97) -- logp(x) = -0.299 +/- 0.026
Evaluate (epoch 98) -- logp(x) = -0.300 +/- 0.024
Evaluate (epoch 99) -- logp(x) = -0.264 +/- 0.025
Evaluate (epoch 100) -- logp(x) = -0.343 +/- 0.024
Evaluate (epoch 101) -- logp(x) = -0.307 +/- 0.023
Evaluate (epoch 102) -- logp(x) = -0.267 +/- 0.025
Evaluate (epoch 103) -- logp(x) = -0.328 +/- 0.027
Evaluate (epoch 104) -- logp(x) = -0.333 +/- 0.031
Evaluate (epoch 105) -- logp(x) = -0.288 +/- 0.026
Evaluate (epoch 106) -- logp(x) = -0.303 +/- 0.024
Evaluate (epoch 107) -- logp(x) = -0.350 +/- 0.027
Evaluate (epoch 108) -- logp(x) = -0.283 +/- 0.025
Evaluate (epoch 109) -- logp(x) = -0.382 +/- 0.028
Evaluate (epoch 110) -- logp(x) = -0.331 +/- 0.027
Evaluate (epoch 111) -- logp(x) = -0.271 +/- 0.025
Evaluate (epoch 112) -- logp(x) = -0.263 +/- 0.025
Evaluate (epoch 113) -- logp(x) = -0.350 +/- 0.027
Evaluate (epoch 114) -- logp(x) = -0.275 +/- 0.026
Evaluate (epoch 115) -- logp(x) = -0.239 +/- 0.028
Evaluate (epoch 116) -- logp(x) = -0.245 +/- 0.028
Evaluate (epoch 117) -- logp(x) = -0.267 +/- 0.025
Evaluate (epoch 118) -- logp(x) = -0.231 +/- 0.026
Evaluate (epoch 119) -- logp(x) = -0.242 +/- 0.027
Evaluate (epoch 120) -- logp(x) = -0.242 +/- 0.028
Evaluate (epoch 121) -- logp(x) = -0.239 +/- 0.025
Evaluate (epoch 122) -- logp(x) = -0.273 +/- 0.025
Evaluate (epoch 123) -- logp(x) = -0.223 +/- 0.025
Evaluate (epoch 124) -- logp(x) = -0.238 +/- 0.026
Evaluate (epoch 125) -- logp(x) = -0.220 +/- 0.026
Evaluate (epoch 126) -- logp(x) = -0.312 +/- 0.027
Evaluate (epoch 127) -- logp(x) = -0.212 +/- 0.026
Evaluate (epoch 128) -- logp(x) = -0.292 +/- 0.026
Evaluate (epoch 129) -- logp(x) = -0.224 +/- 0.026
Evaluate (epoch 130) -- logp(x) = -0.210 +/- 0.026
Evaluate (epoch 131) -- logp(x) = -0.220 +/- 0.026
Evaluate (epoch 132) -- logp(x) = -0.227 +/- 0.025
Evaluate (epoch 133) -- logp(x) = -0.190 +/- 0.027
Evaluate (epoch 134) -- logp(x) = -0.338 +/- 0.025
Evaluate (epoch 135) -- logp(x) = -0.206 +/- 0.025
Evaluate (epoch 136) -- logp(x) = -0.185 +/- 0.026
Evaluate (epoch 137) -- logp(x) = -0.225 +/- 0.026
Evaluate (epoch 138) -- logp(x) = -0.241 +/- 0.025
Evaluate (epoch 139) -- logp(x) = -0.207 +/- 0.026
Evaluate (epoch 140) -- logp(x) = -0.176 +/- 0.026
Evaluate (epoch 141) -- logp(x) = -0.205 +/- 0.026
Evaluate (epoch 142) -- logp(x) = -0.177 +/- 0.028
Evaluate (epoch 143) -- logp(x) = -0.175 +/- 0.028
Evaluate (epoch 144) -- logp(x) = -0.218 +/- 0.026
Evaluate (epoch 145) -- logp(x) = -0.194 +/- 0.027
Evaluate (epoch 146) -- logp(x) = -0.220 +/- 0.027
Evaluate (epoch 147) -- logp(x) = -0.168 +/- 0.027
Evaluate (epoch 148) -- logp(x) = -0.264 +/- 0.027
Evaluate (epoch 149) -- logp(x) = -0.261 +/- 0.026
Evaluate (epoch 150) -- logp(x) = -0.259 +/- 0.030
Evaluate (epoch 151) -- logp(x) = -0.225 +/- 0.025
Evaluate (epoch 152) -- logp(x) = -0.231 +/- 0.027
Evaluate (epoch 153) -- logp(x) = -0.308 +/- 0.027
Evaluate (epoch 154) -- logp(x) = -0.294 +/- 0.028
Evaluate (epoch 155) -- logp(x) = -0.213 +/- 0.026
Evaluate (epoch 156) -- logp(x) = -0.201 +/- 0.027
Evaluate (epoch 157) -- logp(x) = -0.195 +/- 0.027
Evaluate (epoch 158) -- logp(x) = -0.331 +/- 0.027
Evaluate (epoch 159) -- logp(x) = -0.216 +/- 0.028
Evaluate (epoch 160) -- logp(x) = -0.243 +/- 0.025
Evaluate (epoch 161) -- logp(x) = -0.296 +/- 0.026
Evaluate (epoch 162) -- logp(x) = -0.150 +/- 0.028
Evaluate (epoch 163) -- logp(x) = -0.177 +/- 0.027
Evaluate (epoch 164) -- logp(x) = -0.177 +/- 0.027
Evaluate (epoch 165) -- logp(x) = -0.195 +/- 0.027
Evaluate (epoch 166) -- logp(x) = -0.266 +/- 0.027
Evaluate (epoch 167) -- logp(x) = -0.260 +/- 0.027
Evaluate (epoch 168) -- logp(x) = -0.166 +/- 0.028
Evaluate (epoch 169) -- logp(x) = -0.142 +/- 0.028
Evaluate (epoch 170) -- logp(x) = -0.155 +/- 0.030
Evaluate (epoch 171) -- logp(x) = -0.175 +/- 0.028
Evaluate (epoch 172) -- logp(x) = -0.220 +/- 0.027
Evaluate (epoch 173) -- logp(x) = -0.160 +/- 0.026
Evaluate (epoch 174) -- logp(x) = -0.196 +/- 0.027
Evaluate (epoch 175) -- logp(x) = -0.166 +/- 0.026
Evaluate (epoch 176) -- logp(x) = -0.189 +/- 0.029
Evaluate (epoch 177) -- logp(x) = -0.180 +/- 0.028
Evaluate (epoch 178) -- logp(x) = -0.153 +/- 0.026
Evaluate (epoch 179) -- logp(x) = -0.192 +/- 0.030
Evaluate (epoch 180) -- logp(x) = -0.143 +/- 0.027
Evaluate (epoch 181) -- logp(x) = -0.161 +/- 0.027
Evaluate (epoch 182) -- logp(x) = -0.337 +/- 0.027
Evaluate (epoch 183) -- logp(x) = -0.281 +/- 0.029
Evaluate (epoch 184) -- logp(x) = -0.268 +/- 0.027
Evaluate (epoch 185) -- logp(x) = -0.257 +/- 0.031
Evaluate (epoch 186) -- logp(x) = -0.315 +/- 0.030
Evaluate (epoch 187) -- logp(x) = -0.199 +/- 0.029
Evaluate (epoch 188) -- logp(x) = -0.263 +/- 0.027
Evaluate (epoch 189) -- logp(x) = -0.289 +/- 0.033
Evaluate (epoch 190) -- logp(x) = -0.232 +/- 0.026
Evaluate (epoch 191) -- logp(x) = -0.211 +/- 0.028
Evaluate (epoch 192) -- logp(x) = -0.210 +/- 0.028
Evaluate (epoch 193) -- logp(x) = -0.188 +/- 0.031
Evaluate (epoch 194) -- logp(x) = -0.199 +/- 0.028
Evaluate (epoch 195) -- logp(x) = -0.194 +/- 0.029
Evaluate (epoch 196) -- logp(x) = -0.190 +/- 0.032
Evaluate (epoch 197) -- logp(x) = -0.188 +/- 0.027
Evaluate (epoch 198) -- logp(x) = -0.189 +/- 0.029
Evaluate (epoch 199) -- logp(x) = -0.230 +/- 0.028
{'activation_fn': 'relu',
 'batch_size': 100,
 'cond_label_size': None,
 'conditional': False,
 'data_dir': './data/',
 'dataset': 'INVOLUTE',
 'device': device(type='cuda', index=0),
 'evaluate': False,
 'flip_toy_var_order': False,
 'generate': True,
 'hidden_size': 100,
 'input_dims': 2,
 'input_order': 'sequential',
 'input_size': 2,
 'log_interval': 1000,
 'lr': 0.0001,
 'model': 'realnvp',
 'n_blocks': 5,
 'n_components': 1,
 'n_epochs': 50,
 'n_hidden': 1,
 'no_batch_norm': True,
 'no_cuda': False,
 'output_dir': './results/realnvp',
 'restore_file': './results/realnvp/best_model_checkpoint.pt',
 'results_file': './results/realnvp\\results.txt',
 'seed': 1,
 'start_epoch': 170,
 'train': False}
RealNVP(
  (net): FlowSequential(
    (0): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (1): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (2): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (3): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
    (4): LinearMaskedCoupling(
      (s_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): Tanh()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): Tanh()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
      (t_net): Sequential(
        (0): Linear(in_features=2, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=2, bias=True)
      )
    )
  )
)
